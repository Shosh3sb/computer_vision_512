{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shosh3sb/computer_vision_512/blob/main/Imag_colorization_BYTransfer_Learning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBlQyzPng6zM"
      },
      "outputs": [],
      "source": [
        "################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stVcgIfshHWi",
        "outputId": "085a0df3-d50e-4605-bf30-65511df8be21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-16 15:41:23.448872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "# Load the CIFAR10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the input images to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Convert the input images to grayscale\n",
        "x_train_gray = np.dot(x_train, [0.2989, 0.5870, 0.1140])\n",
        "x_test_gray = np.dot(x_test, [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Reshape the input images to 32x32x1\n",
        "x_train_gray = np.reshape(x_train_gray, (len(x_train_gray), 32, 32, 1))\n",
        "x_test_gray = np.reshape(x_test_gray, (len(x_test_gray), 32, 32, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQz3wVnMhJkp",
        "outputId": "ebb5188a-e05a-4d10-e606-5e1c61f872d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-16 15:41:26.056778: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2023-04-16 15:41:26.056929: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-04-16 15:41:26.056934: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-04-16 15:41:26.056944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (firas-lab): /proc/driver/nvidia/version does not exist\n",
            "2023-04-16 15:41:26.057062: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-16 15:41:26.058130: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "# Generator function\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "    assert model.output_shape == (None, 8, 8, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 32, 32, 32)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 32, 32, 3)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    # Load the pre-trained VGG16 model\n",
        "    vgg16 = VGG16(include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "    # Set all layers in the VGG16 model to non-trainable\n",
        "    for layer in vgg16.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add a custom output layer to the VGG16 model\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(vgg16)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# GAN function\n",
        "def make_gan(generator, discriminator):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "# Create the generator and discriminator models\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "# Compile the discriminator model\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "\n",
        "# Create the GAN model\n",
        "gan = make_gan(generator, discriminator)\n",
        "\n",
        "# Compile the GAN model\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "\n",
        "# Train the GAN model\n",
        "# ... add code here to prepare data and train the GAN ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DUhpJUOP6rI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B02hJ83qhcWm",
        "outputId": "df4fbff7-968f-4465-ffea-f4ed2b3b32f9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-16 15:41:26.505728: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2023-04-16 15:41:26.523403: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2688000000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1/390 - D loss: 0.7151, G loss: 0.2512\n",
            "Step 2/390 - D loss: 0.7185, G loss: 0.1982\n",
            "Step 3/390 - D loss: 0.7091, G loss: 0.1716\n",
            "Step 4/390 - D loss: 0.7117, G loss: 0.1565\n",
            "Step 5/390 - D loss: 0.7175, G loss: 0.1444\n",
            "Step 6/390 - D loss: 0.7163, G loss: 0.1344\n",
            "Step 7/390 - D loss: 0.7068, G loss: 0.1168\n",
            "Step 8/390 - D loss: 0.7215, G loss: 0.1047\n",
            "Step 9/390 - D loss: 0.7178, G loss: 0.0921\n",
            "Step 10/390 - D loss: 0.7208, G loss: 0.0801\n",
            "Step 11/390 - D loss: 0.7121, G loss: 0.0706\n",
            "Step 12/390 - D loss: 0.7146, G loss: 0.0637\n",
            "Step 13/390 - D loss: 0.7205, G loss: 0.0559\n",
            "Step 14/390 - D loss: 0.7093, G loss: 0.0507\n",
            "Step 15/390 - D loss: 0.7177, G loss: 0.0453\n",
            "Step 16/390 - D loss: 0.7188, G loss: 0.0411\n",
            "Step 17/390 - D loss: 0.7074, G loss: 0.0371\n",
            "Step 18/390 - D loss: 0.7118, G loss: 0.0334\n",
            "Step 19/390 - D loss: 0.7089, G loss: 0.0303\n",
            "Step 20/390 - D loss: 0.6998, G loss: 0.0274\n",
            "Step 21/390 - D loss: 0.7079, G loss: 0.0242\n",
            "Step 22/390 - D loss: 0.7062, G loss: 0.0223\n",
            "Step 23/390 - D loss: 0.7024, G loss: 0.0204\n",
            "Step 24/390 - D loss: 0.6989, G loss: 0.0180\n",
            "Step 25/390 - D loss: 0.7013, G loss: 0.0164\n",
            "Step 26/390 - D loss: 0.6975, G loss: 0.0152\n",
            "Step 27/390 - D loss: 0.6960, G loss: 0.0142\n",
            "Step 28/390 - D loss: 0.6954, G loss: 0.0130\n",
            "Step 29/390 - D loss: 0.6935, G loss: 0.0120\n",
            "Step 30/390 - D loss: 0.6891, G loss: 0.0113\n",
            "Step 31/390 - D loss: 0.6777, G loss: 0.0103\n",
            "Step 32/390 - D loss: 0.6773, G loss: 0.0098\n",
            "Step 33/390 - D loss: 0.6769, G loss: 0.0094\n",
            "Step 34/390 - D loss: 0.6705, G loss: 0.0087\n",
            "Step 35/390 - D loss: 0.6722, G loss: 0.0081\n",
            "Step 36/390 - D loss: 0.6661, G loss: 0.0080\n",
            "Step 37/390 - D loss: 0.6654, G loss: 0.0073\n",
            "Step 38/390 - D loss: 0.6608, G loss: 0.0067\n",
            "Step 39/390 - D loss: 0.6543, G loss: 0.0068\n",
            "Step 40/390 - D loss: 0.6465, G loss: 0.0064\n",
            "Step 41/390 - D loss: 0.6432, G loss: 0.0061\n",
            "Step 42/390 - D loss: 0.6476, G loss: 0.0057\n",
            "Step 43/390 - D loss: 0.6500, G loss: 0.0054\n",
            "Step 44/390 - D loss: 0.6485, G loss: 0.0053\n",
            "Step 45/390 - D loss: 0.6438, G loss: 0.0048\n",
            "Step 46/390 - D loss: 0.6344, G loss: 0.0046\n",
            "Step 47/390 - D loss: 0.6335, G loss: 0.0046\n",
            "Step 48/390 - D loss: 0.6294, G loss: 0.0043\n",
            "Step 49/390 - D loss: 0.6312, G loss: 0.0042\n",
            "Step 50/390 - D loss: 0.6284, G loss: 0.0040\n",
            "Step 51/390 - D loss: 0.6310, G loss: 0.0039\n",
            "Step 52/390 - D loss: 0.6244, G loss: 0.0037\n",
            "Step 53/390 - D loss: 0.6280, G loss: 0.0036\n",
            "Step 54/390 - D loss: 0.6199, G loss: 0.0036\n",
            "Step 55/390 - D loss: 0.6251, G loss: 0.0033\n",
            "Step 56/390 - D loss: 0.6250, G loss: 0.0032\n",
            "Step 57/390 - D loss: 0.6221, G loss: 0.0031\n",
            "Step 58/390 - D loss: 0.6146, G loss: 0.0031\n",
            "Step 59/390 - D loss: 0.6168, G loss: 0.0029\n",
            "Step 60/390 - D loss: 0.6123, G loss: 0.0028\n",
            "Step 61/390 - D loss: 0.6167, G loss: 0.0028\n",
            "Step 62/390 - D loss: 0.6097, G loss: 0.0027\n",
            "Step 63/390 - D loss: 0.6143, G loss: 0.0026\n",
            "Step 64/390 - D loss: 0.6078, G loss: 0.0026\n",
            "Step 65/390 - D loss: 0.6060, G loss: 0.0026\n",
            "Step 66/390 - D loss: 0.6079, G loss: 0.0025\n",
            "Step 67/390 - D loss: 0.6129, G loss: 0.0023\n",
            "Step 68/390 - D loss: 0.6105, G loss: 0.0023\n",
            "Step 69/390 - D loss: 0.6036, G loss: 0.0022\n",
            "Step 70/390 - D loss: 0.5947, G loss: 0.0023\n",
            "Step 71/390 - D loss: 0.6042, G loss: 0.0021\n",
            "Step 72/390 - D loss: 0.6054, G loss: 0.0021\n",
            "Step 73/390 - D loss: 0.6022, G loss: 0.0021\n",
            "Step 74/390 - D loss: 0.5911, G loss: 0.0020\n",
            "Step 75/390 - D loss: 0.5992, G loss: 0.0019\n",
            "Step 76/390 - D loss: 0.5973, G loss: 0.0020\n",
            "Step 77/390 - D loss: 0.5947, G loss: 0.0019\n",
            "Step 78/390 - D loss: 0.5857, G loss: 0.0018\n",
            "Step 79/390 - D loss: 0.5868, G loss: 0.0019\n",
            "Step 80/390 - D loss: 0.5887, G loss: 0.0018\n",
            "Step 81/390 - D loss: 0.5877, G loss: 0.0017\n",
            "Step 82/390 - D loss: 0.5730, G loss: 0.0018\n",
            "Step 83/390 - D loss: 0.5819, G loss: 0.0017\n",
            "Step 84/390 - D loss: 0.5832, G loss: 0.0017\n",
            "Step 85/390 - D loss: 0.5814, G loss: 0.0016\n",
            "Step 86/390 - D loss: 0.5761, G loss: 0.0016\n",
            "Step 87/390 - D loss: 0.5790, G loss: 0.0016\n",
            "Step 88/390 - D loss: 0.5838, G loss: 0.0016\n",
            "Step 89/390 - D loss: 0.5704, G loss: 0.0016\n",
            "Step 90/390 - D loss: 0.5690, G loss: 0.0015\n",
            "Step 91/390 - D loss: 0.5744, G loss: 0.0015\n",
            "Step 92/390 - D loss: 0.5686, G loss: 0.0015\n",
            "Step 93/390 - D loss: 0.5733, G loss: 0.0015\n",
            "Step 94/390 - D loss: 0.5746, G loss: 0.0015\n",
            "Step 95/390 - D loss: 0.5637, G loss: 0.0015\n",
            "Step 96/390 - D loss: 0.5599, G loss: 0.0014\n",
            "Step 97/390 - D loss: 0.5626, G loss: 0.0014\n",
            "Step 98/390 - D loss: 0.5558, G loss: 0.0014\n",
            "Step 99/390 - D loss: 0.5596, G loss: 0.0014\n",
            "Step 100/390 - D loss: 0.5533, G loss: 0.0014\n",
            "Step 101/390 - D loss: 0.5534, G loss: 0.0013\n",
            "Step 102/390 - D loss: 0.5489, G loss: 0.0013\n",
            "Step 103/390 - D loss: 0.5584, G loss: 0.0013\n",
            "Step 104/390 - D loss: 0.5513, G loss: 0.0013\n",
            "Step 105/390 - D loss: 0.5582, G loss: 0.0013\n",
            "Step 106/390 - D loss: 0.5388, G loss: 0.0013\n",
            "Step 107/390 - D loss: 0.5412, G loss: 0.0013\n",
            "Step 108/390 - D loss: 0.5503, G loss: 0.0013\n",
            "Step 109/390 - D loss: 0.5407, G loss: 0.0012\n",
            "Step 110/390 - D loss: 0.5381, G loss: 0.0012\n",
            "Step 111/390 - D loss: 0.5398, G loss: 0.0012\n",
            "Step 112/390 - D loss: 0.5377, G loss: 0.0012\n",
            "Step 113/390 - D loss: 0.5497, G loss: 0.0012\n",
            "Step 114/390 - D loss: 0.5399, G loss: 0.0012\n",
            "Step 115/390 - D loss: 0.5395, G loss: 0.0011\n",
            "Step 116/390 - D loss: 0.5404, G loss: 0.0011\n",
            "Step 117/390 - D loss: 0.5405, G loss: 0.0011\n",
            "Step 118/390 - D loss: 0.5354, G loss: 0.0011\n",
            "Step 119/390 - D loss: 0.5371, G loss: 0.0011\n",
            "Step 120/390 - D loss: 0.5364, G loss: 0.0011\n",
            "Step 121/390 - D loss: 0.5321, G loss: 0.0011\n",
            "Step 122/390 - D loss: 0.5346, G loss: 0.0011\n",
            "Step 123/390 - D loss: 0.5305, G loss: 0.0011\n",
            "Step 124/390 - D loss: 0.5275, G loss: 0.0011\n",
            "Step 125/390 - D loss: 0.5344, G loss: 0.0010\n",
            "Step 126/390 - D loss: 0.5271, G loss: 0.0011\n",
            "Step 127/390 - D loss: 0.5227, G loss: 0.0011\n",
            "Step 128/390 - D loss: 0.5293, G loss: 0.0010\n",
            "Step 129/390 - D loss: 0.5200, G loss: 0.0010\n",
            "Step 130/390 - D loss: 0.5314, G loss: 0.0010\n",
            "Step 131/390 - D loss: 0.5266, G loss: 0.0010\n",
            "Step 132/390 - D loss: 0.5286, G loss: 0.0010\n",
            "Step 133/390 - D loss: 0.5217, G loss: 0.0010\n",
            "Step 134/390 - D loss: 0.5278, G loss: 0.0010\n",
            "Step 135/390 - D loss: 0.5318, G loss: 0.0010\n",
            "Step 136/390 - D loss: 0.5223, G loss: 0.0010\n",
            "Step 137/390 - D loss: 0.5220, G loss: 0.0010\n",
            "Step 138/390 - D loss: 0.5200, G loss: 0.0010\n",
            "Step 139/390 - D loss: 0.5251, G loss: 0.0009\n",
            "Step 140/390 - D loss: 0.5265, G loss: 0.0009\n",
            "Step 141/390 - D loss: 0.5274, G loss: 0.0009\n",
            "Step 142/390 - D loss: 0.5205, G loss: 0.0009\n",
            "Step 143/390 - D loss: 0.5153, G loss: 0.0009\n",
            "Step 144/390 - D loss: 0.5218, G loss: 0.0009\n",
            "Step 145/390 - D loss: 0.5158, G loss: 0.0009\n",
            "Step 146/390 - D loss: 0.4949, G loss: 0.0009\n",
            "Step 147/390 - D loss: 0.5190, G loss: 0.0009\n",
            "Step 148/390 - D loss: 0.5203, G loss: 0.0009\n",
            "Step 149/390 - D loss: 0.5120, G loss: 0.0009\n",
            "Step 150/390 - D loss: 0.5199, G loss: 0.0009\n",
            "Step 151/390 - D loss: 0.5152, G loss: 0.0009\n",
            "Step 152/390 - D loss: 0.5180, G loss: 0.0009\n",
            "Step 153/390 - D loss: 0.5130, G loss: 0.0009\n",
            "Step 154/390 - D loss: 0.5100, G loss: 0.0009\n",
            "Step 155/390 - D loss: 0.5226, G loss: 0.0009\n",
            "Step 156/390 - D loss: 0.5250, G loss: 0.0009\n",
            "Step 157/390 - D loss: 0.5228, G loss: 0.0009\n",
            "Step 158/390 - D loss: 0.5193, G loss: 0.0009\n",
            "Step 159/390 - D loss: 0.5319, G loss: 0.0009\n",
            "Step 160/390 - D loss: 0.5171, G loss: 0.0009\n",
            "Step 161/390 - D loss: 0.5265, G loss: 0.0009\n",
            "Step 162/390 - D loss: 0.5198, G loss: 0.0009\n",
            "Step 163/390 - D loss: 0.5160, G loss: 0.0009\n",
            "Step 164/390 - D loss: 0.5218, G loss: 0.0009\n",
            "Step 165/390 - D loss: 0.5208, G loss: 0.0009\n",
            "Step 166/390 - D loss: 0.5295, G loss: 0.0009\n",
            "Step 167/390 - D loss: 0.5113, G loss: 0.0009\n",
            "Step 168/390 - D loss: 0.5328, G loss: 0.0009\n",
            "Step 169/390 - D loss: 0.5201, G loss: 0.0009\n",
            "Step 170/390 - D loss: 0.5270, G loss: 0.0009\n",
            "Step 171/390 - D loss: 0.5288, G loss: 0.0009\n",
            "Step 172/390 - D loss: 0.5266, G loss: 0.0009\n",
            "Step 173/390 - D loss: 0.5197, G loss: 0.0009\n",
            "Step 174/390 - D loss: 0.5251, G loss: 0.0009\n",
            "Step 175/390 - D loss: 0.5273, G loss: 0.0009\n",
            "Step 176/390 - D loss: 0.5292, G loss: 0.0009\n",
            "Step 177/390 - D loss: 0.5314, G loss: 0.0009\n",
            "Step 178/390 - D loss: 0.5205, G loss: 0.0009\n",
            "Step 179/390 - D loss: 0.5259, G loss: 0.0009\n",
            "Step 180/390 - D loss: 0.5167, G loss: 0.0010\n",
            "Step 181/390 - D loss: 0.5263, G loss: 0.0010\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 182/390 - D loss: 0.5227, G loss: 0.0010\n",
            "Step 183/390 - D loss: 0.5255, G loss: 0.0010\n",
            "Step 184/390 - D loss: 0.5175, G loss: 0.0010\n",
            "Step 185/390 - D loss: 0.5265, G loss: 0.0010\n",
            "Step 186/390 - D loss: 0.5160, G loss: 0.0010\n",
            "Step 187/390 - D loss: 0.5345, G loss: 0.0010\n",
            "Step 188/390 - D loss: 0.5238, G loss: 0.0010\n",
            "Step 189/390 - D loss: 0.5283, G loss: 0.0010\n",
            "Step 190/390 - D loss: 0.5326, G loss: 0.0011\n",
            "Step 191/390 - D loss: 0.5319, G loss: 0.0011\n",
            "Step 192/390 - D loss: 0.5228, G loss: 0.0011\n",
            "Step 193/390 - D loss: 0.5383, G loss: 0.0011\n",
            "Step 194/390 - D loss: 0.5347, G loss: 0.0011\n",
            "Step 195/390 - D loss: 0.5442, G loss: 0.0011\n",
            "Step 196/390 - D loss: 0.5428, G loss: 0.0012\n",
            "Step 197/390 - D loss: 0.5424, G loss: 0.0011\n",
            "Step 198/390 - D loss: 0.5252, G loss: 0.0012\n",
            "Step 199/390 - D loss: 0.5341, G loss: 0.0011\n",
            "Step 200/390 - D loss: 0.5353, G loss: 0.0012\n",
            "Step 201/390 - D loss: 0.5249, G loss: 0.0013\n",
            "Step 202/390 - D loss: 0.5317, G loss: 0.0013\n",
            "Step 203/390 - D loss: 0.5490, G loss: 0.0013\n",
            "Step 204/390 - D loss: 0.5390, G loss: 0.0013\n",
            "Step 205/390 - D loss: 0.5368, G loss: 0.0013\n",
            "Step 206/390 - D loss: 0.5457, G loss: 0.0013\n",
            "Step 207/390 - D loss: 0.5387, G loss: 0.0013\n",
            "Step 208/390 - D loss: 0.5470, G loss: 0.0013\n",
            "Step 209/390 - D loss: 0.5395, G loss: 0.0014\n",
            "Step 210/390 - D loss: 0.5500, G loss: 0.0014\n",
            "Step 211/390 - D loss: 0.5397, G loss: 0.0014\n",
            "Step 212/390 - D loss: 0.5485, G loss: 0.0015\n",
            "Step 213/390 - D loss: 0.5554, G loss: 0.0014\n",
            "Step 214/390 - D loss: 0.5393, G loss: 0.0015\n",
            "Step 215/390 - D loss: 0.5393, G loss: 0.0015\n",
            "Step 216/390 - D loss: 0.5467, G loss: 0.0015\n",
            "Step 217/390 - D loss: 0.5556, G loss: 0.0015\n",
            "Step 218/390 - D loss: 0.5423, G loss: 0.0016\n",
            "Step 219/390 - D loss: 0.5510, G loss: 0.0016\n",
            "Step 220/390 - D loss: 0.5467, G loss: 0.0017\n",
            "Step 221/390 - D loss: 0.5565, G loss: 0.0017\n",
            "Step 222/390 - D loss: 0.5581, G loss: 0.0016\n",
            "Step 223/390 - D loss: 0.5537, G loss: 0.0017\n",
            "Step 224/390 - D loss: 0.5599, G loss: 0.0017\n",
            "Step 225/390 - D loss: 0.5625, G loss: 0.0017\n",
            "Step 226/390 - D loss: 0.5534, G loss: 0.0018\n",
            "Step 227/390 - D loss: 0.5633, G loss: 0.0018\n",
            "Step 228/390 - D loss: 0.5537, G loss: 0.0019\n",
            "Step 229/390 - D loss: 0.5744, G loss: 0.0019\n",
            "Step 230/390 - D loss: 0.5758, G loss: 0.0019\n",
            "Step 231/390 - D loss: 0.5841, G loss: 0.0020\n",
            "Step 232/390 - D loss: 0.5745, G loss: 0.0020\n",
            "Step 233/390 - D loss: 0.5743, G loss: 0.0021\n",
            "Step 234/390 - D loss: 0.5826, G loss: 0.0021\n",
            "Step 235/390 - D loss: 0.5950, G loss: 0.0021\n",
            "Step 236/390 - D loss: 0.5984, G loss: 0.0021\n",
            "Step 237/390 - D loss: 0.5996, G loss: 0.0023\n",
            "Step 238/390 - D loss: 0.5836, G loss: 0.0023\n",
            "Step 239/390 - D loss: 0.6043, G loss: 0.0023\n",
            "Step 240/390 - D loss: 0.5972, G loss: 0.0024\n",
            "Step 241/390 - D loss: 0.5917, G loss: 0.0024\n",
            "Step 242/390 - D loss: 0.6069, G loss: 0.0025\n",
            "Step 243/390 - D loss: 0.6091, G loss: 0.0026\n",
            "Step 244/390 - D loss: 0.6075, G loss: 0.0026\n",
            "Step 245/390 - D loss: 0.6176, G loss: 0.0027\n",
            "Step 246/390 - D loss: 0.6199, G loss: 0.0028\n",
            "Step 247/390 - D loss: 0.6216, G loss: 0.0028\n",
            "Step 248/390 - D loss: 0.6163, G loss: 0.0029\n",
            "Step 249/390 - D loss: 0.6248, G loss: 0.0030\n",
            "Step 250/390 - D loss: 0.6317, G loss: 0.0031\n",
            "Step 251/390 - D loss: 0.6248, G loss: 0.0031\n",
            "Step 252/390 - D loss: 0.6253, G loss: 0.0033\n",
            "Step 253/390 - D loss: 0.6351, G loss: 0.0035\n",
            "Step 254/390 - D loss: 0.6416, G loss: 0.0035\n",
            "Step 255/390 - D loss: 0.6540, G loss: 0.0036\n",
            "Step 256/390 - D loss: 0.6375, G loss: 0.0038\n",
            "Step 257/390 - D loss: 0.6596, G loss: 0.0039\n",
            "Step 258/390 - D loss: 0.6751, G loss: 0.0040\n",
            "Step 259/390 - D loss: 0.6796, G loss: 0.0041\n",
            "Step 260/390 - D loss: 0.6650, G loss: 0.0043\n",
            "Step 261/390 - D loss: 0.7002, G loss: 0.0045\n",
            "Step 262/390 - D loss: 0.6868, G loss: 0.0047\n",
            "Step 263/390 - D loss: 0.7014, G loss: 0.0047\n",
            "Step 264/390 - D loss: 0.7233, G loss: 0.0049\n",
            "Step 265/390 - D loss: 0.6968, G loss: 0.0051\n",
            "Step 266/390 - D loss: 0.7177, G loss: 0.0053\n",
            "Step 267/390 - D loss: 0.7174, G loss: 0.0055\n",
            "Step 268/390 - D loss: 0.7490, G loss: 0.0057\n",
            "Step 269/390 - D loss: 0.7315, G loss: 0.0059\n",
            "Step 270/390 - D loss: 0.7267, G loss: 0.0061\n",
            "Step 271/390 - D loss: 0.7669, G loss: 0.0064\n",
            "Step 272/390 - D loss: 0.7438, G loss: 0.0065\n",
            "Step 273/390 - D loss: 0.7581, G loss: 0.0069\n",
            "Step 274/390 - D loss: 0.7739, G loss: 0.0071\n",
            "Step 275/390 - D loss: 0.7833, G loss: 0.0074\n",
            "Step 276/390 - D loss: 0.8257, G loss: 0.0075\n",
            "Step 277/390 - D loss: 0.7963, G loss: 0.0077\n",
            "Step 278/390 - D loss: 0.8316, G loss: 0.0082\n",
            "Step 279/390 - D loss: 0.8247, G loss: 0.0082\n",
            "Step 280/390 - D loss: 0.8255, G loss: 0.0087\n",
            "Step 281/390 - D loss: 0.8409, G loss: 0.0089\n",
            "Step 282/390 - D loss: 0.8585, G loss: 0.0091\n",
            "Step 283/390 - D loss: 0.8761, G loss: 0.0095\n",
            "Step 284/390 - D loss: 0.8872, G loss: 0.0095\n",
            "Step 285/390 - D loss: 0.8880, G loss: 0.0098\n",
            "Step 286/390 - D loss: 0.9358, G loss: 0.0100\n",
            "Step 287/390 - D loss: 0.9359, G loss: 0.0104\n",
            "Step 288/390 - D loss: 0.9515, G loss: 0.0106\n",
            "Step 289/390 - D loss: 0.9478, G loss: 0.0108\n",
            "Step 290/390 - D loss: 1.0085, G loss: 0.0112\n",
            "Step 291/390 - D loss: 0.9790, G loss: 0.0112\n",
            "Step 292/390 - D loss: 0.9851, G loss: 0.0118\n",
            "Step 293/390 - D loss: 1.0125, G loss: 0.0117\n",
            "Step 294/390 - D loss: 1.0307, G loss: 0.0119\n",
            "Step 295/390 - D loss: 1.0833, G loss: 0.0122\n",
            "Step 296/390 - D loss: 1.0441, G loss: 0.0122\n",
            "Step 297/390 - D loss: 1.0692, G loss: 0.0124\n",
            "Step 298/390 - D loss: 1.1053, G loss: 0.0123\n",
            "Step 299/390 - D loss: 1.1068, G loss: 0.0123\n",
            "Step 300/390 - D loss: 1.1347, G loss: 0.0126\n",
            "Step 301/390 - D loss: 1.1427, G loss: 0.0125\n",
            "Step 302/390 - D loss: 1.1599, G loss: 0.0120\n",
            "Step 303/390 - D loss: 1.1405, G loss: 0.0125\n",
            "Step 304/390 - D loss: 1.1634, G loss: 0.0120\n",
            "Step 305/390 - D loss: 1.1801, G loss: 0.0121\n",
            "Step 306/390 - D loss: 1.1956, G loss: 0.0122\n",
            "Step 307/390 - D loss: 1.2013, G loss: 0.0117\n",
            "Step 308/390 - D loss: 1.2046, G loss: 0.0115\n",
            "Step 309/390 - D loss: 1.2013, G loss: 0.0114\n",
            "Step 310/390 - D loss: 1.2134, G loss: 0.0114\n",
            "Step 311/390 - D loss: 1.2583, G loss: 0.0113\n",
            "Step 312/390 - D loss: 1.2341, G loss: 0.0112\n",
            "Step 313/390 - D loss: 1.2353, G loss: 0.0108\n",
            "Step 314/390 - D loss: 1.2449, G loss: 0.0106\n",
            "Step 315/390 - D loss: 1.2375, G loss: 0.0106\n",
            "Step 316/390 - D loss: 1.2197, G loss: 0.0106\n",
            "Step 317/390 - D loss: 1.2212, G loss: 0.0104\n",
            "Step 318/390 - D loss: 1.2311, G loss: 0.0101\n",
            "Step 319/390 - D loss: 1.2521, G loss: 0.0103\n",
            "Step 320/390 - D loss: 1.2795, G loss: 0.0101\n",
            "Step 321/390 - D loss: 1.3034, G loss: 0.0101\n",
            "Step 322/390 - D loss: 1.2814, G loss: 0.0101\n",
            "Step 323/390 - D loss: 1.3282, G loss: 0.0103\n",
            "Step 324/390 - D loss: 1.2963, G loss: 0.0102\n",
            "Step 325/390 - D loss: 1.3696, G loss: 0.0101\n",
            "Step 326/390 - D loss: 1.3428, G loss: 0.0098\n",
            "Step 327/390 - D loss: 1.3702, G loss: 0.0101\n",
            "Step 328/390 - D loss: 1.3846, G loss: 0.0099\n",
            "Step 329/390 - D loss: 1.4018, G loss: 0.0102\n",
            "Step 330/390 - D loss: 1.3878, G loss: 0.0100\n",
            "Step 331/390 - D loss: 1.3638, G loss: 0.0102\n",
            "Step 332/390 - D loss: 1.3769, G loss: 0.0102\n",
            "Step 333/390 - D loss: 1.4103, G loss: 0.0099\n",
            "Step 334/390 - D loss: 1.3921, G loss: 0.0102\n",
            "Step 335/390 - D loss: 1.4006, G loss: 0.0102\n",
            "Step 336/390 - D loss: 1.4404, G loss: 0.0101\n",
            "Step 337/390 - D loss: 1.4379, G loss: 0.0102\n",
            "Step 338/390 - D loss: 1.4352, G loss: 0.0103\n",
            "Step 339/390 - D loss: 1.4575, G loss: 0.0102\n",
            "Step 340/390 - D loss: 1.4762, G loss: 0.0103\n",
            "Step 341/390 - D loss: 1.4886, G loss: 0.0102\n",
            "Step 342/390 - D loss: 1.4719, G loss: 0.0103\n",
            "Step 343/390 - D loss: 1.4724, G loss: 0.0105\n",
            "Step 344/390 - D loss: 1.4790, G loss: 0.0102\n",
            "Step 345/390 - D loss: 1.4652, G loss: 0.0101\n",
            "Step 346/390 - D loss: 1.4557, G loss: 0.0098\n",
            "Step 347/390 - D loss: 1.4897, G loss: 0.0102\n",
            "Step 348/390 - D loss: 1.4859, G loss: 0.0098\n",
            "Step 349/390 - D loss: 1.5136, G loss: 0.0102\n",
            "Step 350/390 - D loss: 1.4967, G loss: 0.0099\n",
            "Step 351/390 - D loss: 1.5257, G loss: 0.0098\n",
            "Step 352/390 - D loss: 1.5458, G loss: 0.0099\n",
            "Step 353/390 - D loss: 1.5377, G loss: 0.0098\n",
            "Step 354/390 - D loss: 1.5500, G loss: 0.0099\n",
            "Step 355/390 - D loss: 1.5525, G loss: 0.0099\n",
            "Step 356/390 - D loss: 1.5886, G loss: 0.0097\n",
            "Step 357/390 - D loss: 1.5704, G loss: 0.0095\n",
            "Step 358/390 - D loss: 1.5816, G loss: 0.0098\n",
            "Step 359/390 - D loss: 1.5940, G loss: 0.0094\n",
            "Step 360/390 - D loss: 1.5825, G loss: 0.0093\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 361/390 - D loss: 1.6147, G loss: 0.0096\n",
            "Step 362/390 - D loss: 1.5964, G loss: 0.0092\n",
            "Step 363/390 - D loss: 1.6227, G loss: 0.0092\n",
            "Step 364/390 - D loss: 1.6189, G loss: 0.0090\n",
            "Step 365/390 - D loss: 1.6150, G loss: 0.0088\n",
            "Step 366/390 - D loss: 1.6011, G loss: 0.0091\n",
            "Step 367/390 - D loss: 1.5825, G loss: 0.0087\n",
            "Step 368/390 - D loss: 1.5957, G loss: 0.0087\n",
            "Step 369/390 - D loss: 1.6027, G loss: 0.0088\n",
            "Step 370/390 - D loss: 1.6253, G loss: 0.0085\n",
            "Step 371/390 - D loss: 1.6185, G loss: 0.0084\n",
            "Step 372/390 - D loss: 1.6060, G loss: 0.0081\n",
            "Step 373/390 - D loss: 1.6192, G loss: 0.0081\n",
            "Step 374/390 - D loss: 1.5812, G loss: 0.0078\n",
            "Step 375/390 - D loss: 1.5909, G loss: 0.0075\n",
            "Step 376/390 - D loss: 1.6436, G loss: 0.0073\n",
            "Step 377/390 - D loss: 1.6386, G loss: 0.0071\n",
            "Step 378/390 - D loss: 1.6598, G loss: 0.0069\n",
            "Step 379/390 - D loss: 1.6321, G loss: 0.0065\n",
            "Step 380/390 - D loss: 1.6567, G loss: 0.0064\n",
            "Step 381/390 - D loss: 1.6223, G loss: 0.0061\n",
            "Step 382/390 - D loss: 1.6556, G loss: 0.0058\n",
            "Step 383/390 - D loss: 1.6289, G loss: 0.0057\n",
            "Step 384/390 - D loss: 1.6483, G loss: 0.0053\n",
            "Step 385/390 - D loss: 1.6557, G loss: 0.0052\n",
            "Step 386/390 - D loss: 1.6609, G loss: 0.0050\n",
            "Step 387/390 - D loss: 1.6412, G loss: 0.0048\n",
            "Step 388/390 - D loss: 1.6620, G loss: 0.0047\n",
            "Step 389/390 - D loss: 1.6544, G loss: 0.0045\n",
            "Step 390/390 - D loss: 1.6619, G loss: 0.0045\n",
            "Epoch 2/200\n",
            "Step 1/390 - D loss: 1.6185, G loss: 0.0044\n",
            "Step 2/390 - D loss: 1.6924, G loss: 0.0043\n",
            "Step 3/390 - D loss: 1.6962, G loss: 0.0043\n",
            "Step 4/390 - D loss: 1.6835, G loss: 0.0042\n",
            "Step 5/390 - D loss: 1.6541, G loss: 0.0042\n",
            "Step 6/390 - D loss: 1.6822, G loss: 0.0041\n",
            "Step 7/390 - D loss: 1.7027, G loss: 0.0040\n",
            "Step 8/390 - D loss: 1.6943, G loss: 0.0042\n",
            "Step 9/390 - D loss: 1.6637, G loss: 0.0042\n",
            "Step 10/390 - D loss: 1.6586, G loss: 0.0041\n",
            "Step 11/390 - D loss: 1.6848, G loss: 0.0043\n",
            "Step 12/390 - D loss: 1.6812, G loss: 0.0044\n",
            "Step 13/390 - D loss: 1.6856, G loss: 0.0042\n",
            "Step 14/390 - D loss: 1.6542, G loss: 0.0043\n",
            "Step 15/390 - D loss: 1.6877, G loss: 0.0044\n",
            "Step 16/390 - D loss: 1.6858, G loss: 0.0044\n",
            "Step 17/390 - D loss: 1.7357, G loss: 0.0044\n",
            "Step 18/390 - D loss: 1.6742, G loss: 0.0046\n",
            "Step 19/390 - D loss: 1.7284, G loss: 0.0046\n",
            "Step 20/390 - D loss: 1.7094, G loss: 0.0046\n",
            "Step 21/390 - D loss: 1.7095, G loss: 0.0046\n",
            "Step 22/390 - D loss: 1.7217, G loss: 0.0048\n",
            "Step 23/390 - D loss: 1.7382, G loss: 0.0048\n",
            "Step 24/390 - D loss: 1.7074, G loss: 0.0048\n",
            "Step 25/390 - D loss: 1.7137, G loss: 0.0050\n",
            "Step 26/390 - D loss: 1.7098, G loss: 0.0052\n",
            "Step 27/390 - D loss: 1.7058, G loss: 0.0052\n",
            "Step 28/390 - D loss: 1.7584, G loss: 0.0053\n",
            "Step 29/390 - D loss: 1.6989, G loss: 0.0053\n",
            "Step 30/390 - D loss: 1.7798, G loss: 0.0053\n",
            "Step 31/390 - D loss: 1.7353, G loss: 0.0054\n",
            "Step 32/390 - D loss: 1.7748, G loss: 0.0053\n",
            "Step 33/390 - D loss: 1.7929, G loss: 0.0057\n",
            "Step 34/390 - D loss: 1.7663, G loss: 0.0057\n",
            "Step 35/390 - D loss: 1.7444, G loss: 0.0058\n",
            "Step 36/390 - D loss: 1.7542, G loss: 0.0058\n",
            "Step 37/390 - D loss: 1.8082, G loss: 0.0059\n",
            "Step 38/390 - D loss: 1.8189, G loss: 0.0061\n",
            "Step 39/390 - D loss: 1.8087, G loss: 0.0059\n",
            "Step 40/390 - D loss: 1.8319, G loss: 0.0062\n",
            "Step 41/390 - D loss: 1.8392, G loss: 0.0063\n",
            "Step 42/390 - D loss: 1.8087, G loss: 0.0062\n",
            "Step 43/390 - D loss: 1.8454, G loss: 0.0064\n",
            "Step 44/390 - D loss: 1.8318, G loss: 0.0065\n",
            "Step 45/390 - D loss: 1.8917, G loss: 0.0062\n",
            "Step 46/390 - D loss: 1.8385, G loss: 0.0062\n",
            "Step 47/390 - D loss: 1.8900, G loss: 0.0062\n",
            "Step 48/390 - D loss: 1.8619, G loss: 0.0062\n",
            "Step 49/390 - D loss: 1.8797, G loss: 0.0063\n",
            "Step 50/390 - D loss: 1.8700, G loss: 0.0067\n",
            "Step 51/390 - D loss: 1.8781, G loss: 0.0066\n",
            "Step 52/390 - D loss: 1.9413, G loss: 0.0067\n",
            "Step 53/390 - D loss: 1.8703, G loss: 0.0069\n",
            "Step 54/390 - D loss: 1.9174, G loss: 0.0066\n",
            "Step 55/390 - D loss: 1.9497, G loss: 0.0064\n",
            "Step 56/390 - D loss: 1.9704, G loss: 0.0066\n",
            "Step 57/390 - D loss: 1.9671, G loss: 0.0067\n",
            "Step 58/390 - D loss: 1.9495, G loss: 0.0066\n",
            "Step 59/390 - D loss: 1.9680, G loss: 0.0065\n",
            "Step 60/390 - D loss: 1.9675, G loss: 0.0066\n",
            "Step 61/390 - D loss: 2.0141, G loss: 0.0068\n",
            "Step 62/390 - D loss: 1.9829, G loss: 0.0069\n",
            "Step 63/390 - D loss: 1.9969, G loss: 0.0066\n",
            "Step 64/390 - D loss: 1.9714, G loss: 0.0069\n",
            "Step 65/390 - D loss: 2.0169, G loss: 0.0070\n",
            "Step 66/390 - D loss: 2.0127, G loss: 0.0069\n",
            "Step 67/390 - D loss: 2.0253, G loss: 0.0071\n",
            "Step 68/390 - D loss: 2.0288, G loss: 0.0070\n",
            "Step 69/390 - D loss: 2.0080, G loss: 0.0073\n",
            "Step 70/390 - D loss: 2.0395, G loss: 0.0076\n",
            "Step 71/390 - D loss: 2.0603, G loss: 0.0074\n",
            "Step 72/390 - D loss: 2.0212, G loss: 0.0074\n",
            "Step 73/390 - D loss: 2.0801, G loss: 0.0072\n",
            "Step 74/390 - D loss: 2.0517, G loss: 0.0074\n",
            "Step 75/390 - D loss: 2.0667, G loss: 0.0075\n",
            "Step 76/390 - D loss: 2.0468, G loss: 0.0075\n",
            "Step 77/390 - D loss: 2.0876, G loss: 0.0075\n",
            "Step 78/390 - D loss: 2.0825, G loss: 0.0075\n",
            "Step 79/390 - D loss: 2.0851, G loss: 0.0072\n",
            "Step 80/390 - D loss: 2.0630, G loss: 0.0074\n",
            "Step 81/390 - D loss: 2.1189, G loss: 0.0074\n",
            "Step 82/390 - D loss: 2.1323, G loss: 0.0077\n",
            "Step 83/390 - D loss: 2.0923, G loss: 0.0074\n",
            "Step 84/390 - D loss: 2.1153, G loss: 0.0078\n",
            "Step 85/390 - D loss: 2.1463, G loss: 0.0077\n",
            "Step 86/390 - D loss: 2.1179, G loss: 0.0076\n",
            "Step 87/390 - D loss: 2.1672, G loss: 0.0074\n",
            "Step 88/390 - D loss: 2.1271, G loss: 0.0077\n",
            "Step 89/390 - D loss: 2.1679, G loss: 0.0077\n",
            "Step 90/390 - D loss: 2.1676, G loss: 0.0078\n",
            "Step 91/390 - D loss: 2.1898, G loss: 0.0077\n",
            "Step 92/390 - D loss: 2.1977, G loss: 0.0079\n",
            "Step 93/390 - D loss: 2.2051, G loss: 0.0083\n",
            "Step 94/390 - D loss: 2.1904, G loss: 0.0081\n",
            "Step 95/390 - D loss: 2.2250, G loss: 0.0080\n",
            "Step 96/390 - D loss: 2.2076, G loss: 0.0079\n",
            "Step 97/390 - D loss: 2.2321, G loss: 0.0079\n",
            "Step 98/390 - D loss: 2.2527, G loss: 0.0082\n",
            "Step 99/390 - D loss: 2.2596, G loss: 0.0078\n",
            "Step 100/390 - D loss: 2.2463, G loss: 0.0079\n",
            "Step 101/390 - D loss: 2.2843, G loss: 0.0078\n",
            "Step 102/390 - D loss: 2.2637, G loss: 0.0080\n",
            "Step 103/390 - D loss: 2.2765, G loss: 0.0076\n",
            "Step 104/390 - D loss: 2.3012, G loss: 0.0079\n",
            "Step 105/390 - D loss: 2.2952, G loss: 0.0076\n",
            "Step 106/390 - D loss: 2.3185, G loss: 0.0082\n",
            "Step 107/390 - D loss: 2.2980, G loss: 0.0080\n",
            "Step 108/390 - D loss: 2.2682, G loss: 0.0079\n",
            "Step 109/390 - D loss: 2.3283, G loss: 0.0079\n",
            "Step 110/390 - D loss: 2.3042, G loss: 0.0077\n",
            "Step 111/390 - D loss: 2.3113, G loss: 0.0075\n",
            "Step 112/390 - D loss: 2.3346, G loss: 0.0081\n",
            "Step 113/390 - D loss: 2.3416, G loss: 0.0078\n",
            "Step 114/390 - D loss: 2.3326, G loss: 0.0079\n",
            "Step 115/390 - D loss: 2.3854, G loss: 0.0077\n",
            "Step 116/390 - D loss: 2.3712, G loss: 0.0078\n",
            "Step 117/390 - D loss: 2.3715, G loss: 0.0078\n",
            "Step 118/390 - D loss: 2.3491, G loss: 0.0075\n",
            "Step 119/390 - D loss: 2.3661, G loss: 0.0079\n",
            "Step 120/390 - D loss: 2.4089, G loss: 0.0078\n",
            "Step 121/390 - D loss: 2.3710, G loss: 0.0075\n",
            "Step 122/390 - D loss: 2.3764, G loss: 0.0075\n",
            "Step 123/390 - D loss: 2.4138, G loss: 0.0077\n",
            "Step 124/390 - D loss: 2.4260, G loss: 0.0073\n",
            "Step 125/390 - D loss: 2.4236, G loss: 0.0074\n",
            "Step 126/390 - D loss: 2.4264, G loss: 0.0075\n",
            "Step 127/390 - D loss: 2.4384, G loss: 0.0072\n",
            "Step 128/390 - D loss: 2.4718, G loss: 0.0075\n",
            "Step 129/390 - D loss: 2.4451, G loss: 0.0072\n",
            "Step 130/390 - D loss: 2.4583, G loss: 0.0071\n",
            "Step 131/390 - D loss: 2.4697, G loss: 0.0074\n",
            "Step 132/390 - D loss: 2.4757, G loss: 0.0073\n",
            "Step 133/390 - D loss: 2.4588, G loss: 0.0069\n",
            "Step 134/390 - D loss: 2.4647, G loss: 0.0073\n",
            "Step 135/390 - D loss: 2.4637, G loss: 0.0069\n",
            "Step 136/390 - D loss: 2.4703, G loss: 0.0069\n",
            "Step 137/390 - D loss: 2.5114, G loss: 0.0072\n",
            "Step 138/390 - D loss: 2.4911, G loss: 0.0069\n",
            "Step 139/390 - D loss: 2.5100, G loss: 0.0070\n",
            "Step 140/390 - D loss: 2.5424, G loss: 0.0069\n",
            "Step 141/390 - D loss: 2.5234, G loss: 0.0069\n",
            "Step 142/390 - D loss: 2.5445, G loss: 0.0069\n",
            "Step 143/390 - D loss: 2.5392, G loss: 0.0069\n",
            "Step 144/390 - D loss: 2.5554, G loss: 0.0067\n",
            "Step 145/390 - D loss: 2.5070, G loss: 0.0065\n",
            "Step 146/390 - D loss: 2.5528, G loss: 0.0067\n",
            "Step 147/390 - D loss: 2.5531, G loss: 0.0065\n",
            "Step 148/390 - D loss: 2.5994, G loss: 0.0064\n",
            "Step 149/390 - D loss: 2.5873, G loss: 0.0066\n",
            "Step 150/390 - D loss: 2.6078, G loss: 0.0062\n",
            "Step 151/390 - D loss: 2.5823, G loss: 0.0061\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 152/390 - D loss: 2.5860, G loss: 0.0060\n",
            "Step 153/390 - D loss: 2.6287, G loss: 0.0061\n",
            "Step 154/390 - D loss: 2.6452, G loss: 0.0060\n",
            "Step 155/390 - D loss: 2.6190, G loss: 0.0061\n",
            "Step 156/390 - D loss: 2.6455, G loss: 0.0059\n",
            "Step 157/390 - D loss: 2.6857, G loss: 0.0056\n",
            "Step 158/390 - D loss: 2.6386, G loss: 0.0058\n",
            "Step 159/390 - D loss: 2.6687, G loss: 0.0058\n",
            "Step 160/390 - D loss: 2.6611, G loss: 0.0056\n",
            "Step 161/390 - D loss: 2.6682, G loss: 0.0057\n",
            "Step 162/390 - D loss: 2.6687, G loss: 0.0055\n",
            "Step 163/390 - D loss: 2.6321, G loss: 0.0057\n",
            "Step 164/390 - D loss: 2.6491, G loss: 0.0056\n",
            "Step 165/390 - D loss: 2.6849, G loss: 0.0055\n",
            "Step 166/390 - D loss: 2.6768, G loss: 0.0053\n",
            "Step 167/390 - D loss: 2.6758, G loss: 0.0052\n",
            "Step 168/390 - D loss: 2.6887, G loss: 0.0053\n",
            "Step 169/390 - D loss: 2.6902, G loss: 0.0052\n",
            "Step 170/390 - D loss: 2.7106, G loss: 0.0052\n",
            "Step 171/390 - D loss: 2.6990, G loss: 0.0051\n",
            "Step 172/390 - D loss: 2.6997, G loss: 0.0050\n",
            "Step 173/390 - D loss: 2.7040, G loss: 0.0051\n",
            "Step 174/390 - D loss: 2.7038, G loss: 0.0049\n",
            "Step 175/390 - D loss: 2.7149, G loss: 0.0048\n",
            "Step 176/390 - D loss: 2.7342, G loss: 0.0050\n",
            "Step 177/390 - D loss: 2.7388, G loss: 0.0048\n",
            "Step 178/390 - D loss: 2.7252, G loss: 0.0047\n",
            "Step 179/390 - D loss: 2.7496, G loss: 0.0046\n",
            "Step 180/390 - D loss: 2.7371, G loss: 0.0045\n",
            "Step 181/390 - D loss: 2.7536, G loss: 0.0046\n",
            "Step 182/390 - D loss: 2.7730, G loss: 0.0044\n",
            "Step 183/390 - D loss: 2.7716, G loss: 0.0045\n",
            "Step 184/390 - D loss: 2.7864, G loss: 0.0042\n",
            "Step 185/390 - D loss: 2.7883, G loss: 0.0041\n",
            "Step 186/390 - D loss: 2.8326, G loss: 0.0042\n",
            "Step 187/390 - D loss: 2.8413, G loss: 0.0042\n",
            "Step 188/390 - D loss: 2.8506, G loss: 0.0040\n",
            "Step 189/390 - D loss: 2.8486, G loss: 0.0039\n",
            "Step 190/390 - D loss: 2.8424, G loss: 0.0038\n",
            "Step 191/390 - D loss: 2.8898, G loss: 0.0038\n",
            "Step 192/390 - D loss: 2.8887, G loss: 0.0037\n",
            "Step 193/390 - D loss: 2.8854, G loss: 0.0036\n",
            "Step 194/390 - D loss: 2.9123, G loss: 0.0036\n",
            "Step 195/390 - D loss: 2.8919, G loss: 0.0036\n",
            "Step 196/390 - D loss: 2.9152, G loss: 0.0034\n",
            "Step 197/390 - D loss: 2.8814, G loss: 0.0036\n",
            "Step 198/390 - D loss: 2.9194, G loss: 0.0036\n",
            "Step 199/390 - D loss: 2.9215, G loss: 0.0035\n",
            "Step 200/390 - D loss: 2.8969, G loss: 0.0034\n",
            "Step 201/390 - D loss: 2.9174, G loss: 0.0035\n",
            "Step 202/390 - D loss: 2.9304, G loss: 0.0034\n",
            "Step 203/390 - D loss: 2.9333, G loss: 0.0034\n",
            "Step 204/390 - D loss: 2.9248, G loss: 0.0034\n",
            "Step 205/390 - D loss: 2.9180, G loss: 0.0034\n",
            "Step 206/390 - D loss: 2.9020, G loss: 0.0035\n",
            "Step 207/390 - D loss: 2.8994, G loss: 0.0034\n",
            "Step 208/390 - D loss: 2.8968, G loss: 0.0034\n",
            "Step 209/390 - D loss: 2.9113, G loss: 0.0034\n",
            "Step 210/390 - D loss: 2.9026, G loss: 0.0034\n",
            "Step 211/390 - D loss: 2.8897, G loss: 0.0035\n",
            "Step 212/390 - D loss: 2.8924, G loss: 0.0036\n",
            "Step 213/390 - D loss: 2.8875, G loss: 0.0034\n",
            "Step 214/390 - D loss: 2.8731, G loss: 0.0034\n",
            "Step 215/390 - D loss: 2.8933, G loss: 0.0036\n",
            "Step 216/390 - D loss: 2.8730, G loss: 0.0035\n",
            "Step 217/390 - D loss: 2.8710, G loss: 0.0035\n",
            "Step 218/390 - D loss: 2.8651, G loss: 0.0035\n",
            "Step 219/390 - D loss: 2.8480, G loss: 0.0036\n",
            "Step 220/390 - D loss: 2.8743, G loss: 0.0035\n",
            "Step 221/390 - D loss: 2.8414, G loss: 0.0037\n",
            "Step 222/390 - D loss: 2.8398, G loss: 0.0036\n",
            "Step 223/390 - D loss: 2.8365, G loss: 0.0036\n",
            "Step 224/390 - D loss: 2.8417, G loss: 0.0036\n",
            "Step 225/390 - D loss: 2.8204, G loss: 0.0037\n",
            "Step 226/390 - D loss: 2.8313, G loss: 0.0038\n",
            "Step 227/390 - D loss: 2.8214, G loss: 0.0038\n",
            "Step 228/390 - D loss: 2.8452, G loss: 0.0039\n",
            "Step 229/390 - D loss: 2.8342, G loss: 0.0039\n",
            "Step 230/390 - D loss: 2.8155, G loss: 0.0038\n",
            "Step 231/390 - D loss: 2.8170, G loss: 0.0039\n",
            "Step 232/390 - D loss: 2.8229, G loss: 0.0040\n",
            "Step 233/390 - D loss: 2.8025, G loss: 0.0040\n",
            "Step 234/390 - D loss: 2.8085, G loss: 0.0039\n",
            "Step 235/390 - D loss: 2.7893, G loss: 0.0040\n",
            "Step 236/390 - D loss: 2.8131, G loss: 0.0040\n",
            "Step 237/390 - D loss: 2.8172, G loss: 0.0041\n",
            "Step 238/390 - D loss: 2.7787, G loss: 0.0041\n",
            "Step 239/390 - D loss: 2.7802, G loss: 0.0041\n",
            "Step 240/390 - D loss: 2.7947, G loss: 0.0042\n",
            "Step 241/390 - D loss: 2.8073, G loss: 0.0042\n",
            "Step 242/390 - D loss: 2.7983, G loss: 0.0042\n",
            "Step 243/390 - D loss: 2.7891, G loss: 0.0042\n",
            "Step 244/390 - D loss: 2.8055, G loss: 0.0042\n",
            "Step 245/390 - D loss: 2.7818, G loss: 0.0043\n",
            "Step 246/390 - D loss: 2.7945, G loss: 0.0043\n",
            "Step 247/390 - D loss: 2.7808, G loss: 0.0044\n",
            "Step 248/390 - D loss: 2.7669, G loss: 0.0043\n",
            "Step 249/390 - D loss: 2.7793, G loss: 0.0045\n",
            "Step 250/390 - D loss: 2.7706, G loss: 0.0045\n",
            "Step 251/390 - D loss: 2.7564, G loss: 0.0044\n",
            "Step 252/390 - D loss: 2.7622, G loss: 0.0045\n",
            "Step 253/390 - D loss: 2.7607, G loss: 0.0045\n",
            "Step 254/390 - D loss: 2.7635, G loss: 0.0046\n",
            "Step 255/390 - D loss: 2.7742, G loss: 0.0047\n",
            "Step 256/390 - D loss: 2.7860, G loss: 0.0048\n",
            "Step 257/390 - D loss: 2.7659, G loss: 0.0046\n",
            "Step 258/390 - D loss: 2.7749, G loss: 0.0047\n",
            "Step 259/390 - D loss: 2.7595, G loss: 0.0046\n",
            "Step 260/390 - D loss: 2.7650, G loss: 0.0046\n",
            "Step 261/390 - D loss: 2.7730, G loss: 0.0046\n",
            "Step 262/390 - D loss: 2.7552, G loss: 0.0047\n",
            "Step 263/390 - D loss: 2.7706, G loss: 0.0047\n",
            "Step 264/390 - D loss: 2.7617, G loss: 0.0048\n",
            "Step 265/390 - D loss: 2.7535, G loss: 0.0048\n",
            "Step 266/390 - D loss: 2.7448, G loss: 0.0049\n",
            "Step 267/390 - D loss: 2.7639, G loss: 0.0048\n",
            "Step 268/390 - D loss: 2.7342, G loss: 0.0048\n",
            "Step 269/390 - D loss: 2.7489, G loss: 0.0048\n",
            "Step 270/390 - D loss: 2.7267, G loss: 0.0050\n",
            "Step 271/390 - D loss: 2.7561, G loss: 0.0049\n",
            "Step 272/390 - D loss: 2.7571, G loss: 0.0050\n",
            "Step 273/390 - D loss: 2.7552, G loss: 0.0049\n",
            "Step 274/390 - D loss: 2.7501, G loss: 0.0050\n",
            "Step 275/390 - D loss: 2.7589, G loss: 0.0050\n",
            "Step 276/390 - D loss: 2.7436, G loss: 0.0051\n",
            "Step 277/390 - D loss: 2.7384, G loss: 0.0049\n",
            "Step 278/390 - D loss: 2.7488, G loss: 0.0049\n",
            "Step 279/390 - D loss: 2.7380, G loss: 0.0049\n",
            "Step 280/390 - D loss: 2.7502, G loss: 0.0051\n",
            "Step 281/390 - D loss: 2.7219, G loss: 0.0050\n",
            "Step 282/390 - D loss: 2.7348, G loss: 0.0049\n",
            "Step 283/390 - D loss: 2.7193, G loss: 0.0050\n",
            "Step 284/390 - D loss: 2.7458, G loss: 0.0050\n",
            "Step 285/390 - D loss: 2.7270, G loss: 0.0051\n",
            "Step 286/390 - D loss: 2.7384, G loss: 0.0051\n",
            "Step 287/390 - D loss: 2.7502, G loss: 0.0050\n",
            "Step 288/390 - D loss: 2.7492, G loss: 0.0051\n",
            "Step 289/390 - D loss: 2.7473, G loss: 0.0051\n",
            "Step 290/390 - D loss: 2.7344, G loss: 0.0051\n",
            "Step 291/390 - D loss: 2.7263, G loss: 0.0051\n",
            "Step 292/390 - D loss: 2.7404, G loss: 0.0052\n",
            "Step 293/390 - D loss: 2.7268, G loss: 0.0051\n",
            "Step 294/390 - D loss: 2.7385, G loss: 0.0051\n",
            "Step 295/390 - D loss: 2.7567, G loss: 0.0052\n",
            "Step 296/390 - D loss: 2.7368, G loss: 0.0051\n",
            "Step 297/390 - D loss: 2.7347, G loss: 0.0051\n",
            "Step 298/390 - D loss: 2.7315, G loss: 0.0051\n",
            "Step 299/390 - D loss: 2.7478, G loss: 0.0052\n",
            "Step 300/390 - D loss: 2.7438, G loss: 0.0052\n",
            "Step 301/390 - D loss: 2.7287, G loss: 0.0052\n",
            "Step 302/390 - D loss: 2.7570, G loss: 0.0052\n",
            "Step 303/390 - D loss: 2.7310, G loss: 0.0052\n",
            "Step 304/390 - D loss: 2.7249, G loss: 0.0051\n",
            "Step 305/390 - D loss: 2.7196, G loss: 0.0052\n",
            "Step 306/390 - D loss: 2.7255, G loss: 0.0052\n",
            "Step 307/390 - D loss: 2.7465, G loss: 0.0052\n",
            "Step 308/390 - D loss: 2.7210, G loss: 0.0052\n",
            "Step 309/390 - D loss: 2.7204, G loss: 0.0053\n",
            "Step 310/390 - D loss: 2.7184, G loss: 0.0052\n",
            "Step 311/390 - D loss: 2.7293, G loss: 0.0052\n",
            "Step 312/390 - D loss: 2.7390, G loss: 0.0053\n",
            "Step 313/390 - D loss: 2.7046, G loss: 0.0054\n",
            "Step 314/390 - D loss: 2.7215, G loss: 0.0053\n",
            "Step 315/390 - D loss: 2.7114, G loss: 0.0053\n",
            "Step 316/390 - D loss: 2.7279, G loss: 0.0052\n",
            "Step 317/390 - D loss: 2.7333, G loss: 0.0053\n",
            "Step 318/390 - D loss: 2.7070, G loss: 0.0054\n",
            "Step 319/390 - D loss: 2.7366, G loss: 0.0054\n",
            "Step 320/390 - D loss: 2.7192, G loss: 0.0053\n",
            "Step 321/390 - D loss: 2.7149, G loss: 0.0054\n",
            "Step 322/390 - D loss: 2.7142, G loss: 0.0053\n",
            "Step 323/390 - D loss: 2.7316, G loss: 0.0054\n",
            "Step 324/390 - D loss: 2.7210, G loss: 0.0054\n",
            "Step 325/390 - D loss: 2.7087, G loss: 0.0055\n",
            "Step 326/390 - D loss: 2.7209, G loss: 0.0054\n",
            "Step 327/390 - D loss: 2.7137, G loss: 0.0054\n",
            "Step 328/390 - D loss: 2.7284, G loss: 0.0055\n",
            "Step 329/390 - D loss: 2.7194, G loss: 0.0056\n",
            "Step 330/390 - D loss: 2.7050, G loss: 0.0055\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 331/390 - D loss: 2.7155, G loss: 0.0055\n",
            "Step 332/390 - D loss: 2.7185, G loss: 0.0055\n",
            "Step 333/390 - D loss: 2.6902, G loss: 0.0055\n",
            "Step 334/390 - D loss: 2.7102, G loss: 0.0054\n",
            "Step 335/390 - D loss: 2.6997, G loss: 0.0055\n",
            "Step 336/390 - D loss: 2.7074, G loss: 0.0056\n",
            "Step 337/390 - D loss: 2.7156, G loss: 0.0054\n",
            "Step 338/390 - D loss: 2.7071, G loss: 0.0056\n",
            "Step 339/390 - D loss: 2.7017, G loss: 0.0056\n",
            "Step 340/390 - D loss: 2.7042, G loss: 0.0056\n",
            "Step 341/390 - D loss: 2.7124, G loss: 0.0055\n",
            "Step 342/390 - D loss: 2.6982, G loss: 0.0056\n",
            "Step 343/390 - D loss: 2.7002, G loss: 0.0057\n",
            "Step 344/390 - D loss: 2.7009, G loss: 0.0056\n",
            "Step 345/390 - D loss: 2.6865, G loss: 0.0057\n",
            "Step 346/390 - D loss: 2.6934, G loss: 0.0056\n",
            "Step 347/390 - D loss: 2.6949, G loss: 0.0056\n",
            "Step 348/390 - D loss: 2.6849, G loss: 0.0057\n",
            "Step 349/390 - D loss: 2.6961, G loss: 0.0056\n",
            "Step 350/390 - D loss: 2.6980, G loss: 0.0056\n",
            "Step 351/390 - D loss: 2.6932, G loss: 0.0056\n",
            "Step 352/390 - D loss: 2.6890, G loss: 0.0057\n",
            "Step 353/390 - D loss: 2.6928, G loss: 0.0057\n",
            "Step 354/390 - D loss: 2.6904, G loss: 0.0057\n",
            "Step 355/390 - D loss: 2.7066, G loss: 0.0058\n",
            "Step 356/390 - D loss: 2.6993, G loss: 0.0057\n",
            "Step 357/390 - D loss: 2.6913, G loss: 0.0056\n",
            "Step 358/390 - D loss: 2.6898, G loss: 0.0057\n",
            "Step 359/390 - D loss: 2.6910, G loss: 0.0057\n",
            "Step 360/390 - D loss: 2.6976, G loss: 0.0057\n",
            "Step 361/390 - D loss: 2.6967, G loss: 0.0057\n",
            "Step 362/390 - D loss: 2.6817, G loss: 0.0057\n",
            "Step 363/390 - D loss: 2.6940, G loss: 0.0057\n",
            "Step 364/390 - D loss: 2.6767, G loss: 0.0057\n",
            "Step 365/390 - D loss: 2.6898, G loss: 0.0055\n",
            "Step 366/390 - D loss: 2.6902, G loss: 0.0056\n",
            "Step 367/390 - D loss: 2.6848, G loss: 0.0056\n",
            "Step 368/390 - D loss: 2.6840, G loss: 0.0056\n",
            "Step 369/390 - D loss: 2.6928, G loss: 0.0056\n",
            "Step 370/390 - D loss: 2.7130, G loss: 0.0056\n",
            "Step 371/390 - D loss: 2.6906, G loss: 0.0057\n",
            "Step 372/390 - D loss: 2.7032, G loss: 0.0055\n",
            "Step 373/390 - D loss: 2.6882, G loss: 0.0054\n",
            "Step 374/390 - D loss: 2.7019, G loss: 0.0055\n",
            "Step 375/390 - D loss: 2.6995, G loss: 0.0055\n",
            "Step 376/390 - D loss: 2.6992, G loss: 0.0053\n",
            "Step 377/390 - D loss: 2.6934, G loss: 0.0053\n",
            "Step 378/390 - D loss: 2.6984, G loss: 0.0053\n",
            "Step 379/390 - D loss: 2.6872, G loss: 0.0053\n",
            "Step 380/390 - D loss: 2.7003, G loss: 0.0052\n",
            "Step 381/390 - D loss: 2.6912, G loss: 0.0052\n",
            "Step 382/390 - D loss: 2.7085, G loss: 0.0053\n",
            "Step 383/390 - D loss: 2.7138, G loss: 0.0051\n",
            "Step 384/390 - D loss: 2.7031, G loss: 0.0051\n",
            "Step 385/390 - D loss: 2.7152, G loss: 0.0051\n",
            "Step 386/390 - D loss: 2.7199, G loss: 0.0050\n",
            "Step 387/390 - D loss: 2.7164, G loss: 0.0051\n",
            "Step 388/390 - D loss: 2.7141, G loss: 0.0049\n",
            "Step 389/390 - D loss: 2.7352, G loss: 0.0049\n",
            "Step 390/390 - D loss: 2.7335, G loss: 0.0049\n",
            "Epoch 3/200\n",
            "Step 1/390 - D loss: 2.7439, G loss: 0.0049\n",
            "Step 2/390 - D loss: 2.7377, G loss: 0.0049\n",
            "Step 3/390 - D loss: 2.7308, G loss: 0.0049\n",
            "Step 4/390 - D loss: 2.7372, G loss: 0.0048\n",
            "Step 5/390 - D loss: 2.7348, G loss: 0.0048\n",
            "Step 6/390 - D loss: 2.7548, G loss: 0.0048\n",
            "Step 7/390 - D loss: 2.7619, G loss: 0.0048\n",
            "Step 8/390 - D loss: 2.7688, G loss: 0.0047\n",
            "Step 9/390 - D loss: 2.7618, G loss: 0.0047\n",
            "Step 10/390 - D loss: 2.7575, G loss: 0.0046\n",
            "Step 11/390 - D loss: 2.7584, G loss: 0.0046\n",
            "Step 12/390 - D loss: 2.7663, G loss: 0.0047\n",
            "Step 13/390 - D loss: 2.7656, G loss: 0.0046\n",
            "Step 14/390 - D loss: 2.7580, G loss: 0.0045\n",
            "Step 15/390 - D loss: 2.7601, G loss: 0.0045\n",
            "Step 16/390 - D loss: 2.7611, G loss: 0.0045\n",
            "Step 17/390 - D loss: 2.7701, G loss: 0.0045\n",
            "Step 18/390 - D loss: 2.7711, G loss: 0.0045\n",
            "Step 19/390 - D loss: 2.7887, G loss: 0.0044\n",
            "Step 20/390 - D loss: 2.7905, G loss: 0.0044\n",
            "Step 21/390 - D loss: 2.7946, G loss: 0.0043\n",
            "Step 22/390 - D loss: 2.8017, G loss: 0.0042\n",
            "Step 23/390 - D loss: 2.8153, G loss: 0.0041\n",
            "Step 24/390 - D loss: 2.8202, G loss: 0.0040\n",
            "Step 25/390 - D loss: 2.8414, G loss: 0.0040\n",
            "Step 26/390 - D loss: 2.8259, G loss: 0.0039\n",
            "Step 27/390 - D loss: 2.8568, G loss: 0.0039\n",
            "Step 28/390 - D loss: 2.8691, G loss: 0.0037\n",
            "Step 29/390 - D loss: 2.8800, G loss: 0.0036\n",
            "Step 30/390 - D loss: 2.8936, G loss: 0.0036\n",
            "Step 31/390 - D loss: 2.9171, G loss: 0.0035\n",
            "Step 32/390 - D loss: 2.9324, G loss: 0.0034\n",
            "Step 33/390 - D loss: 2.9551, G loss: 0.0033\n",
            "Step 34/390 - D loss: 2.9718, G loss: 0.0031\n",
            "Step 35/390 - D loss: 2.9762, G loss: 0.0030\n",
            "Step 36/390 - D loss: 2.9889, G loss: 0.0030\n",
            "Step 37/390 - D loss: 3.0007, G loss: 0.0029\n",
            "Step 38/390 - D loss: 3.0209, G loss: 0.0028\n",
            "Step 39/390 - D loss: 3.0407, G loss: 0.0027\n",
            "Step 40/390 - D loss: 3.0320, G loss: 0.0027\n",
            "Step 41/390 - D loss: 3.0815, G loss: 0.0026\n",
            "Step 42/390 - D loss: 3.0951, G loss: 0.0025\n",
            "Step 43/390 - D loss: 3.0752, G loss: 0.0025\n",
            "Step 44/390 - D loss: 3.0918, G loss: 0.0025\n",
            "Step 45/390 - D loss: 3.0847, G loss: 0.0024\n",
            "Step 46/390 - D loss: 3.1160, G loss: 0.0024\n",
            "Step 47/390 - D loss: 3.1310, G loss: 0.0024\n",
            "Step 48/390 - D loss: 3.1331, G loss: 0.0024\n",
            "Step 49/390 - D loss: 3.1111, G loss: 0.0023\n",
            "Step 50/390 - D loss: 3.1280, G loss: 0.0023\n",
            "Step 51/390 - D loss: 3.1533, G loss: 0.0023\n",
            "Step 52/390 - D loss: 3.1296, G loss: 0.0022\n",
            "Step 53/390 - D loss: 3.1168, G loss: 0.0023\n",
            "Step 54/390 - D loss: 3.1358, G loss: 0.0022\n",
            "Step 55/390 - D loss: 3.1380, G loss: 0.0022\n",
            "Step 56/390 - D loss: 3.1483, G loss: 0.0022\n",
            "Step 57/390 - D loss: 3.1609, G loss: 0.0022\n",
            "Step 58/390 - D loss: 3.1459, G loss: 0.0022\n",
            "Step 59/390 - D loss: 3.1453, G loss: 0.0022\n",
            "Step 60/390 - D loss: 3.1475, G loss: 0.0022\n",
            "Step 61/390 - D loss: 3.1584, G loss: 0.0021\n",
            "Step 62/390 - D loss: 3.1376, G loss: 0.0022\n",
            "Step 63/390 - D loss: 3.1632, G loss: 0.0021\n",
            "Step 64/390 - D loss: 3.1998, G loss: 0.0022\n",
            "Step 65/390 - D loss: 3.1467, G loss: 0.0022\n",
            "Step 66/390 - D loss: 3.1698, G loss: 0.0022\n",
            "Step 67/390 - D loss: 3.1666, G loss: 0.0022\n",
            "Step 68/390 - D loss: 3.1695, G loss: 0.0021\n",
            "Step 69/390 - D loss: 3.1815, G loss: 0.0022\n",
            "Step 70/390 - D loss: 3.1601, G loss: 0.0022\n",
            "Step 71/390 - D loss: 3.1745, G loss: 0.0022\n",
            "Step 72/390 - D loss: 3.1679, G loss: 0.0021\n",
            "Step 73/390 - D loss: 3.1691, G loss: 0.0021\n",
            "Step 74/390 - D loss: 3.1588, G loss: 0.0022\n",
            "Step 75/390 - D loss: 3.1601, G loss: 0.0021\n",
            "Step 76/390 - D loss: 3.1574, G loss: 0.0021\n",
            "Step 77/390 - D loss: 3.1822, G loss: 0.0021\n",
            "Step 78/390 - D loss: 3.1708, G loss: 0.0021\n",
            "Step 79/390 - D loss: 3.1825, G loss: 0.0022\n",
            "Step 80/390 - D loss: 3.1865, G loss: 0.0022\n",
            "Step 81/390 - D loss: 3.1741, G loss: 0.0021\n",
            "Step 82/390 - D loss: 3.1858, G loss: 0.0022\n",
            "Step 83/390 - D loss: 3.1715, G loss: 0.0021\n",
            "Step 84/390 - D loss: 3.1805, G loss: 0.0021\n",
            "Step 85/390 - D loss: 3.2058, G loss: 0.0021\n",
            "Step 86/390 - D loss: 3.2142, G loss: 0.0021\n",
            "Step 87/390 - D loss: 3.1966, G loss: 0.0021\n",
            "Step 88/390 - D loss: 3.1870, G loss: 0.0021\n",
            "Step 89/390 - D loss: 3.2044, G loss: 0.0021\n",
            "Step 90/390 - D loss: 3.1929, G loss: 0.0021\n",
            "Step 91/390 - D loss: 3.1861, G loss: 0.0021\n",
            "Step 92/390 - D loss: 3.2023, G loss: 0.0020\n",
            "Step 93/390 - D loss: 3.2103, G loss: 0.0021\n",
            "Step 94/390 - D loss: 3.1835, G loss: 0.0021\n",
            "Step 95/390 - D loss: 3.2080, G loss: 0.0020\n",
            "Step 96/390 - D loss: 3.1954, G loss: 0.0021\n",
            "Step 97/390 - D loss: 3.1928, G loss: 0.0020\n",
            "Step 98/390 - D loss: 3.1944, G loss: 0.0020\n",
            "Step 99/390 - D loss: 3.1917, G loss: 0.0021\n",
            "Step 100/390 - D loss: 3.2102, G loss: 0.0020\n",
            "Step 101/390 - D loss: 3.2141, G loss: 0.0020\n",
            "Step 102/390 - D loss: 3.2172, G loss: 0.0020\n",
            "Step 103/390 - D loss: 3.2146, G loss: 0.0019\n",
            "Step 104/390 - D loss: 3.2407, G loss: 0.0020\n",
            "Step 105/390 - D loss: 3.2542, G loss: 0.0018\n",
            "Step 106/390 - D loss: 3.2438, G loss: 0.0019\n",
            "Step 107/390 - D loss: 3.2205, G loss: 0.0018\n",
            "Step 108/390 - D loss: 3.2455, G loss: 0.0019\n",
            "Step 109/390 - D loss: 3.2493, G loss: 0.0019\n",
            "Step 110/390 - D loss: 3.2679, G loss: 0.0019\n",
            "Step 111/390 - D loss: 3.2598, G loss: 0.0018\n",
            "Step 112/390 - D loss: 3.2598, G loss: 0.0018\n",
            "Step 113/390 - D loss: 3.2550, G loss: 0.0019\n",
            "Step 114/390 - D loss: 3.2611, G loss: 0.0018\n",
            "Step 115/390 - D loss: 3.2485, G loss: 0.0018\n",
            "Step 116/390 - D loss: 3.2588, G loss: 0.0019\n",
            "Step 117/390 - D loss: 3.2442, G loss: 0.0018\n",
            "Step 118/390 - D loss: 3.2657, G loss: 0.0019\n",
            "Step 119/390 - D loss: 3.2747, G loss: 0.0018\n",
            "Step 120/390 - D loss: 3.2842, G loss: 0.0019\n",
            "Step 121/390 - D loss: 3.2581, G loss: 0.0018\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 122/390 - D loss: 3.2795, G loss: 0.0018\n",
            "Step 123/390 - D loss: 3.2391, G loss: 0.0018\n",
            "Step 124/390 - D loss: 3.2775, G loss: 0.0018\n",
            "Step 125/390 - D loss: 3.2740, G loss: 0.0018\n",
            "Step 126/390 - D loss: 3.2531, G loss: 0.0019\n",
            "Step 127/390 - D loss: 3.2525, G loss: 0.0018\n",
            "Step 128/390 - D loss: 3.2475, G loss: 0.0018\n",
            "Step 129/390 - D loss: 3.2833, G loss: 0.0019\n",
            "Step 130/390 - D loss: 3.2657, G loss: 0.0018\n",
            "Step 131/390 - D loss: 3.2656, G loss: 0.0019\n",
            "Step 132/390 - D loss: 3.2726, G loss: 0.0018\n",
            "Step 133/390 - D loss: 3.2838, G loss: 0.0018\n",
            "Step 134/390 - D loss: 3.2777, G loss: 0.0018\n",
            "Step 135/390 - D loss: 3.2800, G loss: 0.0018\n",
            "Step 136/390 - D loss: 3.2887, G loss: 0.0019\n",
            "Step 137/390 - D loss: 3.2775, G loss: 0.0018\n",
            "Step 138/390 - D loss: 3.2682, G loss: 0.0019\n",
            "Step 139/390 - D loss: 3.2725, G loss: 0.0018\n",
            "Step 140/390 - D loss: 3.2783, G loss: 0.0019\n",
            "Step 141/390 - D loss: 3.3178, G loss: 0.0019\n",
            "Step 142/390 - D loss: 3.2935, G loss: 0.0018\n",
            "Step 143/390 - D loss: 3.2957, G loss: 0.0018\n",
            "Step 144/390 - D loss: 3.2934, G loss: 0.0019\n",
            "Step 145/390 - D loss: 3.2969, G loss: 0.0018\n",
            "Step 146/390 - D loss: 3.2890, G loss: 0.0017\n",
            "Step 147/390 - D loss: 3.2778, G loss: 0.0018\n",
            "Step 148/390 - D loss: 3.2960, G loss: 0.0018\n",
            "Step 149/390 - D loss: 3.3023, G loss: 0.0018\n",
            "Step 150/390 - D loss: 3.3198, G loss: 0.0017\n",
            "Step 151/390 - D loss: 3.3139, G loss: 0.0017\n",
            "Step 152/390 - D loss: 3.3334, G loss: 0.0017\n",
            "Step 153/390 - D loss: 3.3009, G loss: 0.0017\n",
            "Step 154/390 - D loss: 3.3341, G loss: 0.0017\n",
            "Step 155/390 - D loss: 3.3353, G loss: 0.0017\n",
            "Step 156/390 - D loss: 3.3371, G loss: 0.0017\n",
            "Step 157/390 - D loss: 3.3775, G loss: 0.0016\n",
            "Step 158/390 - D loss: 3.3530, G loss: 0.0016\n",
            "Step 159/390 - D loss: 3.3721, G loss: 0.0016\n",
            "Step 160/390 - D loss: 3.3503, G loss: 0.0016\n",
            "Step 161/390 - D loss: 3.3614, G loss: 0.0015\n",
            "Step 162/390 - D loss: 3.3911, G loss: 0.0016\n",
            "Step 163/390 - D loss: 3.3733, G loss: 0.0015\n",
            "Step 164/390 - D loss: 3.3968, G loss: 0.0015\n",
            "Step 165/390 - D loss: 3.4026, G loss: 0.0015\n",
            "Step 166/390 - D loss: 3.4217, G loss: 0.0014\n",
            "Step 167/390 - D loss: 3.4227, G loss: 0.0014\n",
            "Step 168/390 - D loss: 3.4327, G loss: 0.0014\n",
            "Step 169/390 - D loss: 3.4408, G loss: 0.0014\n",
            "Step 170/390 - D loss: 3.4672, G loss: 0.0014\n",
            "Step 171/390 - D loss: 3.4406, G loss: 0.0014\n",
            "Step 172/390 - D loss: 3.4538, G loss: 0.0013\n",
            "Step 173/390 - D loss: 3.4761, G loss: 0.0013\n",
            "Step 174/390 - D loss: 3.4765, G loss: 0.0013\n",
            "Step 175/390 - D loss: 3.4886, G loss: 0.0013\n",
            "Step 176/390 - D loss: 3.4764, G loss: 0.0013\n",
            "Step 177/390 - D loss: 3.4831, G loss: 0.0012\n",
            "Step 178/390 - D loss: 3.4770, G loss: 0.0012\n",
            "Step 179/390 - D loss: 3.4941, G loss: 0.0013\n",
            "Step 180/390 - D loss: 3.4935, G loss: 0.0013\n",
            "Step 181/390 - D loss: 3.5129, G loss: 0.0012\n",
            "Step 182/390 - D loss: 3.5407, G loss: 0.0012\n",
            "Step 183/390 - D loss: 3.4989, G loss: 0.0012\n",
            "Step 184/390 - D loss: 3.5047, G loss: 0.0012\n",
            "Step 185/390 - D loss: 3.5240, G loss: 0.0012\n",
            "Step 186/390 - D loss: 3.5225, G loss: 0.0012\n",
            "Step 187/390 - D loss: 3.5256, G loss: 0.0012\n",
            "Step 188/390 - D loss: 3.5183, G loss: 0.0012\n",
            "Step 189/390 - D loss: 3.5151, G loss: 0.0012\n",
            "Step 190/390 - D loss: 3.5172, G loss: 0.0012\n",
            "Step 191/390 - D loss: 3.5215, G loss: 0.0012\n",
            "Step 192/390 - D loss: 3.5303, G loss: 0.0012\n",
            "Step 193/390 - D loss: 3.5393, G loss: 0.0012\n",
            "Step 194/390 - D loss: 3.5135, G loss: 0.0012\n",
            "Step 195/390 - D loss: 3.5320, G loss: 0.0012\n",
            "Step 196/390 - D loss: 3.5235, G loss: 0.0012\n",
            "Step 197/390 - D loss: 3.5275, G loss: 0.0012\n",
            "Step 198/390 - D loss: 3.5213, G loss: 0.0012\n",
            "Step 199/390 - D loss: 3.5371, G loss: 0.0012\n",
            "Step 200/390 - D loss: 3.5344, G loss: 0.0012\n",
            "Step 201/390 - D loss: 3.5418, G loss: 0.0012\n",
            "Step 202/390 - D loss: 3.5422, G loss: 0.0012\n",
            "Step 203/390 - D loss: 3.5156, G loss: 0.0012\n",
            "Step 204/390 - D loss: 3.5132, G loss: 0.0012\n",
            "Step 205/390 - D loss: 3.5282, G loss: 0.0013\n",
            "Step 206/390 - D loss: 3.5063, G loss: 0.0012\n",
            "Step 207/390 - D loss: 3.5435, G loss: 0.0013\n",
            "Step 208/390 - D loss: 3.5177, G loss: 0.0013\n",
            "Step 209/390 - D loss: 3.5166, G loss: 0.0013\n",
            "Step 210/390 - D loss: 3.4891, G loss: 0.0013\n",
            "Step 211/390 - D loss: 3.4968, G loss: 0.0013\n",
            "Step 212/390 - D loss: 3.5272, G loss: 0.0013\n",
            "Step 213/390 - D loss: 3.5044, G loss: 0.0013\n",
            "Step 214/390 - D loss: 3.4817, G loss: 0.0013\n",
            "Step 215/390 - D loss: 3.5220, G loss: 0.0013\n",
            "Step 216/390 - D loss: 3.5199, G loss: 0.0013\n",
            "Step 217/390 - D loss: 3.4882, G loss: 0.0013\n",
            "Step 218/390 - D loss: 3.4941, G loss: 0.0013\n",
            "Step 219/390 - D loss: 3.5055, G loss: 0.0013\n",
            "Step 220/390 - D loss: 3.4782, G loss: 0.0013\n",
            "Step 221/390 - D loss: 3.4945, G loss: 0.0014\n",
            "Step 222/390 - D loss: 3.4911, G loss: 0.0014\n",
            "Step 223/390 - D loss: 3.4899, G loss: 0.0014\n",
            "Step 224/390 - D loss: 3.4901, G loss: 0.0014\n",
            "Step 225/390 - D loss: 3.5239, G loss: 0.0014\n",
            "Step 226/390 - D loss: 3.4936, G loss: 0.0014\n",
            "Step 227/390 - D loss: 3.4900, G loss: 0.0014\n",
            "Step 228/390 - D loss: 3.4891, G loss: 0.0014\n",
            "Step 229/390 - D loss: 3.4808, G loss: 0.0014\n",
            "Step 230/390 - D loss: 3.5055, G loss: 0.0014\n",
            "Step 231/390 - D loss: 3.5014, G loss: 0.0014\n",
            "Step 232/390 - D loss: 3.4676, G loss: 0.0015\n",
            "Step 233/390 - D loss: 3.4888, G loss: 0.0015\n",
            "Step 234/390 - D loss: 3.4789, G loss: 0.0014\n",
            "Step 235/390 - D loss: 3.4898, G loss: 0.0015\n",
            "Step 236/390 - D loss: 3.4610, G loss: 0.0015\n",
            "Step 237/390 - D loss: 3.4523, G loss: 0.0015\n",
            "Step 238/390 - D loss: 3.4681, G loss: 0.0015\n",
            "Step 239/390 - D loss: 3.4736, G loss: 0.0015\n",
            "Step 240/390 - D loss: 3.4710, G loss: 0.0015\n",
            "Step 241/390 - D loss: 3.4780, G loss: 0.0015\n",
            "Step 242/390 - D loss: 3.4628, G loss: 0.0015\n",
            "Step 243/390 - D loss: 3.4652, G loss: 0.0015\n",
            "Step 244/390 - D loss: 3.4699, G loss: 0.0015\n",
            "Step 245/390 - D loss: 3.4622, G loss: 0.0015\n",
            "Step 246/390 - D loss: 3.4643, G loss: 0.0015\n",
            "Step 247/390 - D loss: 3.4398, G loss: 0.0016\n",
            "Step 248/390 - D loss: 3.4322, G loss: 0.0016\n",
            "Step 249/390 - D loss: 3.4582, G loss: 0.0016\n",
            "Step 250/390 - D loss: 3.4548, G loss: 0.0016\n",
            "Step 251/390 - D loss: 3.4524, G loss: 0.0016\n",
            "Step 252/390 - D loss: 3.4452, G loss: 0.0016\n",
            "Step 253/390 - D loss: 3.4257, G loss: 0.0016\n",
            "Step 254/390 - D loss: 3.4333, G loss: 0.0016\n",
            "Step 255/390 - D loss: 3.4638, G loss: 0.0016\n",
            "Step 256/390 - D loss: 3.4243, G loss: 0.0016\n",
            "Step 257/390 - D loss: 3.4400, G loss: 0.0016\n",
            "Step 258/390 - D loss: 3.4334, G loss: 0.0016\n",
            "Step 259/390 - D loss: 3.4250, G loss: 0.0016\n",
            "Step 260/390 - D loss: 3.4334, G loss: 0.0016\n",
            "Step 261/390 - D loss: 3.4634, G loss: 0.0016\n",
            "Step 262/390 - D loss: 3.4286, G loss: 0.0016\n",
            "Step 263/390 - D loss: 3.4172, G loss: 0.0016\n",
            "Step 264/390 - D loss: 3.4326, G loss: 0.0017\n",
            "Step 265/390 - D loss: 3.4073, G loss: 0.0016\n",
            "Step 266/390 - D loss: 3.4371, G loss: 0.0016\n",
            "Step 267/390 - D loss: 3.4285, G loss: 0.0017\n",
            "Step 268/390 - D loss: 3.4048, G loss: 0.0016\n",
            "Step 269/390 - D loss: 3.4182, G loss: 0.0017\n",
            "Step 270/390 - D loss: 3.4345, G loss: 0.0017\n",
            "Step 271/390 - D loss: 3.4172, G loss: 0.0017\n",
            "Step 272/390 - D loss: 3.4453, G loss: 0.0017\n",
            "Step 273/390 - D loss: 3.4047, G loss: 0.0017\n",
            "Step 274/390 - D loss: 3.4345, G loss: 0.0017\n",
            "Step 275/390 - D loss: 3.4056, G loss: 0.0017\n",
            "Step 276/390 - D loss: 3.4150, G loss: 0.0017\n",
            "Step 277/390 - D loss: 3.4404, G loss: 0.0017\n",
            "Step 278/390 - D loss: 3.4305, G loss: 0.0017\n",
            "Step 279/390 - D loss: 3.4000, G loss: 0.0017\n",
            "Step 280/390 - D loss: 3.4162, G loss: 0.0017\n",
            "Step 281/390 - D loss: 3.3916, G loss: 0.0017\n",
            "Step 282/390 - D loss: 3.4115, G loss: 0.0017\n",
            "Step 283/390 - D loss: 3.4171, G loss: 0.0017\n",
            "Step 284/390 - D loss: 3.4104, G loss: 0.0018\n",
            "Step 285/390 - D loss: 3.4319, G loss: 0.0017\n",
            "Step 286/390 - D loss: 3.4105, G loss: 0.0017\n",
            "Step 287/390 - D loss: 3.3901, G loss: 0.0017\n",
            "Step 288/390 - D loss: 3.4242, G loss: 0.0018\n",
            "Step 289/390 - D loss: 3.3938, G loss: 0.0017\n",
            "Step 290/390 - D loss: 3.4047, G loss: 0.0018\n",
            "Step 291/390 - D loss: 3.4002, G loss: 0.0018\n",
            "Step 292/390 - D loss: 3.4196, G loss: 0.0018\n",
            "Step 293/390 - D loss: 3.3989, G loss: 0.0018\n",
            "Step 294/390 - D loss: 3.4289, G loss: 0.0018\n",
            "Step 295/390 - D loss: 3.4182, G loss: 0.0018\n",
            "Step 296/390 - D loss: 3.3995, G loss: 0.0018\n",
            "Step 297/390 - D loss: 3.4066, G loss: 0.0018\n",
            "Step 298/390 - D loss: 3.3968, G loss: 0.0018\n",
            "Step 299/390 - D loss: 3.4072, G loss: 0.0018\n",
            "Step 300/390 - D loss: 3.4018, G loss: 0.0018\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 301/390 - D loss: 3.4052, G loss: 0.0018\n",
            "Step 302/390 - D loss: 3.3955, G loss: 0.0018\n",
            "Step 303/390 - D loss: 3.3832, G loss: 0.0018\n",
            "Step 304/390 - D loss: 3.4170, G loss: 0.0018\n",
            "Step 305/390 - D loss: 3.4131, G loss: 0.0018\n",
            "Step 306/390 - D loss: 3.4136, G loss: 0.0018\n",
            "Step 307/390 - D loss: 3.3746, G loss: 0.0018\n",
            "Step 308/390 - D loss: 3.3898, G loss: 0.0018\n",
            "Step 309/390 - D loss: 3.3919, G loss: 0.0018\n",
            "Step 310/390 - D loss: 3.3797, G loss: 0.0019\n",
            "Step 311/390 - D loss: 3.3996, G loss: 0.0018\n",
            "Step 312/390 - D loss: 3.3841, G loss: 0.0018\n",
            "Step 313/390 - D loss: 3.3886, G loss: 0.0019\n",
            "Step 314/390 - D loss: 3.3908, G loss: 0.0019\n",
            "Step 315/390 - D loss: 3.4148, G loss: 0.0019\n",
            "Step 316/390 - D loss: 3.3902, G loss: 0.0018\n",
            "Step 317/390 - D loss: 3.3924, G loss: 0.0019\n",
            "Step 318/390 - D loss: 3.3736, G loss: 0.0019\n",
            "Step 319/390 - D loss: 3.3673, G loss: 0.0019\n",
            "Step 320/390 - D loss: 3.3759, G loss: 0.0019\n",
            "Step 321/390 - D loss: 3.3861, G loss: 0.0019\n",
            "Step 322/390 - D loss: 3.3704, G loss: 0.0019\n",
            "Step 323/390 - D loss: 3.3756, G loss: 0.0019\n",
            "Step 324/390 - D loss: 3.3719, G loss: 0.0019\n",
            "Step 325/390 - D loss: 3.3775, G loss: 0.0019\n",
            "Step 326/390 - D loss: 3.3777, G loss: 0.0019\n",
            "Step 327/390 - D loss: 3.3476, G loss: 0.0019\n",
            "Step 328/390 - D loss: 3.3773, G loss: 0.0020\n",
            "Step 329/390 - D loss: 3.3554, G loss: 0.0019\n",
            "Step 330/390 - D loss: 3.3656, G loss: 0.0020\n",
            "Step 331/390 - D loss: 3.3777, G loss: 0.0020\n",
            "Step 332/390 - D loss: 3.3698, G loss: 0.0020\n",
            "Step 333/390 - D loss: 3.3614, G loss: 0.0020\n",
            "Step 334/390 - D loss: 3.3355, G loss: 0.0020\n",
            "Step 335/390 - D loss: 3.3641, G loss: 0.0020\n",
            "Step 336/390 - D loss: 3.3689, G loss: 0.0020\n",
            "Step 337/390 - D loss: 3.3508, G loss: 0.0020\n",
            "Step 338/390 - D loss: 3.3434, G loss: 0.0020\n",
            "Step 339/390 - D loss: 3.3477, G loss: 0.0020\n",
            "Step 340/390 - D loss: 3.3661, G loss: 0.0020\n",
            "Step 341/390 - D loss: 3.3640, G loss: 0.0020\n",
            "Step 342/390 - D loss: 3.3507, G loss: 0.0020\n",
            "Step 343/390 - D loss: 3.3572, G loss: 0.0021\n",
            "Step 344/390 - D loss: 3.3512, G loss: 0.0020\n",
            "Step 345/390 - D loss: 3.3708, G loss: 0.0020\n",
            "Step 346/390 - D loss: 3.3578, G loss: 0.0021\n",
            "Step 347/390 - D loss: 3.3537, G loss: 0.0020\n",
            "Step 348/390 - D loss: 3.3570, G loss: 0.0021\n",
            "Step 349/390 - D loss: 3.3596, G loss: 0.0021\n",
            "Step 350/390 - D loss: 3.3526, G loss: 0.0021\n",
            "Step 351/390 - D loss: 3.3586, G loss: 0.0021\n",
            "Step 352/390 - D loss: 3.3486, G loss: 0.0021\n",
            "Step 353/390 - D loss: 3.3276, G loss: 0.0021\n",
            "Step 354/390 - D loss: 3.3430, G loss: 0.0021\n",
            "Step 355/390 - D loss: 3.3431, G loss: 0.0021\n",
            "Step 356/390 - D loss: 3.3445, G loss: 0.0021\n",
            "Step 357/390 - D loss: 3.3344, G loss: 0.0021\n",
            "Step 358/390 - D loss: 3.3169, G loss: 0.0021\n",
            "Step 359/390 - D loss: 3.3519, G loss: 0.0021\n",
            "Step 360/390 - D loss: 3.3358, G loss: 0.0021\n",
            "Step 361/390 - D loss: 3.3395, G loss: 0.0022\n",
            "Step 362/390 - D loss: 3.3438, G loss: 0.0022\n",
            "Step 363/390 - D loss: 3.3351, G loss: 0.0021\n",
            "Step 364/390 - D loss: 3.3192, G loss: 0.0022\n",
            "Step 365/390 - D loss: 3.3218, G loss: 0.0021\n",
            "Step 366/390 - D loss: 3.3426, G loss: 0.0021\n",
            "Step 367/390 - D loss: 3.3303, G loss: 0.0022\n",
            "Step 368/390 - D loss: 3.3376, G loss: 0.0022\n",
            "Step 369/390 - D loss: 3.3118, G loss: 0.0021\n",
            "Step 370/390 - D loss: 3.3391, G loss: 0.0022\n",
            "Step 371/390 - D loss: 3.3225, G loss: 0.0022\n",
            "Step 372/390 - D loss: 3.3387, G loss: 0.0022\n",
            "Step 373/390 - D loss: 3.3075, G loss: 0.0022\n",
            "Step 374/390 - D loss: 3.3251, G loss: 0.0022\n",
            "Step 375/390 - D loss: 3.3332, G loss: 0.0022\n",
            "Step 376/390 - D loss: 3.2948, G loss: 0.0022\n",
            "Step 377/390 - D loss: 3.3206, G loss: 0.0022\n",
            "Step 378/390 - D loss: 3.3370, G loss: 0.0022\n",
            "Step 379/390 - D loss: 3.3130, G loss: 0.0022\n",
            "Step 380/390 - D loss: 3.3036, G loss: 0.0022\n",
            "Step 381/390 - D loss: 3.3129, G loss: 0.0022\n",
            "Step 382/390 - D loss: 3.3020, G loss: 0.0022\n",
            "Step 383/390 - D loss: 3.2992, G loss: 0.0022\n",
            "Step 384/390 - D loss: 3.3265, G loss: 0.0023\n",
            "Step 385/390 - D loss: 3.2934, G loss: 0.0023\n",
            "Step 386/390 - D loss: 3.3109, G loss: 0.0022\n",
            "Step 387/390 - D loss: 3.3153, G loss: 0.0022\n",
            "Step 388/390 - D loss: 3.3284, G loss: 0.0022\n",
            "Step 389/390 - D loss: 3.3072, G loss: 0.0023\n",
            "Step 390/390 - D loss: 3.3084, G loss: 0.0023\n",
            "Epoch 4/200\n",
            "Step 1/390 - D loss: 3.3116, G loss: 0.0023\n",
            "Step 2/390 - D loss: 3.2929, G loss: 0.0023\n",
            "Step 3/390 - D loss: 3.2982, G loss: 0.0023\n",
            "Step 4/390 - D loss: 3.2883, G loss: 0.0023\n",
            "Step 5/390 - D loss: 3.2937, G loss: 0.0023\n",
            "Step 6/390 - D loss: 3.2838, G loss: 0.0023\n",
            "Step 7/390 - D loss: 3.2895, G loss: 0.0023\n",
            "Step 8/390 - D loss: 3.2908, G loss: 0.0023\n",
            "Step 9/390 - D loss: 3.3070, G loss: 0.0023\n",
            "Step 10/390 - D loss: 3.2679, G loss: 0.0023\n",
            "Step 11/390 - D loss: 3.2882, G loss: 0.0023\n",
            "Step 12/390 - D loss: 3.3135, G loss: 0.0023\n",
            "Step 13/390 - D loss: 3.3004, G loss: 0.0023\n",
            "Step 14/390 - D loss: 3.3100, G loss: 0.0023\n",
            "Step 15/390 - D loss: 3.2857, G loss: 0.0023\n",
            "Step 16/390 - D loss: 3.2790, G loss: 0.0023\n",
            "Step 17/390 - D loss: 3.2845, G loss: 0.0023\n",
            "Step 18/390 - D loss: 3.2995, G loss: 0.0023\n",
            "Step 19/390 - D loss: 3.2978, G loss: 0.0023\n",
            "Step 20/390 - D loss: 3.3054, G loss: 0.0024\n",
            "Step 21/390 - D loss: 3.3037, G loss: 0.0024\n",
            "Step 22/390 - D loss: 3.3048, G loss: 0.0023\n",
            "Step 23/390 - D loss: 3.2737, G loss: 0.0023\n",
            "Step 24/390 - D loss: 3.3024, G loss: 0.0023\n",
            "Step 25/390 - D loss: 3.2922, G loss: 0.0024\n",
            "Step 26/390 - D loss: 3.2900, G loss: 0.0024\n",
            "Step 27/390 - D loss: 3.2948, G loss: 0.0024\n",
            "Step 28/390 - D loss: 3.2560, G loss: 0.0024\n",
            "Step 29/390 - D loss: 3.2876, G loss: 0.0024\n",
            "Step 30/390 - D loss: 3.2699, G loss: 0.0024\n",
            "Step 31/390 - D loss: 3.2590, G loss: 0.0024\n",
            "Step 32/390 - D loss: 3.2782, G loss: 0.0024\n",
            "Step 33/390 - D loss: 3.2632, G loss: 0.0024\n",
            "Step 34/390 - D loss: 3.2767, G loss: 0.0024\n",
            "Step 35/390 - D loss: 3.2681, G loss: 0.0024\n",
            "Step 36/390 - D loss: 3.2709, G loss: 0.0024\n",
            "Step 37/390 - D loss: 3.2681, G loss: 0.0024\n",
            "Step 38/390 - D loss: 3.2664, G loss: 0.0024\n",
            "Step 39/390 - D loss: 3.3042, G loss: 0.0024\n",
            "Step 40/390 - D loss: 3.2584, G loss: 0.0024\n",
            "Step 41/390 - D loss: 3.2464, G loss: 0.0024\n",
            "Step 42/390 - D loss: 3.2808, G loss: 0.0024\n",
            "Step 43/390 - D loss: 3.2637, G loss: 0.0024\n",
            "Step 44/390 - D loss: 3.2726, G loss: 0.0024\n",
            "Step 45/390 - D loss: 3.2552, G loss: 0.0024\n",
            "Step 46/390 - D loss: 3.2518, G loss: 0.0024\n",
            "Step 47/390 - D loss: 3.2847, G loss: 0.0024\n",
            "Step 48/390 - D loss: 3.2774, G loss: 0.0025\n",
            "Step 49/390 - D loss: 3.2516, G loss: 0.0024\n",
            "Step 50/390 - D loss: 3.2962, G loss: 0.0024\n",
            "Step 51/390 - D loss: 3.2887, G loss: 0.0024\n",
            "Step 52/390 - D loss: 3.2823, G loss: 0.0024\n",
            "Step 53/390 - D loss: 3.2734, G loss: 0.0024\n",
            "Step 54/390 - D loss: 3.2693, G loss: 0.0024\n",
            "Step 55/390 - D loss: 3.2553, G loss: 0.0024\n",
            "Step 56/390 - D loss: 3.2913, G loss: 0.0024\n",
            "Step 57/390 - D loss: 3.2944, G loss: 0.0024\n",
            "Step 58/390 - D loss: 3.2533, G loss: 0.0024\n",
            "Step 59/390 - D loss: 3.2491, G loss: 0.0024\n",
            "Step 60/390 - D loss: 3.2941, G loss: 0.0024\n",
            "Step 61/390 - D loss: 3.2772, G loss: 0.0024\n",
            "Step 62/390 - D loss: 3.2891, G loss: 0.0024\n",
            "Step 63/390 - D loss: 3.2759, G loss: 0.0024\n",
            "Step 64/390 - D loss: 3.2916, G loss: 0.0024\n",
            "Step 65/390 - D loss: 3.2676, G loss: 0.0024\n",
            "Step 66/390 - D loss: 3.3008, G loss: 0.0024\n",
            "Step 67/390 - D loss: 3.2546, G loss: 0.0024\n",
            "Step 68/390 - D loss: 3.2714, G loss: 0.0024\n",
            "Step 69/390 - D loss: 3.2840, G loss: 0.0024\n",
            "Step 70/390 - D loss: 3.2789, G loss: 0.0024\n",
            "Step 71/390 - D loss: 3.2675, G loss: 0.0024\n",
            "Step 72/390 - D loss: 3.2634, G loss: 0.0023\n",
            "Step 73/390 - D loss: 3.2992, G loss: 0.0024\n",
            "Step 74/390 - D loss: 3.2751, G loss: 0.0023\n",
            "Step 75/390 - D loss: 3.2889, G loss: 0.0023\n",
            "Step 76/390 - D loss: 3.3005, G loss: 0.0023\n",
            "Step 77/390 - D loss: 3.2981, G loss: 0.0023\n",
            "Step 78/390 - D loss: 3.3129, G loss: 0.0023\n",
            "Step 79/390 - D loss: 3.2883, G loss: 0.0023\n",
            "Step 80/390 - D loss: 3.3178, G loss: 0.0022\n",
            "Step 81/390 - D loss: 3.3339, G loss: 0.0022\n",
            "Step 82/390 - D loss: 3.3129, G loss: 0.0022\n",
            "Step 83/390 - D loss: 3.3241, G loss: 0.0022\n",
            "Step 84/390 - D loss: 3.3250, G loss: 0.0022\n",
            "Step 85/390 - D loss: 3.3112, G loss: 0.0022\n",
            "Step 86/390 - D loss: 3.3373, G loss: 0.0021\n",
            "Step 87/390 - D loss: 3.3078, G loss: 0.0021\n",
            "Step 88/390 - D loss: 3.3557, G loss: 0.0021\n",
            "Step 89/390 - D loss: 3.3597, G loss: 0.0021\n",
            "Step 90/390 - D loss: 3.3532, G loss: 0.0021\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 91/390 - D loss: 3.3318, G loss: 0.0021\n",
            "Step 92/390 - D loss: 3.3539, G loss: 0.0021\n",
            "Step 93/390 - D loss: 3.3410, G loss: 0.0020\n",
            "Step 94/390 - D loss: 3.3515, G loss: 0.0020\n",
            "Step 95/390 - D loss: 3.3779, G loss: 0.0020\n",
            "Step 96/390 - D loss: 3.3767, G loss: 0.0020\n",
            "Step 97/390 - D loss: 3.3612, G loss: 0.0019\n",
            "Step 98/390 - D loss: 3.3841, G loss: 0.0019\n",
            "Step 99/390 - D loss: 3.3752, G loss: 0.0019\n",
            "Step 100/390 - D loss: 3.3820, G loss: 0.0019\n",
            "Step 101/390 - D loss: 3.4140, G loss: 0.0019\n",
            "Step 102/390 - D loss: 3.4133, G loss: 0.0019\n",
            "Step 103/390 - D loss: 3.4017, G loss: 0.0019\n",
            "Step 104/390 - D loss: 3.3749, G loss: 0.0018\n",
            "Step 105/390 - D loss: 3.4532, G loss: 0.0019\n",
            "Step 106/390 - D loss: 3.3935, G loss: 0.0019\n",
            "Step 107/390 - D loss: 3.4072, G loss: 0.0019\n",
            "Step 108/390 - D loss: 3.4209, G loss: 0.0018\n",
            "Step 109/390 - D loss: 3.4291, G loss: 0.0018\n",
            "Step 110/390 - D loss: 3.4177, G loss: 0.0018\n",
            "Step 111/390 - D loss: 3.3961, G loss: 0.0018\n",
            "Step 112/390 - D loss: 3.4374, G loss: 0.0018\n",
            "Step 113/390 - D loss: 3.4092, G loss: 0.0018\n",
            "Step 114/390 - D loss: 3.4131, G loss: 0.0018\n",
            "Step 115/390 - D loss: 3.4141, G loss: 0.0018\n",
            "Step 116/390 - D loss: 3.3886, G loss: 0.0018\n",
            "Step 117/390 - D loss: 3.4181, G loss: 0.0018\n",
            "Step 118/390 - D loss: 3.4083, G loss: 0.0018\n",
            "Step 119/390 - D loss: 3.4405, G loss: 0.0018\n",
            "Step 120/390 - D loss: 3.4146, G loss: 0.0018\n",
            "Step 121/390 - D loss: 3.4395, G loss: 0.0018\n",
            "Step 122/390 - D loss: 3.3932, G loss: 0.0018\n",
            "Step 123/390 - D loss: 3.4378, G loss: 0.0018\n",
            "Step 124/390 - D loss: 3.4218, G loss: 0.0018\n",
            "Step 125/390 - D loss: 3.4459, G loss: 0.0018\n",
            "Step 126/390 - D loss: 3.4219, G loss: 0.0018\n",
            "Step 127/390 - D loss: 3.4237, G loss: 0.0018\n",
            "Step 128/390 - D loss: 3.4129, G loss: 0.0018\n",
            "Step 129/390 - D loss: 3.4248, G loss: 0.0018\n",
            "Step 130/390 - D loss: 3.4235, G loss: 0.0018\n",
            "Step 131/390 - D loss: 3.4254, G loss: 0.0018\n",
            "Step 132/390 - D loss: 3.4450, G loss: 0.0018\n",
            "Step 133/390 - D loss: 3.4274, G loss: 0.0018\n",
            "Step 134/390 - D loss: 3.4230, G loss: 0.0018\n",
            "Step 135/390 - D loss: 3.4372, G loss: 0.0018\n",
            "Step 136/390 - D loss: 3.4152, G loss: 0.0018\n",
            "Step 137/390 - D loss: 3.4378, G loss: 0.0018\n",
            "Step 138/390 - D loss: 3.4252, G loss: 0.0017\n",
            "Step 139/390 - D loss: 3.4219, G loss: 0.0018\n",
            "Step 140/390 - D loss: 3.4330, G loss: 0.0018\n",
            "Step 141/390 - D loss: 3.4318, G loss: 0.0018\n",
            "Step 142/390 - D loss: 3.4477, G loss: 0.0018\n",
            "Step 143/390 - D loss: 3.4314, G loss: 0.0018\n",
            "Step 144/390 - D loss: 3.4328, G loss: 0.0017\n",
            "Step 145/390 - D loss: 3.4435, G loss: 0.0018\n",
            "Step 146/390 - D loss: 3.4573, G loss: 0.0018\n",
            "Step 147/390 - D loss: 3.4396, G loss: 0.0018\n",
            "Step 148/390 - D loss: 3.4251, G loss: 0.0017\n",
            "Step 149/390 - D loss: 3.4299, G loss: 0.0018\n",
            "Step 150/390 - D loss: 3.4218, G loss: 0.0017\n",
            "Step 151/390 - D loss: 3.4445, G loss: 0.0018\n",
            "Step 152/390 - D loss: 3.4156, G loss: 0.0018\n",
            "Step 153/390 - D loss: 3.4389, G loss: 0.0017\n",
            "Step 154/390 - D loss: 3.4239, G loss: 0.0018\n",
            "Step 155/390 - D loss: 3.4312, G loss: 0.0017\n",
            "Step 156/390 - D loss: 3.4336, G loss: 0.0018\n",
            "Step 157/390 - D loss: 3.3998, G loss: 0.0018\n",
            "Step 158/390 - D loss: 3.4221, G loss: 0.0018\n",
            "Step 159/390 - D loss: 3.4273, G loss: 0.0018\n",
            "Step 160/390 - D loss: 3.4021, G loss: 0.0018\n",
            "Step 161/390 - D loss: 3.4485, G loss: 0.0018\n",
            "Step 162/390 - D loss: 3.4305, G loss: 0.0017\n",
            "Step 163/390 - D loss: 3.4306, G loss: 0.0018\n",
            "Step 164/390 - D loss: 3.4267, G loss: 0.0018\n",
            "Step 165/390 - D loss: 3.4060, G loss: 0.0018\n",
            "Step 166/390 - D loss: 3.4439, G loss: 0.0018\n",
            "Step 167/390 - D loss: 3.4232, G loss: 0.0018\n",
            "Step 168/390 - D loss: 3.4100, G loss: 0.0018\n",
            "Step 169/390 - D loss: 3.4372, G loss: 0.0018\n",
            "Step 170/390 - D loss: 3.4381, G loss: 0.0018\n",
            "Step 171/390 - D loss: 3.4410, G loss: 0.0018\n",
            "Step 172/390 - D loss: 3.4260, G loss: 0.0018\n",
            "Step 173/390 - D loss: 3.4326, G loss: 0.0018\n",
            "Step 174/390 - D loss: 3.4257, G loss: 0.0018\n",
            "Step 175/390 - D loss: 3.4162, G loss: 0.0018\n",
            "Step 176/390 - D loss: 3.4122, G loss: 0.0018\n",
            "Step 177/390 - D loss: 3.4238, G loss: 0.0018\n",
            "Step 178/390 - D loss: 3.4230, G loss: 0.0018\n",
            "Step 179/390 - D loss: 3.3972, G loss: 0.0018\n",
            "Step 180/390 - D loss: 3.4335, G loss: 0.0018\n",
            "Step 181/390 - D loss: 3.4189, G loss: 0.0018\n",
            "Step 182/390 - D loss: 3.4103, G loss: 0.0018\n",
            "Step 183/390 - D loss: 3.4252, G loss: 0.0018\n",
            "Step 184/390 - D loss: 3.4003, G loss: 0.0018\n",
            "Step 185/390 - D loss: 3.4015, G loss: 0.0018\n",
            "Step 186/390 - D loss: 3.4232, G loss: 0.0018\n",
            "Step 187/390 - D loss: 3.4158, G loss: 0.0018\n",
            "Step 188/390 - D loss: 3.4269, G loss: 0.0018\n",
            "Step 189/390 - D loss: 3.4056, G loss: 0.0018\n",
            "Step 190/390 - D loss: 3.4276, G loss: 0.0018\n",
            "Step 191/390 - D loss: 3.4184, G loss: 0.0018\n",
            "Step 192/390 - D loss: 3.4148, G loss: 0.0018\n",
            "Step 193/390 - D loss: 3.4095, G loss: 0.0018\n",
            "Step 194/390 - D loss: 3.4097, G loss: 0.0018\n",
            "Step 195/390 - D loss: 3.4119, G loss: 0.0018\n",
            "Step 196/390 - D loss: 3.4115, G loss: 0.0018\n",
            "Step 197/390 - D loss: 3.4059, G loss: 0.0018\n",
            "Step 198/390 - D loss: 3.4110, G loss: 0.0018\n",
            "Step 199/390 - D loss: 3.4280, G loss: 0.0018\n",
            "Step 200/390 - D loss: 3.4082, G loss: 0.0018\n",
            "Step 201/390 - D loss: 3.3813, G loss: 0.0018\n",
            "Step 202/390 - D loss: 3.3950, G loss: 0.0018\n",
            "Step 203/390 - D loss: 3.4334, G loss: 0.0018\n",
            "Step 204/390 - D loss: 3.4197, G loss: 0.0019\n",
            "Step 205/390 - D loss: 3.3939, G loss: 0.0019\n",
            "Step 206/390 - D loss: 3.4095, G loss: 0.0018\n",
            "Step 207/390 - D loss: 3.3987, G loss: 0.0018\n",
            "Step 208/390 - D loss: 3.3948, G loss: 0.0018\n",
            "Step 209/390 - D loss: 3.3831, G loss: 0.0018\n",
            "Step 210/390 - D loss: 3.4133, G loss: 0.0018\n",
            "Step 211/390 - D loss: 3.3957, G loss: 0.0018\n",
            "Step 212/390 - D loss: 3.3942, G loss: 0.0018\n",
            "Step 213/390 - D loss: 3.4052, G loss: 0.0019\n",
            "Step 214/390 - D loss: 3.3719, G loss: 0.0019\n",
            "Step 215/390 - D loss: 3.4054, G loss: 0.0018\n",
            "Step 216/390 - D loss: 3.3744, G loss: 0.0018\n",
            "Step 217/390 - D loss: 3.4100, G loss: 0.0019\n",
            "Step 218/390 - D loss: 3.4080, G loss: 0.0018\n",
            "Step 219/390 - D loss: 3.4058, G loss: 0.0019\n",
            "Step 220/390 - D loss: 3.3999, G loss: 0.0019\n",
            "Step 221/390 - D loss: 3.3888, G loss: 0.0019\n",
            "Step 222/390 - D loss: 3.3949, G loss: 0.0019\n",
            "Step 223/390 - D loss: 3.4213, G loss: 0.0019\n",
            "Step 224/390 - D loss: 3.4007, G loss: 0.0019\n",
            "Step 225/390 - D loss: 3.3967, G loss: 0.0019\n",
            "Step 226/390 - D loss: 3.3930, G loss: 0.0019\n",
            "Step 227/390 - D loss: 3.3841, G loss: 0.0019\n",
            "Step 228/390 - D loss: 3.3895, G loss: 0.0019\n",
            "Step 229/390 - D loss: 3.3943, G loss: 0.0019\n",
            "Step 230/390 - D loss: 3.3729, G loss: 0.0019\n",
            "Step 231/390 - D loss: 3.3938, G loss: 0.0019\n",
            "Step 232/390 - D loss: 3.3782, G loss: 0.0019\n",
            "Step 233/390 - D loss: 3.3758, G loss: 0.0019\n",
            "Step 234/390 - D loss: 3.3861, G loss: 0.0019\n",
            "Step 235/390 - D loss: 3.3888, G loss: 0.0019\n",
            "Step 236/390 - D loss: 3.3790, G loss: 0.0019\n",
            "Step 237/390 - D loss: 3.3798, G loss: 0.0020\n",
            "Step 238/390 - D loss: 3.3775, G loss: 0.0019\n",
            "Step 239/390 - D loss: 3.3779, G loss: 0.0020\n",
            "Step 240/390 - D loss: 3.3557, G loss: 0.0019\n",
            "Step 241/390 - D loss: 3.3963, G loss: 0.0019\n",
            "Step 242/390 - D loss: 3.3593, G loss: 0.0020\n",
            "Step 243/390 - D loss: 3.3748, G loss: 0.0020\n",
            "Step 244/390 - D loss: 3.3563, G loss: 0.0019\n",
            "Step 245/390 - D loss: 3.3633, G loss: 0.0020\n",
            "Step 246/390 - D loss: 3.3754, G loss: 0.0020\n",
            "Step 247/390 - D loss: 3.3718, G loss: 0.0020\n",
            "Step 248/390 - D loss: 3.3636, G loss: 0.0020\n",
            "Step 249/390 - D loss: 3.3680, G loss: 0.0020\n",
            "Step 250/390 - D loss: 3.3496, G loss: 0.0020\n",
            "Step 251/390 - D loss: 3.3684, G loss: 0.0020\n",
            "Step 252/390 - D loss: 3.3587, G loss: 0.0020\n",
            "Step 253/390 - D loss: 3.3887, G loss: 0.0020\n",
            "Step 254/390 - D loss: 3.3627, G loss: 0.0020\n",
            "Step 255/390 - D loss: 3.3564, G loss: 0.0020\n",
            "Step 256/390 - D loss: 3.3667, G loss: 0.0020\n",
            "Step 257/390 - D loss: 3.3636, G loss: 0.0020\n",
            "Step 258/390 - D loss: 3.3651, G loss: 0.0020\n",
            "Step 259/390 - D loss: 3.3631, G loss: 0.0020\n",
            "Step 260/390 - D loss: 3.3687, G loss: 0.0020\n",
            "Step 261/390 - D loss: 3.3617, G loss: 0.0020\n",
            "Step 262/390 - D loss: 3.3517, G loss: 0.0020\n",
            "Step 263/390 - D loss: 3.3603, G loss: 0.0020\n",
            "Step 264/390 - D loss: 3.3598, G loss: 0.0020\n",
            "Step 265/390 - D loss: 3.3316, G loss: 0.0020\n",
            "Step 266/390 - D loss: 3.3490, G loss: 0.0020\n",
            "Step 267/390 - D loss: 3.3579, G loss: 0.0020\n",
            "Step 268/390 - D loss: 3.3666, G loss: 0.0020\n",
            "Step 269/390 - D loss: 3.3489, G loss: 0.0020\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 270/390 - D loss: 3.3344, G loss: 0.0020\n",
            "Step 271/390 - D loss: 3.3432, G loss: 0.0021\n",
            "Step 272/390 - D loss: 3.3462, G loss: 0.0021\n",
            "Step 273/390 - D loss: 3.3719, G loss: 0.0021\n",
            "Step 274/390 - D loss: 3.3514, G loss: 0.0021\n",
            "Step 275/390 - D loss: 3.3303, G loss: 0.0021\n",
            "Step 276/390 - D loss: 3.3641, G loss: 0.0021\n",
            "Step 277/390 - D loss: 3.3456, G loss: 0.0021\n",
            "Step 278/390 - D loss: 3.3555, G loss: 0.0021\n",
            "Step 279/390 - D loss: 3.3371, G loss: 0.0021\n",
            "Step 280/390 - D loss: 3.3130, G loss: 0.0021\n",
            "Step 281/390 - D loss: 3.3607, G loss: 0.0021\n",
            "Step 282/390 - D loss: 3.3220, G loss: 0.0021\n",
            "Step 283/390 - D loss: 3.3382, G loss: 0.0021\n",
            "Step 284/390 - D loss: 3.3224, G loss: 0.0021\n",
            "Step 285/390 - D loss: 3.3517, G loss: 0.0021\n",
            "Step 286/390 - D loss: 3.3266, G loss: 0.0021\n",
            "Step 287/390 - D loss: 3.3245, G loss: 0.0021\n",
            "Step 288/390 - D loss: 3.3372, G loss: 0.0021\n",
            "Step 289/390 - D loss: 3.3092, G loss: 0.0021\n",
            "Step 290/390 - D loss: 3.3384, G loss: 0.0021\n",
            "Step 291/390 - D loss: 3.3197, G loss: 0.0021\n",
            "Step 292/390 - D loss: 3.3178, G loss: 0.0021\n",
            "Step 293/390 - D loss: 3.3293, G loss: 0.0021\n",
            "Step 294/390 - D loss: 3.3157, G loss: 0.0021\n",
            "Step 295/390 - D loss: 3.3047, G loss: 0.0021\n",
            "Step 296/390 - D loss: 3.3470, G loss: 0.0021\n",
            "Step 297/390 - D loss: 3.3261, G loss: 0.0021\n",
            "Step 298/390 - D loss: 3.3266, G loss: 0.0021\n",
            "Step 299/390 - D loss: 3.3131, G loss: 0.0021\n",
            "Step 300/390 - D loss: 3.3286, G loss: 0.0021\n",
            "Step 301/390 - D loss: 3.3220, G loss: 0.0021\n",
            "Step 302/390 - D loss: 3.3176, G loss: 0.0022\n",
            "Step 303/390 - D loss: 3.3174, G loss: 0.0021\n",
            "Step 304/390 - D loss: 3.3022, G loss: 0.0021\n",
            "Step 305/390 - D loss: 3.3258, G loss: 0.0021\n",
            "Step 306/390 - D loss: 3.2959, G loss: 0.0022\n",
            "Step 307/390 - D loss: 3.3121, G loss: 0.0021\n",
            "Step 308/390 - D loss: 3.3316, G loss: 0.0021\n",
            "Step 309/390 - D loss: 3.3111, G loss: 0.0021\n",
            "Step 310/390 - D loss: 3.3375, G loss: 0.0021\n",
            "Step 311/390 - D loss: 3.3173, G loss: 0.0022\n",
            "Step 312/390 - D loss: 3.3174, G loss: 0.0022\n",
            "Step 313/390 - D loss: 3.3250, G loss: 0.0022\n",
            "Step 314/390 - D loss: 3.3077, G loss: 0.0022\n",
            "Step 315/390 - D loss: 3.3071, G loss: 0.0022\n",
            "Step 316/390 - D loss: 3.3103, G loss: 0.0022\n",
            "Step 317/390 - D loss: 3.3160, G loss: 0.0022\n",
            "Step 318/390 - D loss: 3.3070, G loss: 0.0022\n",
            "Step 319/390 - D loss: 3.3152, G loss: 0.0022\n",
            "Step 320/390 - D loss: 3.3047, G loss: 0.0022\n",
            "Step 321/390 - D loss: 3.3120, G loss: 0.0022\n",
            "Step 322/390 - D loss: 3.2951, G loss: 0.0022\n",
            "Step 323/390 - D loss: 3.3235, G loss: 0.0022\n",
            "Step 324/390 - D loss: 3.2870, G loss: 0.0022\n",
            "Step 325/390 - D loss: 3.3054, G loss: 0.0022\n",
            "Step 326/390 - D loss: 3.2958, G loss: 0.0022\n",
            "Step 327/390 - D loss: 3.3065, G loss: 0.0022\n",
            "Step 328/390 - D loss: 3.2942, G loss: 0.0022\n",
            "Step 329/390 - D loss: 3.2974, G loss: 0.0022\n",
            "Step 330/390 - D loss: 3.3095, G loss: 0.0022\n",
            "Step 331/390 - D loss: 3.2929, G loss: 0.0022\n",
            "Step 332/390 - D loss: 3.3158, G loss: 0.0022\n",
            "Step 333/390 - D loss: 3.3121, G loss: 0.0022\n",
            "Step 334/390 - D loss: 3.3004, G loss: 0.0022\n",
            "Step 335/390 - D loss: 3.2864, G loss: 0.0022\n",
            "Step 336/390 - D loss: 3.2899, G loss: 0.0022\n",
            "Step 337/390 - D loss: 3.2956, G loss: 0.0022\n",
            "Step 338/390 - D loss: 3.2934, G loss: 0.0022\n",
            "Step 339/390 - D loss: 3.3016, G loss: 0.0022\n",
            "Step 340/390 - D loss: 3.2974, G loss: 0.0022\n",
            "Step 341/390 - D loss: 3.3308, G loss: 0.0022\n",
            "Step 342/390 - D loss: 3.2830, G loss: 0.0022\n",
            "Step 343/390 - D loss: 3.3088, G loss: 0.0022\n",
            "Step 344/390 - D loss: 3.2971, G loss: 0.0023\n",
            "Step 345/390 - D loss: 3.2970, G loss: 0.0023\n",
            "Step 346/390 - D loss: 3.2881, G loss: 0.0022\n",
            "Step 347/390 - D loss: 3.2871, G loss: 0.0022\n",
            "Step 348/390 - D loss: 3.2978, G loss: 0.0022\n",
            "Step 349/390 - D loss: 3.2842, G loss: 0.0022\n",
            "Step 350/390 - D loss: 3.2932, G loss: 0.0023\n",
            "Step 351/390 - D loss: 3.2874, G loss: 0.0023\n",
            "Step 352/390 - D loss: 3.3065, G loss: 0.0023\n",
            "Step 353/390 - D loss: 3.2650, G loss: 0.0023\n",
            "Step 354/390 - D loss: 3.2915, G loss: 0.0023\n",
            "Step 355/390 - D loss: 3.2929, G loss: 0.0023\n",
            "Step 356/390 - D loss: 3.2672, G loss: 0.0023\n",
            "Step 357/390 - D loss: 3.2675, G loss: 0.0023\n",
            "Step 358/390 - D loss: 3.2804, G loss: 0.0023\n",
            "Step 359/390 - D loss: 3.2672, G loss: 0.0023\n",
            "Step 360/390 - D loss: 3.2778, G loss: 0.0023\n",
            "Step 361/390 - D loss: 3.2883, G loss: 0.0023\n",
            "Step 362/390 - D loss: 3.2759, G loss: 0.0023\n",
            "Step 363/390 - D loss: 3.2646, G loss: 0.0023\n",
            "Step 364/390 - D loss: 3.2631, G loss: 0.0023\n",
            "Step 365/390 - D loss: 3.2776, G loss: 0.0023\n",
            "Step 366/390 - D loss: 3.2781, G loss: 0.0023\n",
            "Step 367/390 - D loss: 3.2894, G loss: 0.0023\n",
            "Step 368/390 - D loss: 3.2545, G loss: 0.0023\n",
            "Step 369/390 - D loss: 3.2694, G loss: 0.0023\n",
            "Step 370/390 - D loss: 3.2716, G loss: 0.0023\n",
            "Step 371/390 - D loss: 3.2944, G loss: 0.0023\n",
            "Step 372/390 - D loss: 3.2633, G loss: 0.0023\n",
            "Step 373/390 - D loss: 3.2810, G loss: 0.0023\n",
            "Step 374/390 - D loss: 3.2651, G loss: 0.0023\n",
            "Step 375/390 - D loss: 3.2553, G loss: 0.0023\n",
            "Step 376/390 - D loss: 3.2634, G loss: 0.0023\n",
            "Step 377/390 - D loss: 3.2668, G loss: 0.0023\n",
            "Step 378/390 - D loss: 3.2641, G loss: 0.0023\n",
            "Step 379/390 - D loss: 3.2752, G loss: 0.0023\n",
            "Step 380/390 - D loss: 3.2617, G loss: 0.0023\n",
            "Step 381/390 - D loss: 3.2609, G loss: 0.0023\n",
            "Step 382/390 - D loss: 3.2728, G loss: 0.0023\n",
            "Step 383/390 - D loss: 3.2666, G loss: 0.0023\n",
            "Step 384/390 - D loss: 3.2568, G loss: 0.0023\n",
            "Step 385/390 - D loss: 3.2487, G loss: 0.0023\n",
            "Step 386/390 - D loss: 3.2704, G loss: 0.0023\n",
            "Step 387/390 - D loss: 3.2696, G loss: 0.0024\n",
            "Step 388/390 - D loss: 3.2706, G loss: 0.0023\n",
            "Step 389/390 - D loss: 3.2627, G loss: 0.0023\n",
            "Step 390/390 - D loss: 3.2784, G loss: 0.0023\n",
            "Epoch 5/200\n",
            "Step 1/390 - D loss: 3.2515, G loss: 0.0023\n",
            "Step 2/390 - D loss: 3.2816, G loss: 0.0024\n",
            "Step 3/390 - D loss: 3.2689, G loss: 0.0024\n",
            "Step 4/390 - D loss: 3.2529, G loss: 0.0024\n",
            "Step 5/390 - D loss: 3.2531, G loss: 0.0024\n",
            "Step 6/390 - D loss: 3.2409, G loss: 0.0024\n",
            "Step 7/390 - D loss: 3.2382, G loss: 0.0024\n",
            "Step 8/390 - D loss: 3.2552, G loss: 0.0024\n",
            "Step 9/390 - D loss: 3.2744, G loss: 0.0024\n",
            "Step 10/390 - D loss: 3.2383, G loss: 0.0024\n",
            "Step 11/390 - D loss: 3.2821, G loss: 0.0024\n",
            "Step 12/390 - D loss: 3.2756, G loss: 0.0024\n",
            "Step 13/390 - D loss: 3.2494, G loss: 0.0024\n",
            "Step 14/390 - D loss: 3.2531, G loss: 0.0024\n",
            "Step 15/390 - D loss: 3.2424, G loss: 0.0024\n",
            "Step 16/390 - D loss: 3.2295, G loss: 0.0024\n",
            "Step 17/390 - D loss: 3.2504, G loss: 0.0024\n",
            "Step 18/390 - D loss: 3.2572, G loss: 0.0024\n",
            "Step 19/390 - D loss: 3.2463, G loss: 0.0024\n",
            "Step 20/390 - D loss: 3.2620, G loss: 0.0024\n",
            "Step 21/390 - D loss: 3.2463, G loss: 0.0024\n",
            "Step 22/390 - D loss: 3.2347, G loss: 0.0024\n",
            "Step 23/390 - D loss: 3.2629, G loss: 0.0024\n",
            "Step 24/390 - D loss: 3.2369, G loss: 0.0024\n",
            "Step 25/390 - D loss: 3.2406, G loss: 0.0024\n",
            "Step 26/390 - D loss: 3.2470, G loss: 0.0024\n",
            "Step 27/390 - D loss: 3.2332, G loss: 0.0024\n",
            "Step 28/390 - D loss: 3.2405, G loss: 0.0024\n",
            "Step 29/390 - D loss: 3.2477, G loss: 0.0024\n",
            "Step 30/390 - D loss: 3.2489, G loss: 0.0024\n",
            "Step 31/390 - D loss: 3.2492, G loss: 0.0024\n",
            "Step 32/390 - D loss: 3.2246, G loss: 0.0024\n",
            "Step 33/390 - D loss: 3.2407, G loss: 0.0024\n",
            "Step 34/390 - D loss: 3.2534, G loss: 0.0024\n",
            "Step 35/390 - D loss: 3.2570, G loss: 0.0024\n",
            "Step 36/390 - D loss: 3.2351, G loss: 0.0024\n",
            "Step 37/390 - D loss: 3.2540, G loss: 0.0024\n",
            "Step 38/390 - D loss: 3.2149, G loss: 0.0024\n",
            "Step 39/390 - D loss: 3.2169, G loss: 0.0024\n",
            "Step 40/390 - D loss: 3.2304, G loss: 0.0024\n",
            "Step 41/390 - D loss: 3.2519, G loss: 0.0024\n",
            "Step 42/390 - D loss: 3.2666, G loss: 0.0024\n",
            "Step 43/390 - D loss: 3.2348, G loss: 0.0024\n",
            "Step 44/390 - D loss: 3.2319, G loss: 0.0024\n",
            "Step 45/390 - D loss: 3.2506, G loss: 0.0024\n",
            "Step 46/390 - D loss: 3.2563, G loss: 0.0024\n",
            "Step 47/390 - D loss: 3.2390, G loss: 0.0024\n",
            "Step 48/390 - D loss: 3.2289, G loss: 0.0024\n",
            "Step 49/390 - D loss: 3.2332, G loss: 0.0024\n",
            "Step 50/390 - D loss: 3.2328, G loss: 0.0024\n",
            "Step 51/390 - D loss: 3.2109, G loss: 0.0024\n",
            "Step 52/390 - D loss: 3.2422, G loss: 0.0024\n",
            "Step 53/390 - D loss: 3.2272, G loss: 0.0024\n",
            "Step 54/390 - D loss: 3.2258, G loss: 0.0024\n",
            "Step 55/390 - D loss: 3.2506, G loss: 0.0024\n",
            "Step 56/390 - D loss: 3.2313, G loss: 0.0024\n",
            "Step 57/390 - D loss: 3.2378, G loss: 0.0024\n",
            "Step 58/390 - D loss: 3.2539, G loss: 0.0025\n",
            "Step 59/390 - D loss: 3.2273, G loss: 0.0024\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60/390 - D loss: 3.2432, G loss: 0.0024\n",
            "Step 61/390 - D loss: 3.2410, G loss: 0.0025\n",
            "Step 62/390 - D loss: 3.2173, G loss: 0.0025\n",
            "Step 63/390 - D loss: 3.2215, G loss: 0.0024\n",
            "Step 64/390 - D loss: 3.2269, G loss: 0.0025\n",
            "Step 65/390 - D loss: 3.2245, G loss: 0.0025\n",
            "Step 66/390 - D loss: 3.2219, G loss: 0.0025\n",
            "Step 67/390 - D loss: 3.2471, G loss: 0.0025\n",
            "Step 68/390 - D loss: 3.2298, G loss: 0.0024\n",
            "Step 69/390 - D loss: 3.2310, G loss: 0.0025\n",
            "Step 70/390 - D loss: 3.2219, G loss: 0.0025\n",
            "Step 71/390 - D loss: 3.2210, G loss: 0.0025\n",
            "Step 72/390 - D loss: 3.2322, G loss: 0.0025\n",
            "Step 73/390 - D loss: 3.2191, G loss: 0.0025\n",
            "Step 74/390 - D loss: 3.2290, G loss: 0.0025\n",
            "Step 75/390 - D loss: 3.2119, G loss: 0.0025\n",
            "Step 76/390 - D loss: 3.2317, G loss: 0.0025\n",
            "Step 77/390 - D loss: 3.2146, G loss: 0.0025\n",
            "Step 78/390 - D loss: 3.2315, G loss: 0.0025\n",
            "Step 79/390 - D loss: 3.2320, G loss: 0.0025\n",
            "Step 80/390 - D loss: 3.2126, G loss: 0.0025\n",
            "Step 81/390 - D loss: 3.1892, G loss: 0.0025\n",
            "Step 82/390 - D loss: 3.2098, G loss: 0.0025\n",
            "Step 83/390 - D loss: 3.2204, G loss: 0.0025\n",
            "Step 84/390 - D loss: 3.2168, G loss: 0.0025\n",
            "Step 85/390 - D loss: 3.2487, G loss: 0.0025\n",
            "Step 86/390 - D loss: 3.2326, G loss: 0.0025\n",
            "Step 87/390 - D loss: 3.2306, G loss: 0.0025\n",
            "Step 88/390 - D loss: 3.2259, G loss: 0.0025\n",
            "Step 89/390 - D loss: 3.1976, G loss: 0.0025\n",
            "Step 90/390 - D loss: 3.2288, G loss: 0.0025\n",
            "Step 91/390 - D loss: 3.2121, G loss: 0.0025\n",
            "Step 92/390 - D loss: 3.2179, G loss: 0.0025\n",
            "Step 93/390 - D loss: 3.1993, G loss: 0.0025\n",
            "Step 94/390 - D loss: 3.2097, G loss: 0.0025\n",
            "Step 95/390 - D loss: 3.2167, G loss: 0.0025\n",
            "Step 96/390 - D loss: 3.2131, G loss: 0.0025\n",
            "Step 97/390 - D loss: 3.2172, G loss: 0.0025\n",
            "Step 98/390 - D loss: 3.2076, G loss: 0.0025\n",
            "Step 99/390 - D loss: 3.2314, G loss: 0.0025\n",
            "Step 100/390 - D loss: 3.2016, G loss: 0.0025\n",
            "Step 101/390 - D loss: 3.2326, G loss: 0.0025\n",
            "Step 102/390 - D loss: 3.2289, G loss: 0.0025\n",
            "Step 103/390 - D loss: 3.2102, G loss: 0.0025\n",
            "Step 104/390 - D loss: 3.2248, G loss: 0.0025\n",
            "Step 105/390 - D loss: 3.2212, G loss: 0.0025\n",
            "Step 106/390 - D loss: 3.2109, G loss: 0.0025\n",
            "Step 107/390 - D loss: 3.1924, G loss: 0.0025\n",
            "Step 108/390 - D loss: 3.2119, G loss: 0.0025\n",
            "Step 109/390 - D loss: 3.2142, G loss: 0.0025\n",
            "Step 110/390 - D loss: 3.2156, G loss: 0.0025\n",
            "Step 111/390 - D loss: 3.1880, G loss: 0.0026\n",
            "Step 112/390 - D loss: 3.2245, G loss: 0.0025\n",
            "Step 113/390 - D loss: 3.2165, G loss: 0.0025\n",
            "Step 114/390 - D loss: 3.2016, G loss: 0.0025\n",
            "Step 115/390 - D loss: 3.2275, G loss: 0.0025\n",
            "Step 116/390 - D loss: 3.2046, G loss: 0.0026\n",
            "Step 117/390 - D loss: 3.1904, G loss: 0.0025\n",
            "Step 118/390 - D loss: 3.2113, G loss: 0.0025\n",
            "Step 119/390 - D loss: 3.2031, G loss: 0.0025\n",
            "Step 120/390 - D loss: 3.2203, G loss: 0.0025\n",
            "Step 121/390 - D loss: 3.2142, G loss: 0.0025\n",
            "Step 122/390 - D loss: 3.2232, G loss: 0.0025\n",
            "Step 123/390 - D loss: 3.1872, G loss: 0.0025\n",
            "Step 124/390 - D loss: 3.2180, G loss: 0.0025\n",
            "Step 125/390 - D loss: 3.1983, G loss: 0.0025\n",
            "Step 126/390 - D loss: 3.2314, G loss: 0.0025\n",
            "Step 127/390 - D loss: 3.2210, G loss: 0.0025\n",
            "Step 128/390 - D loss: 3.2064, G loss: 0.0026\n",
            "Step 129/390 - D loss: 3.1907, G loss: 0.0026\n",
            "Step 130/390 - D loss: 3.1972, G loss: 0.0026\n",
            "Step 131/390 - D loss: 3.2007, G loss: 0.0025\n",
            "Step 132/390 - D loss: 3.2160, G loss: 0.0025\n",
            "Step 133/390 - D loss: 3.1979, G loss: 0.0025\n",
            "Step 134/390 - D loss: 3.2014, G loss: 0.0025\n",
            "Step 135/390 - D loss: 3.1872, G loss: 0.0025\n",
            "Step 136/390 - D loss: 3.1908, G loss: 0.0026\n",
            "Step 137/390 - D loss: 3.2020, G loss: 0.0026\n",
            "Step 138/390 - D loss: 3.2112, G loss: 0.0025\n",
            "Step 139/390 - D loss: 3.2049, G loss: 0.0025\n",
            "Step 140/390 - D loss: 3.2112, G loss: 0.0026\n",
            "Step 141/390 - D loss: 3.1950, G loss: 0.0025\n",
            "Step 142/390 - D loss: 3.2065, G loss: 0.0026\n",
            "Step 143/390 - D loss: 3.1776, G loss: 0.0025\n",
            "Step 144/390 - D loss: 3.2020, G loss: 0.0026\n",
            "Step 145/390 - D loss: 3.2145, G loss: 0.0026\n",
            "Step 146/390 - D loss: 3.2103, G loss: 0.0026\n",
            "Step 147/390 - D loss: 3.1984, G loss: 0.0026\n",
            "Step 148/390 - D loss: 3.1929, G loss: 0.0026\n",
            "Step 149/390 - D loss: 3.1924, G loss: 0.0026\n",
            "Step 150/390 - D loss: 3.2038, G loss: 0.0026\n",
            "Step 151/390 - D loss: 3.2005, G loss: 0.0025\n",
            "Step 152/390 - D loss: 3.1846, G loss: 0.0026\n",
            "Step 153/390 - D loss: 3.2018, G loss: 0.0026\n",
            "Step 154/390 - D loss: 3.1958, G loss: 0.0025\n",
            "Step 155/390 - D loss: 3.2112, G loss: 0.0026\n",
            "Step 156/390 - D loss: 3.2026, G loss: 0.0026\n",
            "Step 157/390 - D loss: 3.1859, G loss: 0.0026\n",
            "Step 158/390 - D loss: 3.1916, G loss: 0.0026\n",
            "Step 159/390 - D loss: 3.1923, G loss: 0.0026\n",
            "Step 160/390 - D loss: 3.1941, G loss: 0.0026\n",
            "Step 161/390 - D loss: 3.1837, G loss: 0.0026\n",
            "Step 162/390 - D loss: 3.1923, G loss: 0.0026\n",
            "Step 163/390 - D loss: 3.1837, G loss: 0.0026\n",
            "Step 164/390 - D loss: 3.1940, G loss: 0.0026\n",
            "Step 165/390 - D loss: 3.1968, G loss: 0.0026\n",
            "Step 166/390 - D loss: 3.1995, G loss: 0.0026\n",
            "Step 167/390 - D loss: 3.2072, G loss: 0.0026\n",
            "Step 168/390 - D loss: 3.2068, G loss: 0.0026\n",
            "Step 169/390 - D loss: 3.1923, G loss: 0.0026\n",
            "Step 170/390 - D loss: 3.2055, G loss: 0.0026\n",
            "Step 171/390 - D loss: 3.2078, G loss: 0.0026\n",
            "Step 172/390 - D loss: 3.1827, G loss: 0.0026\n",
            "Step 173/390 - D loss: 3.1921, G loss: 0.0026\n",
            "Step 174/390 - D loss: 3.1988, G loss: 0.0026\n",
            "Step 175/390 - D loss: 3.1852, G loss: 0.0026\n",
            "Step 176/390 - D loss: 3.1895, G loss: 0.0026\n",
            "Step 177/390 - D loss: 3.1979, G loss: 0.0026\n",
            "Step 178/390 - D loss: 3.1727, G loss: 0.0026\n",
            "Step 179/390 - D loss: 3.1999, G loss: 0.0026\n",
            "Step 180/390 - D loss: 3.1849, G loss: 0.0026\n",
            "Step 181/390 - D loss: 3.1889, G loss: 0.0026\n",
            "Step 182/390 - D loss: 3.1912, G loss: 0.0026\n",
            "Step 183/390 - D loss: 3.1976, G loss: 0.0026\n",
            "Step 184/390 - D loss: 3.1725, G loss: 0.0026\n",
            "Step 185/390 - D loss: 3.1938, G loss: 0.0026\n",
            "Step 186/390 - D loss: 3.1758, G loss: 0.0026\n",
            "Step 187/390 - D loss: 3.1721, G loss: 0.0026\n",
            "Step 188/390 - D loss: 3.1726, G loss: 0.0026\n",
            "Step 189/390 - D loss: 3.2062, G loss: 0.0026\n",
            "Step 190/390 - D loss: 3.1922, G loss: 0.0026\n",
            "Step 191/390 - D loss: 3.1851, G loss: 0.0026\n",
            "Step 192/390 - D loss: 3.1788, G loss: 0.0026\n",
            "Step 193/390 - D loss: 3.1827, G loss: 0.0026\n",
            "Step 194/390 - D loss: 3.1941, G loss: 0.0026\n",
            "Step 195/390 - D loss: 3.1807, G loss: 0.0026\n",
            "Step 196/390 - D loss: 3.1963, G loss: 0.0026\n",
            "Step 197/390 - D loss: 3.1803, G loss: 0.0026\n",
            "Step 198/390 - D loss: 3.1767, G loss: 0.0026\n",
            "Step 199/390 - D loss: 3.1849, G loss: 0.0026\n",
            "Step 200/390 - D loss: 3.1655, G loss: 0.0026\n",
            "Step 201/390 - D loss: 3.1829, G loss: 0.0026\n",
            "Step 202/390 - D loss: 3.1930, G loss: 0.0026\n",
            "Step 203/390 - D loss: 3.1649, G loss: 0.0026\n",
            "Step 204/390 - D loss: 3.1710, G loss: 0.0026\n",
            "Step 205/390 - D loss: 3.1800, G loss: 0.0026\n",
            "Step 206/390 - D loss: 3.1897, G loss: 0.0026\n",
            "Step 207/390 - D loss: 3.1861, G loss: 0.0026\n",
            "Step 208/390 - D loss: 3.1582, G loss: 0.0026\n",
            "Step 209/390 - D loss: 3.1687, G loss: 0.0026\n",
            "Step 210/390 - D loss: 3.1665, G loss: 0.0026\n",
            "Step 211/390 - D loss: 3.1889, G loss: 0.0026\n",
            "Step 212/390 - D loss: 3.1905, G loss: 0.0027\n",
            "Step 213/390 - D loss: 3.1939, G loss: 0.0026\n",
            "Step 214/390 - D loss: 3.1663, G loss: 0.0027\n",
            "Step 215/390 - D loss: 3.1690, G loss: 0.0026\n",
            "Step 216/390 - D loss: 3.1690, G loss: 0.0027\n",
            "Step 217/390 - D loss: 3.1755, G loss: 0.0027\n",
            "Step 218/390 - D loss: 3.1634, G loss: 0.0027\n",
            "Step 219/390 - D loss: 3.1701, G loss: 0.0027\n",
            "Step 220/390 - D loss: 3.1700, G loss: 0.0027\n",
            "Step 221/390 - D loss: 3.1710, G loss: 0.0027\n",
            "Step 222/390 - D loss: 3.1614, G loss: 0.0027\n",
            "Step 223/390 - D loss: 3.1786, G loss: 0.0027\n",
            "Step 224/390 - D loss: 3.1548, G loss: 0.0027\n",
            "Step 225/390 - D loss: 3.1559, G loss: 0.0026\n",
            "Step 226/390 - D loss: 3.1672, G loss: 0.0027\n",
            "Step 227/390 - D loss: 3.1854, G loss: 0.0027\n",
            "Step 228/390 - D loss: 3.1713, G loss: 0.0027\n",
            "Step 229/390 - D loss: 3.1862, G loss: 0.0027\n",
            "Step 230/390 - D loss: 3.1652, G loss: 0.0027\n",
            "Step 231/390 - D loss: 3.1872, G loss: 0.0027\n",
            "Step 232/390 - D loss: 3.1662, G loss: 0.0027\n",
            "Step 233/390 - D loss: 3.1757, G loss: 0.0027\n",
            "Step 234/390 - D loss: 3.1798, G loss: 0.0027\n",
            "Step 235/390 - D loss: 3.1748, G loss: 0.0027\n",
            "Step 236/390 - D loss: 3.1707, G loss: 0.0027\n",
            "Step 237/390 - D loss: 3.1601, G loss: 0.0027\n",
            "Step 238/390 - D loss: 3.1791, G loss: 0.0027\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 239/390 - D loss: 3.1704, G loss: 0.0027\n",
            "Step 240/390 - D loss: 3.1660, G loss: 0.0027\n",
            "Step 241/390 - D loss: 3.1600, G loss: 0.0027\n",
            "Step 242/390 - D loss: 3.1674, G loss: 0.0027\n",
            "Step 243/390 - D loss: 3.1463, G loss: 0.0027\n",
            "Step 244/390 - D loss: 3.1652, G loss: 0.0027\n",
            "Step 245/390 - D loss: 3.1720, G loss: 0.0027\n",
            "Step 246/390 - D loss: 3.1640, G loss: 0.0027\n",
            "Step 247/390 - D loss: 3.1571, G loss: 0.0027\n",
            "Step 248/390 - D loss: 3.1579, G loss: 0.0027\n",
            "Step 249/390 - D loss: 3.1565, G loss: 0.0027\n",
            "Step 250/390 - D loss: 3.1476, G loss: 0.0027\n",
            "Step 251/390 - D loss: 3.1678, G loss: 0.0027\n",
            "Step 252/390 - D loss: 3.1567, G loss: 0.0027\n",
            "Step 253/390 - D loss: 3.1814, G loss: 0.0027\n",
            "Step 254/390 - D loss: 3.1465, G loss: 0.0027\n",
            "Step 255/390 - D loss: 3.1554, G loss: 0.0027\n",
            "Step 256/390 - D loss: 3.1630, G loss: 0.0027\n",
            "Step 257/390 - D loss: 3.1643, G loss: 0.0027\n",
            "Step 258/390 - D loss: 3.1537, G loss: 0.0027\n",
            "Step 259/390 - D loss: 3.1639, G loss: 0.0027\n",
            "Step 260/390 - D loss: 3.1544, G loss: 0.0027\n",
            "Step 261/390 - D loss: 3.1408, G loss: 0.0027\n",
            "Step 262/390 - D loss: 3.1526, G loss: 0.0027\n",
            "Step 263/390 - D loss: 3.1550, G loss: 0.0027\n",
            "Step 264/390 - D loss: 3.1799, G loss: 0.0027\n",
            "Step 265/390 - D loss: 3.1456, G loss: 0.0027\n",
            "Step 266/390 - D loss: 3.1488, G loss: 0.0027\n",
            "Step 267/390 - D loss: 3.1577, G loss: 0.0027\n",
            "Step 268/390 - D loss: 3.1482, G loss: 0.0027\n",
            "Step 269/390 - D loss: 3.1502, G loss: 0.0027\n",
            "Step 270/390 - D loss: 3.1568, G loss: 0.0027\n",
            "Step 271/390 - D loss: 3.1375, G loss: 0.0027\n",
            "Step 272/390 - D loss: 3.1591, G loss: 0.0027\n",
            "Step 273/390 - D loss: 3.1449, G loss: 0.0027\n",
            "Step 274/390 - D loss: 3.1609, G loss: 0.0027\n",
            "Step 275/390 - D loss: 3.1694, G loss: 0.0027\n",
            "Step 276/390 - D loss: 3.1593, G loss: 0.0027\n",
            "Step 277/390 - D loss: 3.1242, G loss: 0.0027\n",
            "Step 278/390 - D loss: 3.1459, G loss: 0.0028\n",
            "Step 279/390 - D loss: 3.1641, G loss: 0.0027\n",
            "Step 280/390 - D loss: 3.1374, G loss: 0.0028\n",
            "Step 281/390 - D loss: 3.1437, G loss: 0.0027\n",
            "Step 282/390 - D loss: 3.1667, G loss: 0.0027\n",
            "Step 283/390 - D loss: 3.1366, G loss: 0.0027\n",
            "Step 284/390 - D loss: 3.1632, G loss: 0.0027\n",
            "Step 285/390 - D loss: 3.1524, G loss: 0.0027\n",
            "Step 286/390 - D loss: 3.1770, G loss: 0.0027\n",
            "Step 287/390 - D loss: 3.1238, G loss: 0.0027\n",
            "Step 288/390 - D loss: 3.1699, G loss: 0.0028\n",
            "Step 289/390 - D loss: 3.1369, G loss: 0.0028\n",
            "Step 290/390 - D loss: 3.1419, G loss: 0.0028\n",
            "Step 291/390 - D loss: 3.1261, G loss: 0.0028\n",
            "Step 292/390 - D loss: 3.1484, G loss: 0.0028\n",
            "Step 293/390 - D loss: 3.1335, G loss: 0.0028\n",
            "Step 294/390 - D loss: 3.1422, G loss: 0.0028\n",
            "Step 295/390 - D loss: 3.1540, G loss: 0.0028\n",
            "Step 296/390 - D loss: 3.1410, G loss: 0.0028\n",
            "Step 297/390 - D loss: 3.1338, G loss: 0.0028\n",
            "Step 298/390 - D loss: 3.1479, G loss: 0.0028\n",
            "Step 299/390 - D loss: 3.1520, G loss: 0.0028\n",
            "Step 300/390 - D loss: 3.1391, G loss: 0.0028\n",
            "Step 301/390 - D loss: 3.1327, G loss: 0.0028\n",
            "Step 302/390 - D loss: 3.1375, G loss: 0.0028\n",
            "Step 303/390 - D loss: 3.1437, G loss: 0.0028\n",
            "Step 304/390 - D loss: 3.1368, G loss: 0.0028\n",
            "Step 305/390 - D loss: 3.1358, G loss: 0.0028\n",
            "Step 306/390 - D loss: 3.1454, G loss: 0.0028\n",
            "Step 307/390 - D loss: 3.1369, G loss: 0.0028\n",
            "Step 308/390 - D loss: 3.1418, G loss: 0.0028\n",
            "Step 309/390 - D loss: 3.1525, G loss: 0.0028\n",
            "Step 310/390 - D loss: 3.1290, G loss: 0.0028\n",
            "Step 311/390 - D loss: 3.1275, G loss: 0.0028\n",
            "Step 312/390 - D loss: 3.1460, G loss: 0.0028\n",
            "Step 313/390 - D loss: 3.1458, G loss: 0.0028\n",
            "Step 314/390 - D loss: 3.1389, G loss: 0.0028\n",
            "Step 315/390 - D loss: 3.1597, G loss: 0.0028\n",
            "Step 316/390 - D loss: 3.1593, G loss: 0.0028\n",
            "Step 317/390 - D loss: 3.1203, G loss: 0.0028\n",
            "Step 318/390 - D loss: 3.1555, G loss: 0.0028\n",
            "Step 319/390 - D loss: 3.1349, G loss: 0.0028\n",
            "Step 320/390 - D loss: 3.1476, G loss: 0.0028\n",
            "Step 321/390 - D loss: 3.1211, G loss: 0.0028\n",
            "Step 322/390 - D loss: 3.1241, G loss: 0.0028\n",
            "Step 323/390 - D loss: 3.1248, G loss: 0.0028\n",
            "Step 324/390 - D loss: 3.1265, G loss: 0.0028\n",
            "Step 325/390 - D loss: 3.1345, G loss: 0.0028\n",
            "Step 326/390 - D loss: 3.1253, G loss: 0.0028\n",
            "Step 327/390 - D loss: 3.1256, G loss: 0.0028\n",
            "Step 328/390 - D loss: 3.1369, G loss: 0.0028\n",
            "Step 329/390 - D loss: 3.1286, G loss: 0.0028\n",
            "Step 330/390 - D loss: 3.1329, G loss: 0.0028\n",
            "Step 331/390 - D loss: 3.1167, G loss: 0.0028\n",
            "Step 332/390 - D loss: 3.1350, G loss: 0.0028\n",
            "Step 333/390 - D loss: 3.1274, G loss: 0.0028\n",
            "Step 334/390 - D loss: 3.1279, G loss: 0.0028\n",
            "Step 335/390 - D loss: 3.1238, G loss: 0.0028\n",
            "Step 336/390 - D loss: 3.1416, G loss: 0.0028\n",
            "Step 337/390 - D loss: 3.1287, G loss: 0.0028\n",
            "Step 338/390 - D loss: 3.1230, G loss: 0.0028\n",
            "Step 339/390 - D loss: 3.1323, G loss: 0.0028\n",
            "Step 340/390 - D loss: 3.1222, G loss: 0.0028\n",
            "Step 341/390 - D loss: 3.1296, G loss: 0.0028\n",
            "Step 342/390 - D loss: 3.1122, G loss: 0.0028\n",
            "Step 343/390 - D loss: 3.1151, G loss: 0.0028\n",
            "Step 344/390 - D loss: 3.1209, G loss: 0.0028\n",
            "Step 345/390 - D loss: 3.1293, G loss: 0.0028\n",
            "Step 346/390 - D loss: 3.1184, G loss: 0.0028\n",
            "Step 347/390 - D loss: 3.1217, G loss: 0.0028\n",
            "Step 348/390 - D loss: 3.1344, G loss: 0.0028\n",
            "Step 349/390 - D loss: 3.1038, G loss: 0.0028\n",
            "Step 350/390 - D loss: 3.1070, G loss: 0.0028\n",
            "Step 351/390 - D loss: 3.1123, G loss: 0.0028\n",
            "Step 352/390 - D loss: 3.1465, G loss: 0.0028\n",
            "Step 353/390 - D loss: 3.1026, G loss: 0.0028\n",
            "Step 354/390 - D loss: 3.1263, G loss: 0.0028\n",
            "Step 355/390 - D loss: 3.1087, G loss: 0.0028\n",
            "Step 356/390 - D loss: 3.1387, G loss: 0.0029\n",
            "Step 357/390 - D loss: 3.1137, G loss: 0.0028\n",
            "Step 358/390 - D loss: 3.1311, G loss: 0.0028\n",
            "Step 359/390 - D loss: 3.1285, G loss: 0.0028\n",
            "Step 360/390 - D loss: 3.1262, G loss: 0.0028\n",
            "Step 361/390 - D loss: 3.1195, G loss: 0.0028\n",
            "Step 362/390 - D loss: 3.1134, G loss: 0.0028\n",
            "Step 363/390 - D loss: 3.1306, G loss: 0.0028\n",
            "Step 364/390 - D loss: 3.1209, G loss: 0.0029\n",
            "Step 365/390 - D loss: 3.1147, G loss: 0.0029\n",
            "Step 366/390 - D loss: 3.1166, G loss: 0.0029\n",
            "Step 367/390 - D loss: 3.1035, G loss: 0.0029\n",
            "Step 368/390 - D loss: 3.1017, G loss: 0.0028\n",
            "Step 369/390 - D loss: 3.1195, G loss: 0.0029\n",
            "Step 370/390 - D loss: 3.0992, G loss: 0.0029\n",
            "Step 371/390 - D loss: 3.1365, G loss: 0.0029\n",
            "Step 372/390 - D loss: 3.1064, G loss: 0.0029\n",
            "Step 373/390 - D loss: 3.1130, G loss: 0.0029\n",
            "Step 374/390 - D loss: 3.1220, G loss: 0.0029\n",
            "Step 375/390 - D loss: 3.1062, G loss: 0.0029\n",
            "Step 376/390 - D loss: 3.1094, G loss: 0.0029\n",
            "Step 377/390 - D loss: 3.1013, G loss: 0.0029\n",
            "Step 378/390 - D loss: 3.1238, G loss: 0.0029\n",
            "Step 379/390 - D loss: 3.1060, G loss: 0.0029\n",
            "Step 380/390 - D loss: 3.1052, G loss: 0.0029\n",
            "Step 381/390 - D loss: 3.1047, G loss: 0.0029\n",
            "Step 382/390 - D loss: 3.1045, G loss: 0.0029\n",
            "Step 383/390 - D loss: 3.1151, G loss: 0.0029\n",
            "Step 384/390 - D loss: 3.0976, G loss: 0.0029\n",
            "Step 385/390 - D loss: 3.1035, G loss: 0.0029\n",
            "Step 386/390 - D loss: 3.1029, G loss: 0.0029\n",
            "Step 387/390 - D loss: 3.1242, G loss: 0.0029\n",
            "Step 388/390 - D loss: 3.1009, G loss: 0.0029\n",
            "Step 389/390 - D loss: 3.1007, G loss: 0.0029\n",
            "Step 390/390 - D loss: 3.1174, G loss: 0.0029\n",
            "Epoch 6/200\n",
            "Step 1/390 - D loss: 3.1067, G loss: 0.0029\n",
            "Step 2/390 - D loss: 3.1193, G loss: 0.0029\n",
            "Step 3/390 - D loss: 3.0903, G loss: 0.0029\n",
            "Step 4/390 - D loss: 3.1104, G loss: 0.0029\n",
            "Step 5/390 - D loss: 3.1094, G loss: 0.0029\n",
            "Step 6/390 - D loss: 3.1005, G loss: 0.0029\n",
            "Step 7/390 - D loss: 3.0915, G loss: 0.0029\n",
            "Step 8/390 - D loss: 3.1112, G loss: 0.0029\n",
            "Step 9/390 - D loss: 3.0836, G loss: 0.0029\n",
            "Step 10/390 - D loss: 3.0852, G loss: 0.0029\n",
            "Step 11/390 - D loss: 3.1113, G loss: 0.0029\n",
            "Step 12/390 - D loss: 3.0958, G loss: 0.0029\n",
            "Step 13/390 - D loss: 3.1019, G loss: 0.0029\n",
            "Step 14/390 - D loss: 3.0928, G loss: 0.0029\n",
            "Step 15/390 - D loss: 3.1034, G loss: 0.0029\n",
            "Step 16/390 - D loss: 3.0806, G loss: 0.0029\n",
            "Step 17/390 - D loss: 3.1016, G loss: 0.0029\n",
            "Step 18/390 - D loss: 3.0975, G loss: 0.0029\n",
            "Step 19/390 - D loss: 3.0860, G loss: 0.0029\n",
            "Step 20/390 - D loss: 3.1137, G loss: 0.0029\n",
            "Step 21/390 - D loss: 3.0723, G loss: 0.0030\n",
            "Step 22/390 - D loss: 3.0955, G loss: 0.0030\n",
            "Step 23/390 - D loss: 3.0966, G loss: 0.0030\n",
            "Step 24/390 - D loss: 3.0683, G loss: 0.0030\n",
            "Step 25/390 - D loss: 3.0946, G loss: 0.0029\n",
            "Step 26/390 - D loss: 3.0870, G loss: 0.0030\n",
            "Step 27/390 - D loss: 3.1094, G loss: 0.0030\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 28/390 - D loss: 3.0822, G loss: 0.0030\n",
            "Step 29/390 - D loss: 3.0700, G loss: 0.0030\n",
            "Step 30/390 - D loss: 3.0845, G loss: 0.0030\n",
            "Step 31/390 - D loss: 3.0846, G loss: 0.0030\n",
            "Step 32/390 - D loss: 3.0783, G loss: 0.0030\n",
            "Step 33/390 - D loss: 3.0945, G loss: 0.0030\n",
            "Step 34/390 - D loss: 3.0837, G loss: 0.0030\n",
            "Step 35/390 - D loss: 3.0986, G loss: 0.0030\n",
            "Step 36/390 - D loss: 3.0915, G loss: 0.0030\n",
            "Step 37/390 - D loss: 3.0745, G loss: 0.0030\n",
            "Step 38/390 - D loss: 3.0786, G loss: 0.0030\n",
            "Step 39/390 - D loss: 3.0584, G loss: 0.0030\n",
            "Step 40/390 - D loss: 3.0851, G loss: 0.0030\n",
            "Step 41/390 - D loss: 3.0986, G loss: 0.0030\n",
            "Step 42/390 - D loss: 3.0844, G loss: 0.0030\n",
            "Step 43/390 - D loss: 3.0832, G loss: 0.0030\n",
            "Step 44/390 - D loss: 3.0756, G loss: 0.0030\n",
            "Step 45/390 - D loss: 3.0857, G loss: 0.0030\n",
            "Step 46/390 - D loss: 3.0807, G loss: 0.0030\n",
            "Step 47/390 - D loss: 3.0667, G loss: 0.0030\n",
            "Step 48/390 - D loss: 3.0964, G loss: 0.0030\n",
            "Step 49/390 - D loss: 3.0911, G loss: 0.0030\n",
            "Step 50/390 - D loss: 3.0929, G loss: 0.0030\n",
            "Step 51/390 - D loss: 3.0956, G loss: 0.0030\n",
            "Step 52/390 - D loss: 3.0941, G loss: 0.0030\n",
            "Step 53/390 - D loss: 3.0688, G loss: 0.0030\n",
            "Step 54/390 - D loss: 3.0855, G loss: 0.0030\n",
            "Step 55/390 - D loss: 3.0777, G loss: 0.0030\n",
            "Step 56/390 - D loss: 3.0705, G loss: 0.0030\n",
            "Step 57/390 - D loss: 3.0843, G loss: 0.0030\n",
            "Step 58/390 - D loss: 3.0761, G loss: 0.0030\n",
            "Step 59/390 - D loss: 3.0821, G loss: 0.0030\n",
            "Step 60/390 - D loss: 3.0797, G loss: 0.0030\n",
            "Step 61/390 - D loss: 3.0904, G loss: 0.0030\n",
            "Step 62/390 - D loss: 3.0751, G loss: 0.0030\n",
            "Step 63/390 - D loss: 3.0896, G loss: 0.0030\n",
            "Step 64/390 - D loss: 3.0928, G loss: 0.0030\n",
            "Step 65/390 - D loss: 3.0827, G loss: 0.0030\n",
            "Step 66/390 - D loss: 3.0866, G loss: 0.0030\n",
            "Step 67/390 - D loss: 3.0630, G loss: 0.0030\n",
            "Step 68/390 - D loss: 3.0605, G loss: 0.0030\n",
            "Step 69/390 - D loss: 3.0832, G loss: 0.0030\n",
            "Step 70/390 - D loss: 3.0638, G loss: 0.0030\n",
            "Step 71/390 - D loss: 3.0783, G loss: 0.0030\n",
            "Step 72/390 - D loss: 3.0916, G loss: 0.0030\n",
            "Step 73/390 - D loss: 3.0811, G loss: 0.0030\n",
            "Step 74/390 - D loss: 3.0705, G loss: 0.0030\n",
            "Step 75/390 - D loss: 3.0762, G loss: 0.0030\n",
            "Step 76/390 - D loss: 3.0705, G loss: 0.0030\n",
            "Step 77/390 - D loss: 3.0793, G loss: 0.0030\n",
            "Step 78/390 - D loss: 3.0722, G loss: 0.0030\n",
            "Step 79/390 - D loss: 3.0751, G loss: 0.0030\n",
            "Step 80/390 - D loss: 3.0641, G loss: 0.0030\n",
            "Step 81/390 - D loss: 3.0809, G loss: 0.0030\n",
            "Step 82/390 - D loss: 3.0574, G loss: 0.0030\n",
            "Step 83/390 - D loss: 3.0912, G loss: 0.0030\n",
            "Step 84/390 - D loss: 3.0721, G loss: 0.0030\n",
            "Step 85/390 - D loss: 3.0777, G loss: 0.0030\n",
            "Step 86/390 - D loss: 3.0761, G loss: 0.0030\n",
            "Step 87/390 - D loss: 3.0662, G loss: 0.0031\n",
            "Step 88/390 - D loss: 3.0536, G loss: 0.0031\n",
            "Step 89/390 - D loss: 3.0547, G loss: 0.0031\n",
            "Step 90/390 - D loss: 3.0645, G loss: 0.0030\n",
            "Step 91/390 - D loss: 3.0780, G loss: 0.0030\n",
            "Step 92/390 - D loss: 3.0718, G loss: 0.0031\n",
            "Step 93/390 - D loss: 3.0718, G loss: 0.0031\n",
            "Step 94/390 - D loss: 3.0756, G loss: 0.0031\n",
            "Step 95/390 - D loss: 3.0558, G loss: 0.0031\n",
            "Step 96/390 - D loss: 3.0699, G loss: 0.0031\n",
            "Step 97/390 - D loss: 3.0550, G loss: 0.0031\n",
            "Step 98/390 - D loss: 3.0722, G loss: 0.0031\n",
            "Step 99/390 - D loss: 3.0648, G loss: 0.0031\n",
            "Step 100/390 - D loss: 3.0680, G loss: 0.0031\n",
            "Step 101/390 - D loss: 3.0550, G loss: 0.0031\n",
            "Step 102/390 - D loss: 3.0684, G loss: 0.0031\n",
            "Step 103/390 - D loss: 3.0662, G loss: 0.0031\n",
            "Step 104/390 - D loss: 3.0479, G loss: 0.0031\n",
            "Step 105/390 - D loss: 3.0746, G loss: 0.0031\n",
            "Step 106/390 - D loss: 3.0605, G loss: 0.0031\n",
            "Step 107/390 - D loss: 3.0819, G loss: 0.0031\n",
            "Step 108/390 - D loss: 3.0614, G loss: 0.0031\n",
            "Step 109/390 - D loss: 3.0649, G loss: 0.0031\n",
            "Step 110/390 - D loss: 3.0488, G loss: 0.0031\n",
            "Step 111/390 - D loss: 3.0641, G loss: 0.0031\n",
            "Step 112/390 - D loss: 3.0690, G loss: 0.0031\n",
            "Step 113/390 - D loss: 3.0500, G loss: 0.0031\n",
            "Step 114/390 - D loss: 3.0472, G loss: 0.0031\n",
            "Step 115/390 - D loss: 3.0644, G loss: 0.0031\n",
            "Step 116/390 - D loss: 3.0455, G loss: 0.0031\n",
            "Step 117/390 - D loss: 3.0524, G loss: 0.0031\n",
            "Step 118/390 - D loss: 3.0466, G loss: 0.0031\n",
            "Step 119/390 - D loss: 3.0481, G loss: 0.0031\n",
            "Step 120/390 - D loss: 3.0516, G loss: 0.0031\n",
            "Step 121/390 - D loss: 3.0582, G loss: 0.0031\n",
            "Step 122/390 - D loss: 3.0660, G loss: 0.0031\n",
            "Step 123/390 - D loss: 3.0613, G loss: 0.0031\n",
            "Step 124/390 - D loss: 3.0650, G loss: 0.0031\n",
            "Step 125/390 - D loss: 3.0503, G loss: 0.0031\n",
            "Step 126/390 - D loss: 3.0447, G loss: 0.0031\n",
            "Step 127/390 - D loss: 3.0415, G loss: 0.0031\n",
            "Step 128/390 - D loss: 3.0522, G loss: 0.0031\n",
            "Step 129/390 - D loss: 3.0558, G loss: 0.0031\n",
            "Step 130/390 - D loss: 3.0667, G loss: 0.0031\n",
            "Step 131/390 - D loss: 3.0526, G loss: 0.0031\n",
            "Step 132/390 - D loss: 3.0602, G loss: 0.0031\n",
            "Step 133/390 - D loss: 3.0551, G loss: 0.0031\n",
            "Step 134/390 - D loss: 3.0647, G loss: 0.0031\n",
            "Step 135/390 - D loss: 3.0521, G loss: 0.0031\n",
            "Step 136/390 - D loss: 3.0708, G loss: 0.0030\n",
            "Step 137/390 - D loss: 3.0668, G loss: 0.0030\n",
            "Step 138/390 - D loss: 3.0761, G loss: 0.0030\n",
            "Step 139/390 - D loss: 3.0596, G loss: 0.0030\n",
            "Step 140/390 - D loss: 3.0785, G loss: 0.0030\n",
            "Step 141/390 - D loss: 3.0623, G loss: 0.0030\n",
            "Step 142/390 - D loss: 3.0714, G loss: 0.0030\n",
            "Step 143/390 - D loss: 3.0719, G loss: 0.0030\n",
            "Step 144/390 - D loss: 3.0675, G loss: 0.0030\n",
            "Step 145/390 - D loss: 3.0744, G loss: 0.0030\n",
            "Step 146/390 - D loss: 3.0688, G loss: 0.0030\n",
            "Step 147/390 - D loss: 3.0633, G loss: 0.0030\n",
            "Step 148/390 - D loss: 3.0779, G loss: 0.0030\n",
            "Step 149/390 - D loss: 3.0701, G loss: 0.0030\n",
            "Step 150/390 - D loss: 3.0783, G loss: 0.0030\n",
            "Step 151/390 - D loss: 3.0777, G loss: 0.0029\n",
            "Step 152/390 - D loss: 3.0850, G loss: 0.0030\n",
            "Step 153/390 - D loss: 3.0817, G loss: 0.0030\n",
            "Step 154/390 - D loss: 3.0877, G loss: 0.0030\n",
            "Step 155/390 - D loss: 3.0715, G loss: 0.0030\n",
            "Step 156/390 - D loss: 3.0705, G loss: 0.0029\n",
            "Step 157/390 - D loss: 3.0606, G loss: 0.0030\n",
            "Step 158/390 - D loss: 3.0601, G loss: 0.0029\n",
            "Step 159/390 - D loss: 3.0639, G loss: 0.0030\n",
            "Step 160/390 - D loss: 3.0755, G loss: 0.0029\n",
            "Step 161/390 - D loss: 3.0781, G loss: 0.0030\n",
            "Step 162/390 - D loss: 3.0702, G loss: 0.0029\n",
            "Step 163/390 - D loss: 3.0706, G loss: 0.0030\n",
            "Step 164/390 - D loss: 3.0723, G loss: 0.0029\n",
            "Step 165/390 - D loss: 3.0708, G loss: 0.0029\n",
            "Step 166/390 - D loss: 3.0654, G loss: 0.0029\n",
            "Step 167/390 - D loss: 3.0703, G loss: 0.0029\n",
            "Step 168/390 - D loss: 3.0771, G loss: 0.0029\n",
            "Step 169/390 - D loss: 3.0613, G loss: 0.0029\n",
            "Step 170/390 - D loss: 3.0776, G loss: 0.0030\n",
            "Step 171/390 - D loss: 3.0846, G loss: 0.0030\n",
            "Step 172/390 - D loss: 3.0852, G loss: 0.0030\n",
            "Step 173/390 - D loss: 3.0720, G loss: 0.0030\n",
            "Step 174/390 - D loss: 3.0766, G loss: 0.0030\n",
            "Step 175/390 - D loss: 3.0813, G loss: 0.0029\n",
            "Step 176/390 - D loss: 3.0769, G loss: 0.0030\n",
            "Step 177/390 - D loss: 3.0689, G loss: 0.0030\n",
            "Step 178/390 - D loss: 3.0769, G loss: 0.0030\n",
            "Step 179/390 - D loss: 3.0715, G loss: 0.0030\n",
            "Step 180/390 - D loss: 3.0721, G loss: 0.0030\n",
            "Step 181/390 - D loss: 3.0628, G loss: 0.0030\n",
            "Step 182/390 - D loss: 3.0725, G loss: 0.0030\n",
            "Step 183/390 - D loss: 3.0629, G loss: 0.0030\n",
            "Step 184/390 - D loss: 3.0668, G loss: 0.0030\n",
            "Step 185/390 - D loss: 3.0888, G loss: 0.0030\n",
            "Step 186/390 - D loss: 3.0544, G loss: 0.0030\n",
            "Step 187/390 - D loss: 3.0658, G loss: 0.0030\n",
            "Step 188/390 - D loss: 3.0610, G loss: 0.0030\n",
            "Step 189/390 - D loss: 3.0632, G loss: 0.0030\n",
            "Step 190/390 - D loss: 3.0633, G loss: 0.0030\n",
            "Step 191/390 - D loss: 3.0547, G loss: 0.0030\n",
            "Step 192/390 - D loss: 3.0683, G loss: 0.0030\n",
            "Step 193/390 - D loss: 3.0891, G loss: 0.0030\n",
            "Step 194/390 - D loss: 3.0653, G loss: 0.0030\n",
            "Step 195/390 - D loss: 3.0604, G loss: 0.0030\n",
            "Step 196/390 - D loss: 3.0537, G loss: 0.0030\n",
            "Step 197/390 - D loss: 3.0803, G loss: 0.0030\n",
            "Step 198/390 - D loss: 3.0657, G loss: 0.0030\n",
            "Step 199/390 - D loss: 3.0596, G loss: 0.0030\n",
            "Step 200/390 - D loss: 3.0502, G loss: 0.0030\n",
            "Step 201/390 - D loss: 3.0668, G loss: 0.0030\n",
            "Step 202/390 - D loss: 3.0553, G loss: 0.0030\n",
            "Step 203/390 - D loss: 3.0699, G loss: 0.0030\n",
            "Step 204/390 - D loss: 3.0563, G loss: 0.0030\n",
            "Step 205/390 - D loss: 3.0580, G loss: 0.0030\n",
            "Step 206/390 - D loss: 3.0577, G loss: 0.0030\n",
            "Step 207/390 - D loss: 3.0538, G loss: 0.0030\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 208/390 - D loss: 3.0600, G loss: 0.0030\n",
            "Step 209/390 - D loss: 3.0569, G loss: 0.0030\n",
            "Step 210/390 - D loss: 3.0745, G loss: 0.0030\n",
            "Step 211/390 - D loss: 3.0608, G loss: 0.0030\n",
            "Step 212/390 - D loss: 3.0638, G loss: 0.0030\n",
            "Step 213/390 - D loss: 3.0517, G loss: 0.0030\n",
            "Step 214/390 - D loss: 3.0527, G loss: 0.0030\n",
            "Step 215/390 - D loss: 3.0709, G loss: 0.0030\n",
            "Step 216/390 - D loss: 3.0486, G loss: 0.0030\n",
            "Step 217/390 - D loss: 3.0527, G loss: 0.0030\n",
            "Step 218/390 - D loss: 3.0462, G loss: 0.0031\n",
            "Step 219/390 - D loss: 3.0478, G loss: 0.0031\n",
            "Step 220/390 - D loss: 3.0453, G loss: 0.0030\n",
            "Step 221/390 - D loss: 3.0605, G loss: 0.0030\n",
            "Step 222/390 - D loss: 3.0755, G loss: 0.0030\n",
            "Step 223/390 - D loss: 3.0795, G loss: 0.0030\n",
            "Step 224/390 - D loss: 3.0632, G loss: 0.0029\n",
            "Step 225/390 - D loss: 3.0808, G loss: 0.0029\n",
            "Step 226/390 - D loss: 3.0840, G loss: 0.0029\n",
            "Step 227/390 - D loss: 3.1010, G loss: 0.0028\n",
            "Step 228/390 - D loss: 3.0978, G loss: 0.0027\n",
            "Step 229/390 - D loss: 3.1058, G loss: 0.0027\n",
            "Step 230/390 - D loss: 3.1201, G loss: 0.0026\n",
            "Step 231/390 - D loss: 3.1387, G loss: 0.0026\n",
            "Step 232/390 - D loss: 3.1435, G loss: 0.0026\n",
            "Step 233/390 - D loss: 3.1468, G loss: 0.0026\n",
            "Step 234/390 - D loss: 3.1490, G loss: 0.0025\n",
            "Step 235/390 - D loss: 3.1663, G loss: 0.0025\n",
            "Step 236/390 - D loss: 3.1617, G loss: 0.0025\n",
            "Step 237/390 - D loss: 3.1555, G loss: 0.0025\n",
            "Step 238/390 - D loss: 3.1463, G loss: 0.0025\n",
            "Step 239/390 - D loss: 3.1430, G loss: 0.0025\n",
            "Step 240/390 - D loss: 3.1586, G loss: 0.0025\n",
            "Step 241/390 - D loss: 3.1596, G loss: 0.0025\n",
            "Step 242/390 - D loss: 3.1701, G loss: 0.0024\n",
            "Step 243/390 - D loss: 3.1707, G loss: 0.0024\n",
            "Step 244/390 - D loss: 3.1776, G loss: 0.0024\n",
            "Step 245/390 - D loss: 3.1757, G loss: 0.0024\n",
            "Step 246/390 - D loss: 3.1570, G loss: 0.0024\n",
            "Step 247/390 - D loss: 3.1692, G loss: 0.0024\n",
            "Step 248/390 - D loss: 3.1804, G loss: 0.0024\n",
            "Step 249/390 - D loss: 3.1640, G loss: 0.0024\n",
            "Step 250/390 - D loss: 3.1798, G loss: 0.0024\n",
            "Step 251/390 - D loss: 3.1743, G loss: 0.0024\n",
            "Step 252/390 - D loss: 3.1718, G loss: 0.0024\n",
            "Step 253/390 - D loss: 3.1672, G loss: 0.0024\n",
            "Step 254/390 - D loss: 3.1755, G loss: 0.0024\n",
            "Step 255/390 - D loss: 3.1674, G loss: 0.0024\n",
            "Step 256/390 - D loss: 3.1749, G loss: 0.0024\n",
            "Step 257/390 - D loss: 3.1710, G loss: 0.0024\n",
            "Step 258/390 - D loss: 3.1680, G loss: 0.0024\n",
            "Step 259/390 - D loss: 3.1699, G loss: 0.0024\n",
            "Step 260/390 - D loss: 3.1691, G loss: 0.0025\n",
            "Step 261/390 - D loss: 3.1532, G loss: 0.0025\n",
            "Step 262/390 - D loss: 3.1478, G loss: 0.0025\n",
            "Step 263/390 - D loss: 3.1544, G loss: 0.0025\n",
            "Step 264/390 - D loss: 3.1617, G loss: 0.0025\n",
            "Step 265/390 - D loss: 3.1660, G loss: 0.0025\n",
            "Step 266/390 - D loss: 3.1425, G loss: 0.0025\n",
            "Step 267/390 - D loss: 3.1631, G loss: 0.0025\n",
            "Step 268/390 - D loss: 3.1495, G loss: 0.0025\n",
            "Step 269/390 - D loss: 3.1472, G loss: 0.0025\n",
            "Step 270/390 - D loss: 3.1570, G loss: 0.0025\n",
            "Step 271/390 - D loss: 3.1568, G loss: 0.0025\n",
            "Step 272/390 - D loss: 3.1490, G loss: 0.0025\n",
            "Step 273/390 - D loss: 3.1503, G loss: 0.0025\n",
            "Step 274/390 - D loss: 3.1378, G loss: 0.0025\n",
            "Step 275/390 - D loss: 3.1449, G loss: 0.0025\n",
            "Step 276/390 - D loss: 3.1548, G loss: 0.0025\n",
            "Step 277/390 - D loss: 3.1536, G loss: 0.0025\n",
            "Step 278/390 - D loss: 3.1622, G loss: 0.0025\n",
            "Step 279/390 - D loss: 3.1589, G loss: 0.0025\n",
            "Step 280/390 - D loss: 3.1376, G loss: 0.0025\n",
            "Step 281/390 - D loss: 3.1571, G loss: 0.0025\n",
            "Step 282/390 - D loss: 3.1563, G loss: 0.0025\n",
            "Step 283/390 - D loss: 3.1445, G loss: 0.0025\n",
            "Step 284/390 - D loss: 3.1494, G loss: 0.0025\n",
            "Step 285/390 - D loss: 3.1444, G loss: 0.0025\n",
            "Step 286/390 - D loss: 3.1488, G loss: 0.0025\n",
            "Step 287/390 - D loss: 3.1527, G loss: 0.0025\n",
            "Step 288/390 - D loss: 3.1417, G loss: 0.0025\n",
            "Step 289/390 - D loss: 3.1476, G loss: 0.0025\n",
            "Step 290/390 - D loss: 3.1662, G loss: 0.0025\n",
            "Step 291/390 - D loss: 3.1493, G loss: 0.0025\n",
            "Step 292/390 - D loss: 3.1526, G loss: 0.0024\n",
            "Step 293/390 - D loss: 3.1749, G loss: 0.0024\n",
            "Step 294/390 - D loss: 3.1643, G loss: 0.0024\n",
            "Step 295/390 - D loss: 3.2074, G loss: 0.0023\n",
            "Step 296/390 - D loss: 3.1893, G loss: 0.0023\n",
            "Step 297/390 - D loss: 3.1970, G loss: 0.0023\n",
            "Step 298/390 - D loss: 3.1848, G loss: 0.0023\n",
            "Step 299/390 - D loss: 3.1866, G loss: 0.0023\n",
            "Step 300/390 - D loss: 3.2143, G loss: 0.0023\n",
            "Step 301/390 - D loss: 3.2100, G loss: 0.0022\n",
            "Step 302/390 - D loss: 3.2217, G loss: 0.0021\n",
            "Step 303/390 - D loss: 3.2233, G loss: 0.0021\n",
            "Step 304/390 - D loss: 3.2458, G loss: 0.0020\n",
            "Step 305/390 - D loss: 3.2629, G loss: 0.0020\n",
            "Step 306/390 - D loss: 3.3198, G loss: 0.0018\n",
            "Step 307/390 - D loss: 3.3515, G loss: 0.0017\n",
            "Step 308/390 - D loss: 3.3745, G loss: 0.0016\n",
            "Step 309/390 - D loss: 3.4034, G loss: 0.0015\n",
            "Step 310/390 - D loss: 3.4465, G loss: 0.0014\n",
            "Step 311/390 - D loss: 3.4752, G loss: 0.0013\n",
            "Step 312/390 - D loss: 3.4943, G loss: 0.0013\n",
            "Step 313/390 - D loss: 3.5217, G loss: 0.0012\n",
            "Step 314/390 - D loss: 3.5565, G loss: 0.0011\n",
            "Step 315/390 - D loss: 3.6251, G loss: 0.0010\n",
            "Step 316/390 - D loss: 3.6362, G loss: 0.0009\n",
            "Step 317/390 - D loss: 3.6682, G loss: 0.0008\n",
            "Step 318/390 - D loss: 3.7099, G loss: 0.0008\n",
            "Step 319/390 - D loss: 3.7409, G loss: 0.0007\n",
            "Step 320/390 - D loss: 3.8188, G loss: 0.0006\n",
            "Step 321/390 - D loss: 3.9063, G loss: 0.0006\n",
            "Step 322/390 - D loss: 3.9632, G loss: 0.0005\n",
            "Step 323/390 - D loss: 3.9995, G loss: 0.0005\n",
            "Step 324/390 - D loss: 4.0508, G loss: 0.0004\n",
            "Step 325/390 - D loss: 4.1066, G loss: 0.0004\n",
            "Step 326/390 - D loss: 4.1169, G loss: 0.0004\n",
            "Step 327/390 - D loss: 4.1296, G loss: 0.0004\n",
            "Step 328/390 - D loss: 4.1364, G loss: 0.0003\n",
            "Step 329/390 - D loss: 4.1812, G loss: 0.0003\n",
            "Step 330/390 - D loss: 4.1919, G loss: 0.0003\n",
            "Step 331/390 - D loss: 4.2348, G loss: 0.0003\n",
            "Step 332/390 - D loss: 4.2674, G loss: 0.0003\n",
            "Step 333/390 - D loss: 4.3058, G loss: 0.0003\n",
            "Step 334/390 - D loss: 4.3128, G loss: 0.0003\n",
            "Step 335/390 - D loss: 4.3332, G loss: 0.0003\n",
            "Step 336/390 - D loss: 4.3549, G loss: 0.0002\n",
            "Step 337/390 - D loss: 4.3871, G loss: 0.0002\n",
            "Step 338/390 - D loss: 4.3949, G loss: 0.0002\n",
            "Step 339/390 - D loss: 4.4006, G loss: 0.0002\n",
            "Step 340/390 - D loss: 4.4278, G loss: 0.0002\n",
            "Step 341/390 - D loss: 4.4380, G loss: 0.0002\n",
            "Step 342/390 - D loss: 4.4368, G loss: 0.0002\n",
            "Step 343/390 - D loss: 4.4596, G loss: 0.0002\n",
            "Step 344/390 - D loss: 4.4546, G loss: 0.0002\n",
            "Step 345/390 - D loss: 4.4645, G loss: 0.0002\n",
            "Step 346/390 - D loss: 4.4451, G loss: 0.0002\n",
            "Step 347/390 - D loss: 4.4440, G loss: 0.0002\n",
            "Step 348/390 - D loss: 4.4595, G loss: 0.0002\n",
            "Step 349/390 - D loss: 4.4551, G loss: 0.0002\n",
            "Step 350/390 - D loss: 4.4669, G loss: 0.0002\n",
            "Step 351/390 - D loss: 4.4683, G loss: 0.0002\n",
            "Step 352/390 - D loss: 4.4944, G loss: 0.0002\n",
            "Step 353/390 - D loss: 4.5054, G loss: 0.0002\n",
            "Step 354/390 - D loss: 4.5164, G loss: 0.0002\n",
            "Step 355/390 - D loss: 4.5362, G loss: 0.0002\n",
            "Step 356/390 - D loss: 4.5419, G loss: 0.0002\n",
            "Step 357/390 - D loss: 4.5515, G loss: 0.0002\n",
            "Step 358/390 - D loss: 4.5480, G loss: 0.0002\n",
            "Step 359/390 - D loss: 4.5572, G loss: 0.0002\n",
            "Step 360/390 - D loss: 4.5527, G loss: 0.0002\n",
            "Step 361/390 - D loss: 4.5489, G loss: 0.0002\n",
            "Step 362/390 - D loss: 4.5645, G loss: 0.0002\n",
            "Step 363/390 - D loss: 4.5444, G loss: 0.0002\n",
            "Step 364/390 - D loss: 4.5509, G loss: 0.0002\n",
            "Step 365/390 - D loss: 4.5458, G loss: 0.0002\n",
            "Step 366/390 - D loss: 4.5197, G loss: 0.0002\n",
            "Step 367/390 - D loss: 4.5364, G loss: 0.0002\n",
            "Step 368/390 - D loss: 4.5282, G loss: 0.0002\n",
            "Step 369/390 - D loss: 4.5193, G loss: 0.0002\n",
            "Step 370/390 - D loss: 4.5207, G loss: 0.0002\n",
            "Step 371/390 - D loss: 4.5109, G loss: 0.0002\n",
            "Step 372/390 - D loss: 4.5039, G loss: 0.0002\n",
            "Step 373/390 - D loss: 4.5125, G loss: 0.0002\n",
            "Step 374/390 - D loss: 4.4951, G loss: 0.0002\n",
            "Step 375/390 - D loss: 4.4786, G loss: 0.0002\n",
            "Step 376/390 - D loss: 4.4821, G loss: 0.0002\n",
            "Step 377/390 - D loss: 4.4930, G loss: 0.0002\n",
            "Step 378/390 - D loss: 4.4890, G loss: 0.0002\n",
            "Step 379/390 - D loss: 4.4912, G loss: 0.0002\n",
            "Step 380/390 - D loss: 4.4800, G loss: 0.0002\n",
            "Step 381/390 - D loss: 4.4722, G loss: 0.0002\n",
            "Step 382/390 - D loss: 4.4821, G loss: 0.0002\n",
            "Step 383/390 - D loss: 4.4858, G loss: 0.0002\n",
            "Step 384/390 - D loss: 4.4532, G loss: 0.0002\n",
            "Step 385/390 - D loss: 4.4613, G loss: 0.0002\n",
            "Step 386/390 - D loss: 4.4534, G loss: 0.0002\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 387/390 - D loss: 4.4397, G loss: 0.0002\n",
            "Step 388/390 - D loss: 4.4356, G loss: 0.0002\n",
            "Step 389/390 - D loss: 4.4163, G loss: 0.0002\n",
            "Step 390/390 - D loss: 4.4373, G loss: 0.0002\n",
            "Epoch 7/200\n",
            "Step 1/390 - D loss: 4.4098, G loss: 0.0002\n",
            "Step 2/390 - D loss: 4.4241, G loss: 0.0002\n",
            "Step 3/390 - D loss: 4.3988, G loss: 0.0002\n",
            "Step 4/390 - D loss: 4.4028, G loss: 0.0002\n",
            "Step 5/390 - D loss: 4.3980, G loss: 0.0002\n",
            "Step 6/390 - D loss: 4.3931, G loss: 0.0002\n",
            "Step 7/390 - D loss: 4.3962, G loss: 0.0002\n",
            "Step 8/390 - D loss: 4.3729, G loss: 0.0002\n",
            "Step 9/390 - D loss: 4.3631, G loss: 0.0002\n",
            "Step 10/390 - D loss: 4.3697, G loss: 0.0002\n",
            "Step 11/390 - D loss: 4.3644, G loss: 0.0003\n",
            "Step 12/390 - D loss: 4.3849, G loss: 0.0003\n",
            "Step 13/390 - D loss: 4.3484, G loss: 0.0003\n",
            "Step 14/390 - D loss: 4.3671, G loss: 0.0003\n",
            "Step 15/390 - D loss: 4.3544, G loss: 0.0003\n",
            "Step 16/390 - D loss: 4.3532, G loss: 0.0003\n",
            "Step 17/390 - D loss: 4.3523, G loss: 0.0003\n",
            "Step 18/390 - D loss: 4.3560, G loss: 0.0003\n",
            "Step 19/390 - D loss: 4.3689, G loss: 0.0003\n",
            "Step 20/390 - D loss: 4.3756, G loss: 0.0003\n",
            "Step 21/390 - D loss: 4.3381, G loss: 0.0003\n",
            "Step 22/390 - D loss: 4.3452, G loss: 0.0003\n",
            "Step 23/390 - D loss: 4.3516, G loss: 0.0003\n",
            "Step 24/390 - D loss: 4.3724, G loss: 0.0003\n",
            "Step 25/390 - D loss: 4.3334, G loss: 0.0003\n",
            "Step 26/390 - D loss: 4.3381, G loss: 0.0003\n",
            "Step 27/390 - D loss: 4.3416, G loss: 0.0003\n",
            "Step 28/390 - D loss: 4.3267, G loss: 0.0003\n",
            "Step 29/390 - D loss: 4.3460, G loss: 0.0003\n",
            "Step 30/390 - D loss: 4.3351, G loss: 0.0003\n",
            "Step 31/390 - D loss: 4.3413, G loss: 0.0003\n",
            "Step 32/390 - D loss: 4.3413, G loss: 0.0003\n",
            "Step 33/390 - D loss: 4.3431, G loss: 0.0003\n",
            "Step 34/390 - D loss: 4.3333, G loss: 0.0003\n",
            "Step 35/390 - D loss: 4.3256, G loss: 0.0003\n",
            "Step 36/390 - D loss: 4.3124, G loss: 0.0003\n",
            "Step 37/390 - D loss: 4.3323, G loss: 0.0003\n",
            "Step 38/390 - D loss: 4.3379, G loss: 0.0003\n",
            "Step 39/390 - D loss: 4.3095, G loss: 0.0003\n",
            "Step 40/390 - D loss: 4.3173, G loss: 0.0003\n",
            "Step 41/390 - D loss: 4.3332, G loss: 0.0003\n",
            "Step 42/390 - D loss: 4.3175, G loss: 0.0003\n",
            "Step 43/390 - D loss: 4.3060, G loss: 0.0003\n",
            "Step 44/390 - D loss: 4.2984, G loss: 0.0003\n",
            "Step 45/390 - D loss: 4.3010, G loss: 0.0003\n",
            "Step 46/390 - D loss: 4.2940, G loss: 0.0003\n",
            "Step 47/390 - D loss: 4.3171, G loss: 0.0003\n",
            "Step 48/390 - D loss: 4.3124, G loss: 0.0003\n",
            "Step 49/390 - D loss: 4.2953, G loss: 0.0003\n",
            "Step 50/390 - D loss: 4.3166, G loss: 0.0003\n",
            "Step 51/390 - D loss: 4.3121, G loss: 0.0003\n",
            "Step 52/390 - D loss: 4.3133, G loss: 0.0003\n",
            "Step 53/390 - D loss: 4.3154, G loss: 0.0003\n",
            "Step 54/390 - D loss: 4.3060, G loss: 0.0003\n",
            "Step 55/390 - D loss: 4.3014, G loss: 0.0003\n",
            "Step 56/390 - D loss: 4.3115, G loss: 0.0003\n",
            "Step 57/390 - D loss: 4.3011, G loss: 0.0003\n",
            "Step 58/390 - D loss: 4.2724, G loss: 0.0003\n",
            "Step 59/390 - D loss: 4.2782, G loss: 0.0003\n",
            "Step 60/390 - D loss: 4.2958, G loss: 0.0003\n",
            "Step 61/390 - D loss: 4.3035, G loss: 0.0003\n",
            "Step 62/390 - D loss: 4.2943, G loss: 0.0003\n",
            "Step 63/390 - D loss: 4.2980, G loss: 0.0003\n",
            "Step 64/390 - D loss: 4.2823, G loss: 0.0003\n",
            "Step 65/390 - D loss: 4.2603, G loss: 0.0003\n",
            "Step 66/390 - D loss: 4.2485, G loss: 0.0003\n",
            "Step 67/390 - D loss: 4.2806, G loss: 0.0003\n",
            "Step 68/390 - D loss: 4.2522, G loss: 0.0003\n",
            "Step 69/390 - D loss: 4.2427, G loss: 0.0003\n",
            "Step 70/390 - D loss: 4.2564, G loss: 0.0003\n",
            "Step 71/390 - D loss: 4.2409, G loss: 0.0003\n",
            "Step 72/390 - D loss: 4.2353, G loss: 0.0003\n",
            "Step 73/390 - D loss: 4.2590, G loss: 0.0003\n",
            "Step 74/390 - D loss: 4.2287, G loss: 0.0003\n",
            "Step 75/390 - D loss: 4.2240, G loss: 0.0003\n",
            "Step 76/390 - D loss: 4.2402, G loss: 0.0003\n",
            "Step 77/390 - D loss: 4.2188, G loss: 0.0003\n",
            "Step 78/390 - D loss: 4.2322, G loss: 0.0003\n",
            "Step 79/390 - D loss: 4.2218, G loss: 0.0004\n",
            "Step 80/390 - D loss: 4.2285, G loss: 0.0004\n",
            "Step 81/390 - D loss: 4.2003, G loss: 0.0004\n",
            "Step 82/390 - D loss: 4.2068, G loss: 0.0004\n",
            "Step 83/390 - D loss: 4.2132, G loss: 0.0004\n",
            "Step 84/390 - D loss: 4.2079, G loss: 0.0004\n",
            "Step 85/390 - D loss: 4.1928, G loss: 0.0004\n",
            "Step 86/390 - D loss: 4.1812, G loss: 0.0004\n",
            "Step 87/390 - D loss: 4.1853, G loss: 0.0004\n",
            "Step 88/390 - D loss: 4.2049, G loss: 0.0004\n",
            "Step 89/390 - D loss: 4.1866, G loss: 0.0004\n",
            "Step 90/390 - D loss: 4.1876, G loss: 0.0004\n",
            "Step 91/390 - D loss: 4.2031, G loss: 0.0004\n",
            "Step 92/390 - D loss: 4.1628, G loss: 0.0004\n",
            "Step 93/390 - D loss: 4.1667, G loss: 0.0004\n",
            "Step 94/390 - D loss: 4.2008, G loss: 0.0004\n",
            "Step 95/390 - D loss: 4.1771, G loss: 0.0004\n",
            "Step 96/390 - D loss: 4.1545, G loss: 0.0004\n",
            "Step 97/390 - D loss: 4.1763, G loss: 0.0004\n",
            "Step 98/390 - D loss: 4.2010, G loss: 0.0004\n",
            "Step 99/390 - D loss: 4.1824, G loss: 0.0004\n",
            "Step 100/390 - D loss: 4.1706, G loss: 0.0004\n",
            "Step 101/390 - D loss: 4.1585, G loss: 0.0004\n",
            "Step 102/390 - D loss: 4.1858, G loss: 0.0004\n",
            "Step 103/390 - D loss: 4.1657, G loss: 0.0004\n",
            "Step 104/390 - D loss: 4.1698, G loss: 0.0004\n",
            "Step 105/390 - D loss: 4.1677, G loss: 0.0004\n",
            "Step 106/390 - D loss: 4.1628, G loss: 0.0004\n",
            "Step 107/390 - D loss: 4.1766, G loss: 0.0004\n",
            "Step 108/390 - D loss: 4.1647, G loss: 0.0004\n",
            "Step 109/390 - D loss: 4.1702, G loss: 0.0004\n",
            "Step 110/390 - D loss: 4.1704, G loss: 0.0004\n",
            "Step 111/390 - D loss: 4.1602, G loss: 0.0004\n",
            "Step 112/390 - D loss: 4.1738, G loss: 0.0004\n",
            "Step 113/390 - D loss: 4.1422, G loss: 0.0004\n",
            "Step 114/390 - D loss: 4.1868, G loss: 0.0004\n",
            "Step 115/390 - D loss: 4.1792, G loss: 0.0004\n",
            "Step 116/390 - D loss: 4.1907, G loss: 0.0004\n",
            "Step 117/390 - D loss: 4.1735, G loss: 0.0004\n",
            "Step 118/390 - D loss: 4.1627, G loss: 0.0004\n",
            "Step 119/390 - D loss: 4.1784, G loss: 0.0004\n",
            "Step 120/390 - D loss: 4.2053, G loss: 0.0004\n",
            "Step 121/390 - D loss: 4.2050, G loss: 0.0004\n",
            "Step 122/390 - D loss: 4.1951, G loss: 0.0004\n",
            "Step 123/390 - D loss: 4.1899, G loss: 0.0004\n",
            "Step 124/390 - D loss: 4.2137, G loss: 0.0004\n",
            "Step 125/390 - D loss: 4.1953, G loss: 0.0004\n",
            "Step 126/390 - D loss: 4.2056, G loss: 0.0004\n",
            "Step 127/390 - D loss: 4.2214, G loss: 0.0004\n",
            "Step 128/390 - D loss: 4.2130, G loss: 0.0004\n",
            "Step 129/390 - D loss: 4.2066, G loss: 0.0004\n",
            "Step 130/390 - D loss: 4.2266, G loss: 0.0004\n",
            "Step 131/390 - D loss: 4.2598, G loss: 0.0004\n",
            "Step 132/390 - D loss: 4.2711, G loss: 0.0003\n",
            "Step 133/390 - D loss: 4.2288, G loss: 0.0003\n",
            "Step 134/390 - D loss: 4.2469, G loss: 0.0003\n",
            "Step 135/390 - D loss: 4.2719, G loss: 0.0003\n",
            "Step 136/390 - D loss: 4.2689, G loss: 0.0003\n",
            "Step 137/390 - D loss: 4.2520, G loss: 0.0003\n",
            "Step 138/390 - D loss: 4.2567, G loss: 0.0003\n",
            "Step 139/390 - D loss: 4.2783, G loss: 0.0003\n",
            "Step 140/390 - D loss: 4.2894, G loss: 0.0003\n",
            "Step 141/390 - D loss: 4.2809, G loss: 0.0003\n",
            "Step 142/390 - D loss: 4.2865, G loss: 0.0003\n",
            "Step 143/390 - D loss: 4.3023, G loss: 0.0003\n",
            "Step 144/390 - D loss: 4.3002, G loss: 0.0003\n",
            "Step 145/390 - D loss: 4.2976, G loss: 0.0003\n",
            "Step 146/390 - D loss: 4.3329, G loss: 0.0003\n",
            "Step 147/390 - D loss: 4.3329, G loss: 0.0003\n",
            "Step 148/390 - D loss: 4.3432, G loss: 0.0003\n",
            "Step 149/390 - D loss: 4.3421, G loss: 0.0003\n",
            "Step 150/390 - D loss: 4.3488, G loss: 0.0003\n",
            "Step 151/390 - D loss: 4.3587, G loss: 0.0003\n",
            "Step 152/390 - D loss: 4.3717, G loss: 0.0003\n",
            "Step 153/390 - D loss: 4.3760, G loss: 0.0003\n",
            "Step 154/390 - D loss: 4.3705, G loss: 0.0003\n",
            "Step 155/390 - D loss: 4.3748, G loss: 0.0003\n",
            "Step 156/390 - D loss: 4.3614, G loss: 0.0003\n",
            "Step 157/390 - D loss: 4.3638, G loss: 0.0003\n",
            "Step 158/390 - D loss: 4.3721, G loss: 0.0003\n",
            "Step 159/390 - D loss: 4.3796, G loss: 0.0003\n",
            "Step 160/390 - D loss: 4.3825, G loss: 0.0003\n",
            "Step 161/390 - D loss: 4.3876, G loss: 0.0003\n",
            "Step 162/390 - D loss: 4.4042, G loss: 0.0002\n",
            "Step 163/390 - D loss: 4.4028, G loss: 0.0003\n",
            "Step 164/390 - D loss: 4.4003, G loss: 0.0002\n",
            "Step 165/390 - D loss: 4.4131, G loss: 0.0002\n",
            "Step 166/390 - D loss: 4.4098, G loss: 0.0002\n",
            "Step 167/390 - D loss: 4.4491, G loss: 0.0002\n",
            "Step 168/390 - D loss: 4.3926, G loss: 0.0002\n",
            "Step 169/390 - D loss: 4.4426, G loss: 0.0002\n",
            "Step 170/390 - D loss: 4.4350, G loss: 0.0002\n",
            "Step 171/390 - D loss: 4.4171, G loss: 0.0002\n",
            "Step 172/390 - D loss: 4.4188, G loss: 0.0002\n",
            "Step 173/390 - D loss: 4.4523, G loss: 0.0002\n",
            "Step 174/390 - D loss: 4.4267, G loss: 0.0002\n",
            "Step 175/390 - D loss: 4.4325, G loss: 0.0002\n",
            "Step 176/390 - D loss: 4.4267, G loss: 0.0002\n",
            "Step 177/390 - D loss: 4.4490, G loss: 0.0002\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 178/390 - D loss: 4.4410, G loss: 0.0002\n",
            "Step 179/390 - D loss: 4.4366, G loss: 0.0002\n",
            "Step 180/390 - D loss: 4.4349, G loss: 0.0002\n",
            "Step 181/390 - D loss: 4.4206, G loss: 0.0002\n",
            "Step 182/390 - D loss: 4.4476, G loss: 0.0002\n",
            "Step 183/390 - D loss: 4.4279, G loss: 0.0002\n",
            "Step 184/390 - D loss: 4.4462, G loss: 0.0002\n",
            "Step 185/390 - D loss: 4.4308, G loss: 0.0002\n",
            "Step 186/390 - D loss: 4.4679, G loss: 0.0002\n",
            "Step 187/390 - D loss: 4.4227, G loss: 0.0002\n",
            "Step 188/390 - D loss: 4.4082, G loss: 0.0002\n",
            "Step 189/390 - D loss: 4.4300, G loss: 0.0002\n",
            "Step 190/390 - D loss: 4.4381, G loss: 0.0002\n",
            "Step 191/390 - D loss: 4.4140, G loss: 0.0002\n",
            "Step 192/390 - D loss: 4.4111, G loss: 0.0002\n",
            "Step 193/390 - D loss: 4.4027, G loss: 0.0002\n",
            "Step 194/390 - D loss: 4.4077, G loss: 0.0002\n",
            "Step 195/390 - D loss: 4.4152, G loss: 0.0002\n",
            "Step 196/390 - D loss: 4.4148, G loss: 0.0003\n",
            "Step 197/390 - D loss: 4.4174, G loss: 0.0003\n",
            "Step 198/390 - D loss: 4.4125, G loss: 0.0003\n",
            "Step 199/390 - D loss: 4.4015, G loss: 0.0003\n",
            "Step 200/390 - D loss: 4.3963, G loss: 0.0003\n",
            "Step 201/390 - D loss: 4.3854, G loss: 0.0003\n",
            "Step 202/390 - D loss: 4.4055, G loss: 0.0003\n",
            "Step 203/390 - D loss: 4.3854, G loss: 0.0003\n",
            "Step 204/390 - D loss: 4.4180, G loss: 0.0003\n",
            "Step 205/390 - D loss: 4.3950, G loss: 0.0003\n",
            "Step 206/390 - D loss: 4.3605, G loss: 0.0003\n",
            "Step 207/390 - D loss: 4.4021, G loss: 0.0003\n",
            "Step 208/390 - D loss: 4.3846, G loss: 0.0003\n",
            "Step 209/390 - D loss: 4.3863, G loss: 0.0003\n",
            "Step 210/390 - D loss: 4.3730, G loss: 0.0003\n",
            "Step 211/390 - D loss: 4.3646, G loss: 0.0003\n",
            "Step 212/390 - D loss: 4.3688, G loss: 0.0003\n",
            "Step 213/390 - D loss: 4.3610, G loss: 0.0003\n",
            "Step 214/390 - D loss: 4.3777, G loss: 0.0003\n",
            "Step 215/390 - D loss: 4.3700, G loss: 0.0003\n",
            "Step 216/390 - D loss: 4.3774, G loss: 0.0003\n",
            "Step 217/390 - D loss: 4.3656, G loss: 0.0003\n",
            "Step 218/390 - D loss: 4.3654, G loss: 0.0003\n",
            "Step 219/390 - D loss: 4.3671, G loss: 0.0003\n",
            "Step 220/390 - D loss: 4.3481, G loss: 0.0003\n",
            "Step 221/390 - D loss: 4.3684, G loss: 0.0003\n",
            "Step 222/390 - D loss: 4.3623, G loss: 0.0003\n",
            "Step 223/390 - D loss: 4.3687, G loss: 0.0003\n",
            "Step 224/390 - D loss: 4.3435, G loss: 0.0003\n",
            "Step 225/390 - D loss: 4.3590, G loss: 0.0003\n",
            "Step 226/390 - D loss: 4.3679, G loss: 0.0003\n",
            "Step 227/390 - D loss: 4.3409, G loss: 0.0003\n",
            "Step 228/390 - D loss: 4.3374, G loss: 0.0003\n",
            "Step 229/390 - D loss: 4.3263, G loss: 0.0003\n",
            "Step 230/390 - D loss: 4.3244, G loss: 0.0003\n",
            "Step 231/390 - D loss: 4.3249, G loss: 0.0003\n",
            "Step 232/390 - D loss: 4.3133, G loss: 0.0003\n",
            "Step 233/390 - D loss: 4.3221, G loss: 0.0003\n",
            "Step 234/390 - D loss: 4.3201, G loss: 0.0003\n",
            "Step 235/390 - D loss: 4.3294, G loss: 0.0003\n",
            "Step 236/390 - D loss: 4.3347, G loss: 0.0003\n",
            "Step 237/390 - D loss: 4.3306, G loss: 0.0003\n",
            "Step 238/390 - D loss: 4.3278, G loss: 0.0003\n",
            "Step 239/390 - D loss: 4.3245, G loss: 0.0003\n",
            "Step 240/390 - D loss: 4.3245, G loss: 0.0003\n",
            "Step 241/390 - D loss: 4.3288, G loss: 0.0003\n",
            "Step 242/390 - D loss: 4.3268, G loss: 0.0003\n",
            "Step 243/390 - D loss: 4.3184, G loss: 0.0003\n",
            "Step 244/390 - D loss: 4.3115, G loss: 0.0003\n",
            "Step 245/390 - D loss: 4.3031, G loss: 0.0003\n",
            "Step 246/390 - D loss: 4.3165, G loss: 0.0003\n",
            "Step 247/390 - D loss: 4.2969, G loss: 0.0003\n",
            "Step 248/390 - D loss: 4.3165, G loss: 0.0003\n",
            "Step 249/390 - D loss: 4.2919, G loss: 0.0003\n",
            "Step 250/390 - D loss: 4.3265, G loss: 0.0003\n",
            "Step 251/390 - D loss: 4.3456, G loss: 0.0003\n",
            "Step 252/390 - D loss: 4.3205, G loss: 0.0003\n",
            "Step 253/390 - D loss: 4.3093, G loss: 0.0003\n",
            "Step 254/390 - D loss: 4.3165, G loss: 0.0003\n",
            "Step 255/390 - D loss: 4.3221, G loss: 0.0003\n",
            "Step 256/390 - D loss: 4.3289, G loss: 0.0003\n",
            "Step 257/390 - D loss: 4.3161, G loss: 0.0003\n",
            "Step 258/390 - D loss: 4.3172, G loss: 0.0003\n",
            "Step 259/390 - D loss: 4.3091, G loss: 0.0003\n",
            "Step 260/390 - D loss: 4.3024, G loss: 0.0003\n",
            "Step 261/390 - D loss: 4.2946, G loss: 0.0003\n",
            "Step 262/390 - D loss: 4.3149, G loss: 0.0003\n",
            "Step 263/390 - D loss: 4.3207, G loss: 0.0003\n",
            "Step 264/390 - D loss: 4.3228, G loss: 0.0003\n",
            "Step 265/390 - D loss: 4.2968, G loss: 0.0003\n",
            "Step 266/390 - D loss: 4.2896, G loss: 0.0003\n",
            "Step 267/390 - D loss: 4.2978, G loss: 0.0003\n",
            "Step 268/390 - D loss: 4.3104, G loss: 0.0003\n",
            "Step 269/390 - D loss: 4.2960, G loss: 0.0003\n",
            "Step 270/390 - D loss: 4.2960, G loss: 0.0003\n",
            "Step 271/390 - D loss: 4.2926, G loss: 0.0003\n",
            "Step 272/390 - D loss: 4.3124, G loss: 0.0003\n",
            "Step 273/390 - D loss: 4.2863, G loss: 0.0003\n",
            "Step 274/390 - D loss: 4.2897, G loss: 0.0003\n",
            "Step 275/390 - D loss: 4.2910, G loss: 0.0003\n",
            "Step 276/390 - D loss: 4.2846, G loss: 0.0003\n",
            "Step 277/390 - D loss: 4.2923, G loss: 0.0003\n",
            "Step 278/390 - D loss: 4.2909, G loss: 0.0003\n",
            "Step 279/390 - D loss: 4.2966, G loss: 0.0003\n",
            "Step 280/390 - D loss: 4.2791, G loss: 0.0003\n",
            "Step 281/390 - D loss: 4.2812, G loss: 0.0003\n",
            "Step 282/390 - D loss: 4.2796, G loss: 0.0003\n",
            "Step 283/390 - D loss: 4.2713, G loss: 0.0003\n",
            "Step 284/390 - D loss: 4.2905, G loss: 0.0003\n",
            "Step 285/390 - D loss: 4.2989, G loss: 0.0003\n",
            "Step 286/390 - D loss: 4.2920, G loss: 0.0003\n",
            "Step 287/390 - D loss: 4.2824, G loss: 0.0003\n",
            "Step 288/390 - D loss: 4.2807, G loss: 0.0003\n",
            "Step 289/390 - D loss: 4.2710, G loss: 0.0003\n",
            "Step 290/390 - D loss: 4.2747, G loss: 0.0003\n",
            "Step 291/390 - D loss: 4.2711, G loss: 0.0003\n",
            "Step 292/390 - D loss: 4.2892, G loss: 0.0003\n",
            "Step 293/390 - D loss: 4.2923, G loss: 0.0003\n",
            "Step 294/390 - D loss: 4.2709, G loss: 0.0003\n",
            "Step 295/390 - D loss: 4.2788, G loss: 0.0003\n",
            "Step 296/390 - D loss: 4.2776, G loss: 0.0003\n",
            "Step 297/390 - D loss: 4.2670, G loss: 0.0003\n",
            "Step 298/390 - D loss: 4.2512, G loss: 0.0003\n",
            "Step 299/390 - D loss: 4.2555, G loss: 0.0003\n",
            "Step 300/390 - D loss: 4.2596, G loss: 0.0003\n",
            "Step 301/390 - D loss: 4.2661, G loss: 0.0003\n",
            "Step 302/390 - D loss: 4.2584, G loss: 0.0003\n",
            "Step 303/390 - D loss: 4.2694, G loss: 0.0003\n",
            "Step 304/390 - D loss: 4.2488, G loss: 0.0003\n",
            "Step 305/390 - D loss: 4.2604, G loss: 0.0003\n",
            "Step 306/390 - D loss: 4.2466, G loss: 0.0003\n",
            "Step 307/390 - D loss: 4.2595, G loss: 0.0003\n",
            "Step 308/390 - D loss: 4.2540, G loss: 0.0003\n",
            "Step 309/390 - D loss: 4.2620, G loss: 0.0003\n",
            "Step 310/390 - D loss: 4.2605, G loss: 0.0003\n",
            "Step 311/390 - D loss: 4.2352, G loss: 0.0003\n",
            "Step 312/390 - D loss: 4.2361, G loss: 0.0004\n",
            "Step 313/390 - D loss: 4.2483, G loss: 0.0004\n",
            "Step 314/390 - D loss: 4.2240, G loss: 0.0003\n",
            "Step 315/390 - D loss: 4.2376, G loss: 0.0004\n",
            "Step 316/390 - D loss: 4.2545, G loss: 0.0004\n",
            "Step 317/390 - D loss: 4.2323, G loss: 0.0004\n",
            "Step 318/390 - D loss: 4.2310, G loss: 0.0004\n",
            "Step 319/390 - D loss: 4.2555, G loss: 0.0004\n",
            "Step 320/390 - D loss: 4.2468, G loss: 0.0004\n",
            "Step 321/390 - D loss: 4.2228, G loss: 0.0004\n",
            "Step 322/390 - D loss: 4.2164, G loss: 0.0004\n",
            "Step 323/390 - D loss: 4.2157, G loss: 0.0004\n",
            "Step 324/390 - D loss: 4.2179, G loss: 0.0004\n",
            "Step 325/390 - D loss: 4.2013, G loss: 0.0004\n",
            "Step 326/390 - D loss: 4.2209, G loss: 0.0004\n",
            "Step 327/390 - D loss: 4.2189, G loss: 0.0004\n",
            "Step 328/390 - D loss: 4.2178, G loss: 0.0004\n",
            "Step 329/390 - D loss: 4.2308, G loss: 0.0004\n",
            "Step 330/390 - D loss: 4.2115, G loss: 0.0004\n",
            "Step 331/390 - D loss: 4.2147, G loss: 0.0004\n",
            "Step 332/390 - D loss: 4.2013, G loss: 0.0004\n",
            "Step 333/390 - D loss: 4.2096, G loss: 0.0004\n",
            "Step 334/390 - D loss: 4.2165, G loss: 0.0004\n",
            "Step 335/390 - D loss: 4.2085, G loss: 0.0004\n",
            "Step 336/390 - D loss: 4.2029, G loss: 0.0004\n",
            "Step 337/390 - D loss: 4.2128, G loss: 0.0004\n",
            "Step 338/390 - D loss: 4.2177, G loss: 0.0004\n",
            "Step 339/390 - D loss: 4.1756, G loss: 0.0004\n",
            "Step 340/390 - D loss: 4.2024, G loss: 0.0004\n",
            "Step 341/390 - D loss: 4.2128, G loss: 0.0004\n",
            "Step 342/390 - D loss: 4.1763, G loss: 0.0004\n",
            "Step 343/390 - D loss: 4.1871, G loss: 0.0004\n",
            "Step 344/390 - D loss: 4.2008, G loss: 0.0004\n",
            "Step 345/390 - D loss: 4.1899, G loss: 0.0004\n",
            "Step 346/390 - D loss: 4.2084, G loss: 0.0004\n",
            "Step 347/390 - D loss: 4.1935, G loss: 0.0004\n",
            "Step 348/390 - D loss: 4.1954, G loss: 0.0004\n",
            "Step 349/390 - D loss: 4.1765, G loss: 0.0004\n",
            "Step 350/390 - D loss: 4.1587, G loss: 0.0004\n",
            "Step 351/390 - D loss: 4.1934, G loss: 0.0004\n",
            "Step 352/390 - D loss: 4.1798, G loss: 0.0004\n",
            "Step 353/390 - D loss: 4.1921, G loss: 0.0004\n",
            "Step 354/390 - D loss: 4.1661, G loss: 0.0004\n",
            "Step 355/390 - D loss: 4.1617, G loss: 0.0004\n",
            "Step 356/390 - D loss: 4.1740, G loss: 0.0004\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 357/390 - D loss: 4.1463, G loss: 0.0004\n",
            "Step 358/390 - D loss: 4.1650, G loss: 0.0004\n",
            "Step 359/390 - D loss: 4.1527, G loss: 0.0004\n",
            "Step 360/390 - D loss: 4.1659, G loss: 0.0004\n",
            "Step 361/390 - D loss: 4.1626, G loss: 0.0004\n",
            "Step 362/390 - D loss: 4.1726, G loss: 0.0004\n",
            "Step 363/390 - D loss: 4.1501, G loss: 0.0004\n",
            "Step 364/390 - D loss: 4.1641, G loss: 0.0004\n",
            "Step 365/390 - D loss: 4.1491, G loss: 0.0004\n",
            "Step 366/390 - D loss: 4.1417, G loss: 0.0004\n",
            "Step 367/390 - D loss: 4.1600, G loss: 0.0004\n",
            "Step 368/390 - D loss: 4.1497, G loss: 0.0004\n",
            "Step 369/390 - D loss: 4.1454, G loss: 0.0004\n",
            "Step 370/390 - D loss: 4.1330, G loss: 0.0004\n",
            "Step 371/390 - D loss: 4.1224, G loss: 0.0004\n",
            "Step 372/390 - D loss: 4.1548, G loss: 0.0004\n",
            "Step 373/390 - D loss: 4.1436, G loss: 0.0004\n",
            "Step 374/390 - D loss: 4.1417, G loss: 0.0004\n",
            "Step 375/390 - D loss: 4.1240, G loss: 0.0004\n",
            "Step 376/390 - D loss: 4.1262, G loss: 0.0004\n",
            "Step 377/390 - D loss: 4.1383, G loss: 0.0004\n",
            "Step 378/390 - D loss: 4.1446, G loss: 0.0004\n",
            "Step 379/390 - D loss: 4.1252, G loss: 0.0004\n",
            "Step 380/390 - D loss: 4.1241, G loss: 0.0004\n",
            "Step 381/390 - D loss: 4.1137, G loss: 0.0004\n",
            "Step 382/390 - D loss: 4.1109, G loss: 0.0004\n",
            "Step 383/390 - D loss: 4.0860, G loss: 0.0004\n",
            "Step 384/390 - D loss: 4.1226, G loss: 0.0004\n",
            "Step 385/390 - D loss: 4.1221, G loss: 0.0004\n",
            "Step 386/390 - D loss: 4.1313, G loss: 0.0004\n",
            "Step 387/390 - D loss: 4.1288, G loss: 0.0004\n",
            "Step 388/390 - D loss: 4.0934, G loss: 0.0004\n",
            "Step 389/390 - D loss: 4.1030, G loss: 0.0005\n",
            "Step 390/390 - D loss: 4.0766, G loss: 0.0004\n",
            "Epoch 8/200\n",
            "Step 1/390 - D loss: 4.0914, G loss: 0.0005\n",
            "Step 2/390 - D loss: 4.1010, G loss: 0.0005\n",
            "Step 3/390 - D loss: 4.0901, G loss: 0.0005\n",
            "Step 4/390 - D loss: 4.0903, G loss: 0.0005\n",
            "Step 5/390 - D loss: 4.0867, G loss: 0.0005\n",
            "Step 6/390 - D loss: 4.0787, G loss: 0.0005\n",
            "Step 7/390 - D loss: 4.1211, G loss: 0.0005\n",
            "Step 8/390 - D loss: 4.1084, G loss: 0.0005\n",
            "Step 9/390 - D loss: 4.0943, G loss: 0.0005\n",
            "Step 10/390 - D loss: 4.0788, G loss: 0.0005\n",
            "Step 11/390 - D loss: 4.1079, G loss: 0.0005\n",
            "Step 12/390 - D loss: 4.1063, G loss: 0.0005\n",
            "Step 13/390 - D loss: 4.0933, G loss: 0.0005\n",
            "Step 14/390 - D loss: 4.1060, G loss: 0.0005\n",
            "Step 15/390 - D loss: 4.0846, G loss: 0.0005\n",
            "Step 16/390 - D loss: 4.0843, G loss: 0.0005\n",
            "Step 17/390 - D loss: 4.0898, G loss: 0.0005\n",
            "Step 18/390 - D loss: 4.0735, G loss: 0.0005\n",
            "Step 19/390 - D loss: 4.0769, G loss: 0.0005\n",
            "Step 20/390 - D loss: 4.0792, G loss: 0.0005\n",
            "Step 21/390 - D loss: 4.1060, G loss: 0.0005\n",
            "Step 22/390 - D loss: 4.0846, G loss: 0.0005\n",
            "Step 23/390 - D loss: 4.0975, G loss: 0.0005\n",
            "Step 24/390 - D loss: 4.0970, G loss: 0.0005\n",
            "Step 25/390 - D loss: 4.0738, G loss: 0.0005\n",
            "Step 26/390 - D loss: 4.0835, G loss: 0.0005\n",
            "Step 27/390 - D loss: 4.0665, G loss: 0.0005\n",
            "Step 28/390 - D loss: 4.0591, G loss: 0.0005\n",
            "Step 29/390 - D loss: 4.1013, G loss: 0.0005\n",
            "Step 30/390 - D loss: 4.0743, G loss: 0.0005\n",
            "Step 31/390 - D loss: 4.0650, G loss: 0.0005\n",
            "Step 32/390 - D loss: 4.0850, G loss: 0.0005\n",
            "Step 33/390 - D loss: 4.0648, G loss: 0.0005\n",
            "Step 34/390 - D loss: 4.0457, G loss: 0.0005\n",
            "Step 35/390 - D loss: 4.0469, G loss: 0.0005\n",
            "Step 36/390 - D loss: 4.0689, G loss: 0.0005\n",
            "Step 37/390 - D loss: 4.0847, G loss: 0.0005\n",
            "Step 38/390 - D loss: 4.0820, G loss: 0.0005\n",
            "Step 39/390 - D loss: 4.0706, G loss: 0.0005\n",
            "Step 40/390 - D loss: 4.0536, G loss: 0.0005\n",
            "Step 41/390 - D loss: 4.0641, G loss: 0.0005\n",
            "Step 42/390 - D loss: 4.0587, G loss: 0.0005\n",
            "Step 43/390 - D loss: 4.0608, G loss: 0.0005\n",
            "Step 44/390 - D loss: 4.0520, G loss: 0.0005\n",
            "Step 45/390 - D loss: 4.0486, G loss: 0.0005\n",
            "Step 46/390 - D loss: 4.0764, G loss: 0.0005\n",
            "Step 47/390 - D loss: 4.0697, G loss: 0.0005\n",
            "Step 48/390 - D loss: 4.0478, G loss: 0.0005\n",
            "Step 49/390 - D loss: 4.0292, G loss: 0.0005\n",
            "Step 50/390 - D loss: 4.0636, G loss: 0.0005\n",
            "Step 51/390 - D loss: 4.0448, G loss: 0.0005\n",
            "Step 52/390 - D loss: 4.0607, G loss: 0.0005\n",
            "Step 53/390 - D loss: 4.0462, G loss: 0.0005\n",
            "Step 54/390 - D loss: 4.0615, G loss: 0.0005\n",
            "Step 55/390 - D loss: 4.0524, G loss: 0.0005\n",
            "Step 56/390 - D loss: 4.0704, G loss: 0.0005\n",
            "Step 57/390 - D loss: 4.0618, G loss: 0.0005\n",
            "Step 58/390 - D loss: 4.0395, G loss: 0.0005\n",
            "Step 59/390 - D loss: 4.0458, G loss: 0.0005\n",
            "Step 60/390 - D loss: 4.0467, G loss: 0.0005\n",
            "Step 61/390 - D loss: 4.0454, G loss: 0.0005\n",
            "Step 62/390 - D loss: 4.0292, G loss: 0.0005\n",
            "Step 63/390 - D loss: 4.0514, G loss: 0.0005\n",
            "Step 64/390 - D loss: 4.0509, G loss: 0.0005\n",
            "Step 65/390 - D loss: 4.0474, G loss: 0.0005\n",
            "Step 66/390 - D loss: 4.0474, G loss: 0.0005\n",
            "Step 67/390 - D loss: 4.0403, G loss: 0.0005\n",
            "Step 68/390 - D loss: 4.0530, G loss: 0.0005\n",
            "Step 69/390 - D loss: 4.0448, G loss: 0.0005\n",
            "Step 70/390 - D loss: 4.0133, G loss: 0.0005\n",
            "Step 71/390 - D loss: 4.0424, G loss: 0.0005\n",
            "Step 72/390 - D loss: 4.0448, G loss: 0.0005\n",
            "Step 73/390 - D loss: 4.0447, G loss: 0.0005\n",
            "Step 74/390 - D loss: 4.0538, G loss: 0.0005\n",
            "Step 75/390 - D loss: 4.0337, G loss: 0.0005\n",
            "Step 76/390 - D loss: 4.0462, G loss: 0.0005\n",
            "Step 77/390 - D loss: 4.0369, G loss: 0.0005\n",
            "Step 78/390 - D loss: 4.0551, G loss: 0.0005\n",
            "Step 79/390 - D loss: 4.0327, G loss: 0.0005\n",
            "Step 80/390 - D loss: 4.0817, G loss: 0.0005\n",
            "Step 81/390 - D loss: 4.0196, G loss: 0.0005\n",
            "Step 82/390 - D loss: 4.0148, G loss: 0.0005\n",
            "Step 83/390 - D loss: 4.0407, G loss: 0.0005\n",
            "Step 84/390 - D loss: 4.0295, G loss: 0.0005\n",
            "Step 85/390 - D loss: 4.0404, G loss: 0.0005\n",
            "Step 86/390 - D loss: 4.0156, G loss: 0.0005\n",
            "Step 87/390 - D loss: 4.0440, G loss: 0.0005\n",
            "Step 88/390 - D loss: 4.0312, G loss: 0.0005\n",
            "Step 89/390 - D loss: 4.0227, G loss: 0.0005\n",
            "Step 90/390 - D loss: 4.0218, G loss: 0.0005\n",
            "Step 91/390 - D loss: 4.0039, G loss: 0.0005\n",
            "Step 92/390 - D loss: 4.0308, G loss: 0.0005\n",
            "Step 93/390 - D loss: 4.0252, G loss: 0.0005\n",
            "Step 94/390 - D loss: 4.0283, G loss: 0.0005\n",
            "Step 95/390 - D loss: 4.0138, G loss: 0.0005\n",
            "Step 96/390 - D loss: 4.0581, G loss: 0.0005\n",
            "Step 97/390 - D loss: 4.0243, G loss: 0.0005\n",
            "Step 98/390 - D loss: 4.0382, G loss: 0.0005\n",
            "Step 99/390 - D loss: 4.0180, G loss: 0.0005\n",
            "Step 100/390 - D loss: 4.0168, G loss: 0.0005\n",
            "Step 101/390 - D loss: 4.0182, G loss: 0.0005\n",
            "Step 102/390 - D loss: 4.0273, G loss: 0.0005\n",
            "Step 103/390 - D loss: 4.0214, G loss: 0.0005\n",
            "Step 104/390 - D loss: 4.0429, G loss: 0.0005\n",
            "Step 105/390 - D loss: 4.0446, G loss: 0.0005\n",
            "Step 106/390 - D loss: 4.0361, G loss: 0.0005\n",
            "Step 107/390 - D loss: 4.0420, G loss: 0.0005\n",
            "Step 108/390 - D loss: 4.0319, G loss: 0.0005\n",
            "Step 109/390 - D loss: 4.0379, G loss: 0.0005\n",
            "Step 110/390 - D loss: 4.0423, G loss: 0.0005\n",
            "Step 111/390 - D loss: 4.0511, G loss: 0.0005\n",
            "Step 112/390 - D loss: 4.0486, G loss: 0.0005\n",
            "Step 113/390 - D loss: 4.0317, G loss: 0.0005\n",
            "Step 114/390 - D loss: 4.0186, G loss: 0.0005\n",
            "Step 115/390 - D loss: 4.0145, G loss: 0.0005\n",
            "Step 116/390 - D loss: 4.0222, G loss: 0.0005\n",
            "Step 117/390 - D loss: 4.0296, G loss: 0.0005\n",
            "Step 118/390 - D loss: 4.0300, G loss: 0.0005\n",
            "Step 119/390 - D loss: 4.0181, G loss: 0.0005\n",
            "Step 120/390 - D loss: 4.0477, G loss: 0.0005\n",
            "Step 121/390 - D loss: 4.0201, G loss: 0.0005\n",
            "Step 122/390 - D loss: 4.0394, G loss: 0.0005\n",
            "Step 123/390 - D loss: 4.0382, G loss: 0.0005\n",
            "Step 124/390 - D loss: 4.0297, G loss: 0.0005\n",
            "Step 125/390 - D loss: 4.0397, G loss: 0.0005\n",
            "Step 126/390 - D loss: 4.0512, G loss: 0.0005\n",
            "Step 127/390 - D loss: 4.0456, G loss: 0.0005\n",
            "Step 128/390 - D loss: 4.0176, G loss: 0.0005\n",
            "Step 129/390 - D loss: 4.0286, G loss: 0.0005\n",
            "Step 130/390 - D loss: 4.0202, G loss: 0.0005\n",
            "Step 131/390 - D loss: 4.0699, G loss: 0.0005\n",
            "Step 132/390 - D loss: 4.0411, G loss: 0.0005\n",
            "Step 133/390 - D loss: 4.0228, G loss: 0.0005\n",
            "Step 134/390 - D loss: 4.0136, G loss: 0.0005\n",
            "Step 135/390 - D loss: 4.0471, G loss: 0.0005\n",
            "Step 136/390 - D loss: 4.0523, G loss: 0.0005\n",
            "Step 137/390 - D loss: 4.0499, G loss: 0.0005\n",
            "Step 138/390 - D loss: 4.0336, G loss: 0.0005\n",
            "Step 139/390 - D loss: 4.0244, G loss: 0.0005\n",
            "Step 140/390 - D loss: 4.0043, G loss: 0.0005\n",
            "Step 141/390 - D loss: 4.0389, G loss: 0.0005\n",
            "Step 142/390 - D loss: 4.0159, G loss: 0.0005\n",
            "Step 143/390 - D loss: 4.0503, G loss: 0.0005\n",
            "Step 144/390 - D loss: 4.0431, G loss: 0.0005\n",
            "Step 145/390 - D loss: 4.0396, G loss: 0.0005\n",
            "Step 146/390 - D loss: 4.0402, G loss: 0.0005\n",
            "Step 147/390 - D loss: 4.0363, G loss: 0.0005\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 148/390 - D loss: 4.0223, G loss: 0.0005\n",
            "Step 149/390 - D loss: 4.0233, G loss: 0.0005\n",
            "Step 150/390 - D loss: 4.0373, G loss: 0.0005\n",
            "Step 151/390 - D loss: 4.0227, G loss: 0.0005\n",
            "Step 152/390 - D loss: 4.0164, G loss: 0.0005\n",
            "Step 153/390 - D loss: 4.0173, G loss: 0.0005\n",
            "Step 154/390 - D loss: 4.0451, G loss: 0.0005\n",
            "Step 155/390 - D loss: 4.0333, G loss: 0.0005\n",
            "Step 156/390 - D loss: 4.0262, G loss: 0.0005\n",
            "Step 157/390 - D loss: 4.0242, G loss: 0.0005\n",
            "Step 158/390 - D loss: 4.0362, G loss: 0.0005\n",
            "Step 159/390 - D loss: 4.0446, G loss: 0.0005\n",
            "Step 160/390 - D loss: 4.0403, G loss: 0.0005\n",
            "Step 161/390 - D loss: 4.0119, G loss: 0.0005\n",
            "Step 162/390 - D loss: 4.0412, G loss: 0.0005\n",
            "Step 163/390 - D loss: 4.0332, G loss: 0.0005\n",
            "Step 164/390 - D loss: 4.0217, G loss: 0.0005\n",
            "Step 165/390 - D loss: 4.0096, G loss: 0.0005\n",
            "Step 166/390 - D loss: 4.0290, G loss: 0.0005\n",
            "Step 167/390 - D loss: 4.0150, G loss: 0.0005\n",
            "Step 168/390 - D loss: 4.0049, G loss: 0.0005\n",
            "Step 169/390 - D loss: 4.0144, G loss: 0.0005\n",
            "Step 170/390 - D loss: 4.0285, G loss: 0.0005\n",
            "Step 171/390 - D loss: 4.0227, G loss: 0.0005\n",
            "Step 172/390 - D loss: 3.9951, G loss: 0.0005\n",
            "Step 173/390 - D loss: 4.0043, G loss: 0.0005\n",
            "Step 174/390 - D loss: 4.0203, G loss: 0.0005\n",
            "Step 175/390 - D loss: 4.0282, G loss: 0.0005\n",
            "Step 176/390 - D loss: 4.0291, G loss: 0.0005\n",
            "Step 177/390 - D loss: 4.0244, G loss: 0.0005\n",
            "Step 178/390 - D loss: 4.0228, G loss: 0.0005\n",
            "Step 179/390 - D loss: 3.9979, G loss: 0.0005\n",
            "Step 180/390 - D loss: 4.0125, G loss: 0.0005\n",
            "Step 181/390 - D loss: 4.0177, G loss: 0.0005\n",
            "Step 182/390 - D loss: 4.0119, G loss: 0.0005\n",
            "Step 183/390 - D loss: 4.0176, G loss: 0.0005\n",
            "Step 184/390 - D loss: 4.0195, G loss: 0.0005\n",
            "Step 185/390 - D loss: 3.9983, G loss: 0.0005\n",
            "Step 186/390 - D loss: 4.0070, G loss: 0.0005\n",
            "Step 187/390 - D loss: 4.0231, G loss: 0.0005\n",
            "Step 188/390 - D loss: 4.0138, G loss: 0.0005\n",
            "Step 189/390 - D loss: 3.9914, G loss: 0.0005\n",
            "Step 190/390 - D loss: 4.0087, G loss: 0.0005\n",
            "Step 191/390 - D loss: 3.9922, G loss: 0.0005\n",
            "Step 192/390 - D loss: 4.0105, G loss: 0.0005\n",
            "Step 193/390 - D loss: 3.9875, G loss: 0.0005\n",
            "Step 194/390 - D loss: 3.9934, G loss: 0.0005\n",
            "Step 195/390 - D loss: 3.9888, G loss: 0.0005\n",
            "Step 196/390 - D loss: 4.0015, G loss: 0.0005\n",
            "Step 197/390 - D loss: 3.9930, G loss: 0.0005\n",
            "Step 198/390 - D loss: 3.9988, G loss: 0.0005\n",
            "Step 199/390 - D loss: 4.0005, G loss: 0.0005\n",
            "Step 200/390 - D loss: 4.0062, G loss: 0.0005\n",
            "Step 201/390 - D loss: 3.9840, G loss: 0.0005\n",
            "Step 202/390 - D loss: 3.9785, G loss: 0.0005\n",
            "Step 203/390 - D loss: 3.9987, G loss: 0.0005\n",
            "Step 204/390 - D loss: 3.9874, G loss: 0.0005\n",
            "Step 205/390 - D loss: 3.9810, G loss: 0.0005\n",
            "Step 206/390 - D loss: 3.9915, G loss: 0.0005\n",
            "Step 207/390 - D loss: 3.9715, G loss: 0.0005\n",
            "Step 208/390 - D loss: 3.9952, G loss: 0.0005\n",
            "Step 209/390 - D loss: 3.9698, G loss: 0.0006\n",
            "Step 210/390 - D loss: 3.9880, G loss: 0.0005\n",
            "Step 211/390 - D loss: 3.9739, G loss: 0.0005\n",
            "Step 212/390 - D loss: 3.9756, G loss: 0.0006\n",
            "Step 213/390 - D loss: 3.9591, G loss: 0.0006\n",
            "Step 214/390 - D loss: 3.9935, G loss: 0.0006\n",
            "Step 215/390 - D loss: 3.9804, G loss: 0.0006\n",
            "Step 216/390 - D loss: 3.9644, G loss: 0.0006\n",
            "Step 217/390 - D loss: 3.9758, G loss: 0.0006\n",
            "Step 218/390 - D loss: 3.9837, G loss: 0.0006\n",
            "Step 219/390 - D loss: 3.9686, G loss: 0.0006\n",
            "Step 220/390 - D loss: 3.9534, G loss: 0.0006\n",
            "Step 221/390 - D loss: 3.9647, G loss: 0.0006\n",
            "Step 222/390 - D loss: 3.9756, G loss: 0.0006\n",
            "Step 223/390 - D loss: 3.9762, G loss: 0.0006\n",
            "Step 224/390 - D loss: 3.9694, G loss: 0.0006\n",
            "Step 225/390 - D loss: 3.9742, G loss: 0.0006\n",
            "Step 226/390 - D loss: 3.9722, G loss: 0.0006\n",
            "Step 227/390 - D loss: 3.9538, G loss: 0.0006\n",
            "Step 228/390 - D loss: 3.9655, G loss: 0.0006\n",
            "Step 229/390 - D loss: 3.9685, G loss: 0.0006\n",
            "Step 230/390 - D loss: 3.9467, G loss: 0.0006\n",
            "Step 231/390 - D loss: 3.9355, G loss: 0.0006\n",
            "Step 232/390 - D loss: 3.9578, G loss: 0.0006\n",
            "Step 233/390 - D loss: 3.9573, G loss: 0.0006\n",
            "Step 234/390 - D loss: 3.9580, G loss: 0.0006\n",
            "Step 235/390 - D loss: 3.9550, G loss: 0.0006\n",
            "Step 236/390 - D loss: 3.9589, G loss: 0.0006\n",
            "Step 237/390 - D loss: 3.9793, G loss: 0.0006\n",
            "Step 238/390 - D loss: 3.9683, G loss: 0.0006\n",
            "Step 239/390 - D loss: 3.9500, G loss: 0.0006\n",
            "Step 240/390 - D loss: 3.9669, G loss: 0.0006\n",
            "Step 241/390 - D loss: 3.9427, G loss: 0.0006\n",
            "Step 242/390 - D loss: 3.9178, G loss: 0.0006\n",
            "Step 243/390 - D loss: 3.9479, G loss: 0.0006\n",
            "Step 244/390 - D loss: 3.9401, G loss: 0.0006\n",
            "Step 245/390 - D loss: 3.9354, G loss: 0.0006\n",
            "Step 246/390 - D loss: 3.9570, G loss: 0.0006\n",
            "Step 247/390 - D loss: 3.9628, G loss: 0.0006\n",
            "Step 248/390 - D loss: 3.9543, G loss: 0.0006\n",
            "Step 249/390 - D loss: 3.9520, G loss: 0.0006\n",
            "Step 250/390 - D loss: 3.9360, G loss: 0.0006\n",
            "Step 251/390 - D loss: 3.9446, G loss: 0.0006\n",
            "Step 252/390 - D loss: 3.9257, G loss: 0.0006\n",
            "Step 253/390 - D loss: 3.9744, G loss: 0.0006\n",
            "Step 254/390 - D loss: 3.9459, G loss: 0.0006\n",
            "Step 255/390 - D loss: 3.9398, G loss: 0.0006\n",
            "Step 256/390 - D loss: 3.9406, G loss: 0.0006\n",
            "Step 257/390 - D loss: 3.9460, G loss: 0.0006\n",
            "Step 258/390 - D loss: 3.9221, G loss: 0.0006\n",
            "Step 259/390 - D loss: 3.9454, G loss: 0.0006\n",
            "Step 260/390 - D loss: 3.9316, G loss: 0.0006\n",
            "Step 261/390 - D loss: 3.9206, G loss: 0.0006\n",
            "Step 262/390 - D loss: 3.9460, G loss: 0.0006\n",
            "Step 263/390 - D loss: 3.9334, G loss: 0.0006\n",
            "Step 264/390 - D loss: 3.9355, G loss: 0.0006\n",
            "Step 265/390 - D loss: 3.9493, G loss: 0.0006\n",
            "Step 266/390 - D loss: 3.9216, G loss: 0.0006\n",
            "Step 267/390 - D loss: 3.9232, G loss: 0.0006\n",
            "Step 268/390 - D loss: 3.9177, G loss: 0.0006\n",
            "Step 269/390 - D loss: 3.9290, G loss: 0.0006\n",
            "Step 270/390 - D loss: 3.9236, G loss: 0.0006\n",
            "Step 271/390 - D loss: 3.9246, G loss: 0.0006\n",
            "Step 272/390 - D loss: 3.9280, G loss: 0.0006\n",
            "Step 273/390 - D loss: 3.9256, G loss: 0.0006\n",
            "Step 274/390 - D loss: 3.9016, G loss: 0.0006\n",
            "Step 275/390 - D loss: 3.9042, G loss: 0.0006\n",
            "Step 276/390 - D loss: 3.8881, G loss: 0.0006\n",
            "Step 277/390 - D loss: 3.9107, G loss: 0.0006\n",
            "Step 278/390 - D loss: 3.9044, G loss: 0.0006\n",
            "Step 279/390 - D loss: 3.9088, G loss: 0.0006\n",
            "Step 280/390 - D loss: 3.9226, G loss: 0.0006\n",
            "Step 281/390 - D loss: 3.9211, G loss: 0.0006\n",
            "Step 282/390 - D loss: 3.9132, G loss: 0.0006\n",
            "Step 283/390 - D loss: 3.9268, G loss: 0.0006\n",
            "Step 284/390 - D loss: 3.9047, G loss: 0.0006\n",
            "Step 285/390 - D loss: 3.9122, G loss: 0.0006\n",
            "Step 286/390 - D loss: 3.9225, G loss: 0.0006\n",
            "Step 287/390 - D loss: 3.8859, G loss: 0.0006\n",
            "Step 288/390 - D loss: 3.8951, G loss: 0.0006\n",
            "Step 289/390 - D loss: 3.9161, G loss: 0.0006\n",
            "Step 290/390 - D loss: 3.9334, G loss: 0.0006\n",
            "Step 291/390 - D loss: 3.8893, G loss: 0.0006\n",
            "Step 292/390 - D loss: 3.9167, G loss: 0.0006\n",
            "Step 293/390 - D loss: 3.8989, G loss: 0.0006\n",
            "Step 294/390 - D loss: 3.9022, G loss: 0.0006\n",
            "Step 295/390 - D loss: 3.9188, G loss: 0.0006\n",
            "Step 296/390 - D loss: 3.8910, G loss: 0.0006\n",
            "Step 297/390 - D loss: 3.8879, G loss: 0.0006\n",
            "Step 298/390 - D loss: 3.8965, G loss: 0.0006\n",
            "Step 299/390 - D loss: 3.9060, G loss: 0.0006\n",
            "Step 300/390 - D loss: 3.9017, G loss: 0.0006\n",
            "Step 301/390 - D loss: 3.9036, G loss: 0.0006\n",
            "Step 302/390 - D loss: 3.8993, G loss: 0.0006\n",
            "Step 303/390 - D loss: 3.8989, G loss: 0.0006\n",
            "Step 304/390 - D loss: 3.9023, G loss: 0.0006\n",
            "Step 305/390 - D loss: 3.8868, G loss: 0.0006\n",
            "Step 306/390 - D loss: 3.9082, G loss: 0.0006\n",
            "Step 307/390 - D loss: 3.8868, G loss: 0.0006\n",
            "Step 308/390 - D loss: 3.8899, G loss: 0.0006\n",
            "Step 309/390 - D loss: 3.8977, G loss: 0.0006\n",
            "Step 310/390 - D loss: 3.8794, G loss: 0.0006\n",
            "Step 311/390 - D loss: 3.8917, G loss: 0.0006\n",
            "Step 312/390 - D loss: 3.8916, G loss: 0.0006\n",
            "Step 313/390 - D loss: 3.8972, G loss: 0.0006\n",
            "Step 314/390 - D loss: 3.8686, G loss: 0.0006\n",
            "Step 315/390 - D loss: 3.8900, G loss: 0.0006\n",
            "Step 316/390 - D loss: 3.8891, G loss: 0.0006\n",
            "Step 317/390 - D loss: 3.8905, G loss: 0.0006\n",
            "Step 318/390 - D loss: 3.8745, G loss: 0.0006\n",
            "Step 319/390 - D loss: 3.8838, G loss: 0.0006\n",
            "Step 320/390 - D loss: 3.8737, G loss: 0.0006\n",
            "Step 321/390 - D loss: 3.8932, G loss: 0.0006\n",
            "Step 322/390 - D loss: 3.8826, G loss: 0.0006\n",
            "Step 323/390 - D loss: 3.8857, G loss: 0.0006\n",
            "Step 324/390 - D loss: 3.8754, G loss: 0.0006\n",
            "Step 325/390 - D loss: 3.8761, G loss: 0.0006\n",
            "Step 326/390 - D loss: 3.8734, G loss: 0.0006\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 327/390 - D loss: 3.8892, G loss: 0.0006\n",
            "Step 328/390 - D loss: 3.8938, G loss: 0.0006\n",
            "Step 329/390 - D loss: 3.8792, G loss: 0.0006\n",
            "Step 330/390 - D loss: 3.8828, G loss: 0.0006\n",
            "Step 331/390 - D loss: 3.8593, G loss: 0.0006\n",
            "Step 332/390 - D loss: 3.8633, G loss: 0.0006\n",
            "Step 333/390 - D loss: 3.8568, G loss: 0.0006\n",
            "Step 334/390 - D loss: 3.8675, G loss: 0.0006\n",
            "Step 335/390 - D loss: 3.8703, G loss: 0.0006\n",
            "Step 336/390 - D loss: 3.8808, G loss: 0.0007\n",
            "Step 337/390 - D loss: 3.8630, G loss: 0.0007\n",
            "Step 338/390 - D loss: 3.8674, G loss: 0.0007\n",
            "Step 339/390 - D loss: 3.8502, G loss: 0.0007\n",
            "Step 340/390 - D loss: 3.8666, G loss: 0.0007\n",
            "Step 341/390 - D loss: 3.8672, G loss: 0.0007\n",
            "Step 342/390 - D loss: 3.8803, G loss: 0.0007\n",
            "Step 343/390 - D loss: 3.8587, G loss: 0.0007\n",
            "Step 344/390 - D loss: 3.8855, G loss: 0.0007\n",
            "Step 345/390 - D loss: 3.8688, G loss: 0.0007\n",
            "Step 346/390 - D loss: 3.8758, G loss: 0.0007\n",
            "Step 347/390 - D loss: 3.8757, G loss: 0.0007\n",
            "Step 348/390 - D loss: 3.8691, G loss: 0.0007\n",
            "Step 349/390 - D loss: 3.8749, G loss: 0.0007\n",
            "Step 350/390 - D loss: 3.8617, G loss: 0.0007\n",
            "Step 351/390 - D loss: 3.8523, G loss: 0.0007\n",
            "Step 352/390 - D loss: 3.8647, G loss: 0.0007\n",
            "Step 353/390 - D loss: 3.8584, G loss: 0.0007\n",
            "Step 354/390 - D loss: 3.8480, G loss: 0.0007\n",
            "Step 355/390 - D loss: 3.8472, G loss: 0.0007\n",
            "Step 356/390 - D loss: 3.8545, G loss: 0.0007\n",
            "Step 357/390 - D loss: 3.8501, G loss: 0.0007\n",
            "Step 358/390 - D loss: 3.8615, G loss: 0.0007\n",
            "Step 359/390 - D loss: 3.8561, G loss: 0.0007\n",
            "Step 360/390 - D loss: 3.8482, G loss: 0.0007\n",
            "Step 361/390 - D loss: 3.8696, G loss: 0.0007\n",
            "Step 362/390 - D loss: 3.8414, G loss: 0.0007\n",
            "Step 363/390 - D loss: 3.8660, G loss: 0.0007\n",
            "Step 364/390 - D loss: 3.8605, G loss: 0.0007\n",
            "Step 365/390 - D loss: 3.8534, G loss: 0.0007\n",
            "Step 366/390 - D loss: 3.8553, G loss: 0.0007\n",
            "Step 367/390 - D loss: 3.8547, G loss: 0.0007\n",
            "Step 368/390 - D loss: 3.8460, G loss: 0.0007\n",
            "Step 369/390 - D loss: 3.8613, G loss: 0.0007\n",
            "Step 370/390 - D loss: 3.8504, G loss: 0.0007\n",
            "Step 371/390 - D loss: 3.8678, G loss: 0.0007\n",
            "Step 372/390 - D loss: 3.8559, G loss: 0.0007\n",
            "Step 373/390 - D loss: 3.8426, G loss: 0.0007\n",
            "Step 374/390 - D loss: 3.8468, G loss: 0.0007\n",
            "Step 375/390 - D loss: 3.8308, G loss: 0.0007\n",
            "Step 376/390 - D loss: 3.8335, G loss: 0.0007\n",
            "Step 377/390 - D loss: 3.8376, G loss: 0.0007\n",
            "Step 378/390 - D loss: 3.8456, G loss: 0.0007\n",
            "Step 379/390 - D loss: 3.8309, G loss: 0.0007\n",
            "Step 380/390 - D loss: 3.8509, G loss: 0.0007\n",
            "Step 381/390 - D loss: 3.8501, G loss: 0.0007\n",
            "Step 382/390 - D loss: 3.8271, G loss: 0.0007\n",
            "Step 383/390 - D loss: 3.8299, G loss: 0.0007\n",
            "Step 384/390 - D loss: 3.8463, G loss: 0.0007\n",
            "Step 385/390 - D loss: 3.8338, G loss: 0.0007\n",
            "Step 386/390 - D loss: 3.8362, G loss: 0.0007\n",
            "Step 387/390 - D loss: 3.8198, G loss: 0.0007\n",
            "Step 388/390 - D loss: 3.8434, G loss: 0.0007\n",
            "Step 389/390 - D loss: 3.8381, G loss: 0.0007\n",
            "Step 390/390 - D loss: 3.8388, G loss: 0.0007\n",
            "Epoch 9/200\n",
            "Step 1/390 - D loss: 3.8453, G loss: 0.0007\n",
            "Step 2/390 - D loss: 3.8263, G loss: 0.0007\n",
            "Step 3/390 - D loss: 3.8411, G loss: 0.0007\n",
            "Step 4/390 - D loss: 3.8434, G loss: 0.0007\n",
            "Step 5/390 - D loss: 3.8311, G loss: 0.0007\n",
            "Step 6/390 - D loss: 3.8473, G loss: 0.0007\n",
            "Step 7/390 - D loss: 3.8360, G loss: 0.0007\n",
            "Step 8/390 - D loss: 3.8447, G loss: 0.0007\n",
            "Step 9/390 - D loss: 3.8430, G loss: 0.0007\n",
            "Step 10/390 - D loss: 3.8099, G loss: 0.0007\n",
            "Step 11/390 - D loss: 3.8239, G loss: 0.0007\n",
            "Step 12/390 - D loss: 3.8281, G loss: 0.0007\n",
            "Step 13/390 - D loss: 3.8424, G loss: 0.0007\n",
            "Step 14/390 - D loss: 3.8216, G loss: 0.0007\n",
            "Step 15/390 - D loss: 3.8205, G loss: 0.0007\n",
            "Step 16/390 - D loss: 3.8358, G loss: 0.0007\n",
            "Step 17/390 - D loss: 3.8233, G loss: 0.0007\n",
            "Step 18/390 - D loss: 3.8111, G loss: 0.0007\n",
            "Step 19/390 - D loss: 3.8244, G loss: 0.0007\n",
            "Step 20/390 - D loss: 3.8350, G loss: 0.0007\n",
            "Step 21/390 - D loss: 3.8355, G loss: 0.0007\n",
            "Step 22/390 - D loss: 3.8280, G loss: 0.0007\n",
            "Step 23/390 - D loss: 3.8278, G loss: 0.0007\n",
            "Step 24/390 - D loss: 3.8250, G loss: 0.0007\n",
            "Step 25/390 - D loss: 3.8355, G loss: 0.0007\n",
            "Step 26/390 - D loss: 3.7887, G loss: 0.0007\n",
            "Step 27/390 - D loss: 3.7917, G loss: 0.0007\n",
            "Step 28/390 - D loss: 3.8340, G loss: 0.0007\n",
            "Step 29/390 - D loss: 3.8206, G loss: 0.0007\n",
            "Step 30/390 - D loss: 3.8188, G loss: 0.0007\n",
            "Step 31/390 - D loss: 3.8299, G loss: 0.0007\n",
            "Step 32/390 - D loss: 3.8304, G loss: 0.0007\n",
            "Step 33/390 - D loss: 3.8256, G loss: 0.0007\n",
            "Step 34/390 - D loss: 3.8202, G loss: 0.0007\n",
            "Step 35/390 - D loss: 3.8282, G loss: 0.0007\n",
            "Step 36/390 - D loss: 3.8307, G loss: 0.0007\n",
            "Step 37/390 - D loss: 3.8421, G loss: 0.0007\n",
            "Step 38/390 - D loss: 3.8395, G loss: 0.0007\n",
            "Step 39/390 - D loss: 3.8370, G loss: 0.0006\n",
            "Step 40/390 - D loss: 3.8696, G loss: 0.0006\n",
            "Step 41/390 - D loss: 3.8631, G loss: 0.0006\n",
            "Step 42/390 - D loss: 3.9140, G loss: 0.0006\n",
            "Step 43/390 - D loss: 3.9317, G loss: 0.0005\n",
            "Step 44/390 - D loss: 3.9449, G loss: 0.0005\n",
            "Step 45/390 - D loss: 3.9830, G loss: 0.0005\n",
            "Step 46/390 - D loss: 3.9527, G loss: 0.0005\n",
            "Step 47/390 - D loss: 4.0115, G loss: 0.0005\n",
            "Step 48/390 - D loss: 4.0316, G loss: 0.0005\n",
            "Step 49/390 - D loss: 4.0363, G loss: 0.0004\n",
            "Step 50/390 - D loss: 4.0583, G loss: 0.0004\n",
            "Step 51/390 - D loss: 4.0749, G loss: 0.0004\n",
            "Step 52/390 - D loss: 4.1182, G loss: 0.0004\n",
            "Step 53/390 - D loss: 4.1076, G loss: 0.0004\n",
            "Step 54/390 - D loss: 4.1525, G loss: 0.0004\n",
            "Step 55/390 - D loss: 4.1574, G loss: 0.0003\n",
            "Step 56/390 - D loss: 4.1813, G loss: 0.0003\n",
            "Step 57/390 - D loss: 4.1671, G loss: 0.0003\n",
            "Step 58/390 - D loss: 4.1971, G loss: 0.0003\n",
            "Step 59/390 - D loss: 4.2056, G loss: 0.0003\n",
            "Step 60/390 - D loss: 4.2246, G loss: 0.0003\n",
            "Step 61/390 - D loss: 4.2373, G loss: 0.0003\n",
            "Step 62/390 - D loss: 4.2474, G loss: 0.0003\n",
            "Step 63/390 - D loss: 4.2463, G loss: 0.0003\n",
            "Step 64/390 - D loss: 4.2489, G loss: 0.0003\n",
            "Step 65/390 - D loss: 4.2730, G loss: 0.0003\n",
            "Step 66/390 - D loss: 4.2770, G loss: 0.0003\n",
            "Step 67/390 - D loss: 4.2889, G loss: 0.0003\n",
            "Step 68/390 - D loss: 4.3076, G loss: 0.0003\n",
            "Step 69/390 - D loss: 4.3069, G loss: 0.0003\n",
            "Step 70/390 - D loss: 4.3128, G loss: 0.0003\n",
            "Step 71/390 - D loss: 4.3153, G loss: 0.0003\n",
            "Step 72/390 - D loss: 4.3307, G loss: 0.0003\n",
            "Step 73/390 - D loss: 4.3417, G loss: 0.0002\n",
            "Step 74/390 - D loss: 4.3304, G loss: 0.0002\n",
            "Step 75/390 - D loss: 4.3243, G loss: 0.0002\n",
            "Step 76/390 - D loss: 4.3401, G loss: 0.0002\n",
            "Step 77/390 - D loss: 4.3376, G loss: 0.0002\n",
            "Step 78/390 - D loss: 4.3433, G loss: 0.0002\n",
            "Step 79/390 - D loss: 4.3523, G loss: 0.0002\n",
            "Step 80/390 - D loss: 4.3492, G loss: 0.0002\n",
            "Step 81/390 - D loss: 4.3586, G loss: 0.0002\n",
            "Step 82/390 - D loss: 4.3456, G loss: 0.0002\n",
            "Step 83/390 - D loss: 4.3344, G loss: 0.0002\n",
            "Step 84/390 - D loss: 4.3527, G loss: 0.0002\n",
            "Step 85/390 - D loss: 4.3300, G loss: 0.0002\n",
            "Step 86/390 - D loss: 4.3307, G loss: 0.0002\n",
            "Step 87/390 - D loss: 4.3551, G loss: 0.0002\n",
            "Step 88/390 - D loss: 4.3403, G loss: 0.0002\n",
            "Step 89/390 - D loss: 4.3609, G loss: 0.0002\n",
            "Step 90/390 - D loss: 4.3533, G loss: 0.0002\n",
            "Step 91/390 - D loss: 4.3294, G loss: 0.0002\n",
            "Step 92/390 - D loss: 4.3261, G loss: 0.0002\n",
            "Step 93/390 - D loss: 4.3262, G loss: 0.0002\n",
            "Step 94/390 - D loss: 4.3271, G loss: 0.0002\n",
            "Step 95/390 - D loss: 4.3201, G loss: 0.0002\n",
            "Step 96/390 - D loss: 4.2995, G loss: 0.0002\n",
            "Step 97/390 - D loss: 4.3259, G loss: 0.0003\n",
            "Step 98/390 - D loss: 4.3106, G loss: 0.0003\n",
            "Step 99/390 - D loss: 4.3150, G loss: 0.0003\n",
            "Step 100/390 - D loss: 4.3119, G loss: 0.0003\n",
            "Step 101/390 - D loss: 4.3055, G loss: 0.0003\n",
            "Step 102/390 - D loss: 4.2924, G loss: 0.0003\n",
            "Step 103/390 - D loss: 4.2750, G loss: 0.0003\n",
            "Step 104/390 - D loss: 4.2699, G loss: 0.0003\n",
            "Step 105/390 - D loss: 4.2707, G loss: 0.0003\n",
            "Step 106/390 - D loss: 4.2656, G loss: 0.0003\n",
            "Step 107/390 - D loss: 4.2734, G loss: 0.0003\n",
            "Step 108/390 - D loss: 4.2777, G loss: 0.0003\n",
            "Step 109/390 - D loss: 4.2931, G loss: 0.0003\n",
            "Step 110/390 - D loss: 4.2473, G loss: 0.0003\n",
            "Step 111/390 - D loss: 4.2726, G loss: 0.0003\n",
            "Step 112/390 - D loss: 4.2688, G loss: 0.0003\n",
            "Step 113/390 - D loss: 4.2465, G loss: 0.0003\n",
            "Step 114/390 - D loss: 4.2489, G loss: 0.0003\n",
            "Step 115/390 - D loss: 4.2359, G loss: 0.0003\n",
            "Step 116/390 - D loss: 4.2384, G loss: 0.0003\n",
            "Step 117/390 - D loss: 4.2359, G loss: 0.0003\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 118/390 - D loss: 4.2463, G loss: 0.0003\n",
            "Step 119/390 - D loss: 4.2272, G loss: 0.0003\n",
            "Step 120/390 - D loss: 4.2436, G loss: 0.0003\n",
            "Step 121/390 - D loss: 4.2156, G loss: 0.0003\n",
            "Step 122/390 - D loss: 4.1951, G loss: 0.0003\n",
            "Step 123/390 - D loss: 4.1931, G loss: 0.0003\n",
            "Step 124/390 - D loss: 4.2006, G loss: 0.0003\n",
            "Step 125/390 - D loss: 4.2062, G loss: 0.0003\n",
            "Step 126/390 - D loss: 4.2016, G loss: 0.0003\n",
            "Step 127/390 - D loss: 4.1945, G loss: 0.0003\n",
            "Step 128/390 - D loss: 4.2049, G loss: 0.0003\n",
            "Step 129/390 - D loss: 4.1913, G loss: 0.0003\n",
            "Step 130/390 - D loss: 4.1804, G loss: 0.0003\n",
            "Step 131/390 - D loss: 4.1674, G loss: 0.0003\n",
            "Step 132/390 - D loss: 4.1653, G loss: 0.0003\n",
            "Step 133/390 - D loss: 4.1658, G loss: 0.0003\n",
            "Step 134/390 - D loss: 4.1564, G loss: 0.0003\n",
            "Step 135/390 - D loss: 4.1574, G loss: 0.0003\n",
            "Step 136/390 - D loss: 4.1744, G loss: 0.0003\n",
            "Step 137/390 - D loss: 4.1682, G loss: 0.0003\n",
            "Step 138/390 - D loss: 4.1576, G loss: 0.0003\n",
            "Step 139/390 - D loss: 4.1573, G loss: 0.0003\n",
            "Step 140/390 - D loss: 4.1543, G loss: 0.0003\n",
            "Step 141/390 - D loss: 4.1481, G loss: 0.0003\n",
            "Step 142/390 - D loss: 4.1348, G loss: 0.0003\n",
            "Step 143/390 - D loss: 4.1501, G loss: 0.0003\n",
            "Step 144/390 - D loss: 4.1345, G loss: 0.0003\n",
            "Step 145/390 - D loss: 4.1240, G loss: 0.0003\n",
            "Step 146/390 - D loss: 4.1357, G loss: 0.0003\n",
            "Step 147/390 - D loss: 4.1282, G loss: 0.0003\n",
            "Step 148/390 - D loss: 4.1145, G loss: 0.0003\n",
            "Step 149/390 - D loss: 4.1541, G loss: 0.0003\n",
            "Step 150/390 - D loss: 4.1293, G loss: 0.0003\n",
            "Step 151/390 - D loss: 4.1425, G loss: 0.0004\n",
            "Step 152/390 - D loss: 4.1483, G loss: 0.0004\n",
            "Step 153/390 - D loss: 4.1432, G loss: 0.0004\n",
            "Step 154/390 - D loss: 4.1223, G loss: 0.0004\n",
            "Step 155/390 - D loss: 4.1160, G loss: 0.0004\n",
            "Step 156/390 - D loss: 4.1208, G loss: 0.0004\n",
            "Step 157/390 - D loss: 4.1372, G loss: 0.0004\n",
            "Step 158/390 - D loss: 4.1104, G loss: 0.0004\n",
            "Step 159/390 - D loss: 4.1422, G loss: 0.0004\n",
            "Step 160/390 - D loss: 4.1265, G loss: 0.0004\n",
            "Step 161/390 - D loss: 4.1377, G loss: 0.0004\n",
            "Step 162/390 - D loss: 4.1170, G loss: 0.0004\n",
            "Step 163/390 - D loss: 4.1020, G loss: 0.0004\n",
            "Step 164/390 - D loss: 4.1243, G loss: 0.0004\n",
            "Step 165/390 - D loss: 4.1020, G loss: 0.0004\n",
            "Step 166/390 - D loss: 4.0973, G loss: 0.0004\n",
            "Step 167/390 - D loss: 4.1131, G loss: 0.0004\n",
            "Step 168/390 - D loss: 4.1018, G loss: 0.0004\n",
            "Step 169/390 - D loss: 4.1042, G loss: 0.0004\n",
            "Step 170/390 - D loss: 4.1114, G loss: 0.0004\n",
            "Step 171/390 - D loss: 4.1342, G loss: 0.0004\n",
            "Step 172/390 - D loss: 4.1060, G loss: 0.0004\n",
            "Step 173/390 - D loss: 4.0879, G loss: 0.0004\n",
            "Step 174/390 - D loss: 4.1064, G loss: 0.0004\n",
            "Step 175/390 - D loss: 4.0989, G loss: 0.0004\n",
            "Step 176/390 - D loss: 4.0814, G loss: 0.0004\n",
            "Step 177/390 - D loss: 4.0856, G loss: 0.0004\n",
            "Step 178/390 - D loss: 4.0769, G loss: 0.0004\n",
            "Step 179/390 - D loss: 4.1207, G loss: 0.0004\n",
            "Step 180/390 - D loss: 4.0747, G loss: 0.0004\n",
            "Step 181/390 - D loss: 4.0774, G loss: 0.0004\n",
            "Step 182/390 - D loss: 4.0928, G loss: 0.0004\n",
            "Step 183/390 - D loss: 4.0767, G loss: 0.0004\n",
            "Step 184/390 - D loss: 4.1013, G loss: 0.0004\n",
            "Step 185/390 - D loss: 4.0623, G loss: 0.0004\n",
            "Step 186/390 - D loss: 4.0657, G loss: 0.0004\n",
            "Step 187/390 - D loss: 4.0784, G loss: 0.0004\n",
            "Step 188/390 - D loss: 4.0618, G loss: 0.0004\n",
            "Step 189/390 - D loss: 4.0601, G loss: 0.0004\n",
            "Step 190/390 - D loss: 4.0691, G loss: 0.0004\n",
            "Step 191/390 - D loss: 4.0574, G loss: 0.0004\n",
            "Step 192/390 - D loss: 4.0596, G loss: 0.0004\n",
            "Step 193/390 - D loss: 4.0579, G loss: 0.0004\n",
            "Step 194/390 - D loss: 4.0413, G loss: 0.0004\n",
            "Step 195/390 - D loss: 4.0597, G loss: 0.0004\n",
            "Step 196/390 - D loss: 4.0526, G loss: 0.0004\n",
            "Step 197/390 - D loss: 4.0396, G loss: 0.0004\n",
            "Step 198/390 - D loss: 4.0421, G loss: 0.0004\n",
            "Step 199/390 - D loss: 4.0232, G loss: 0.0004\n",
            "Step 200/390 - D loss: 4.0343, G loss: 0.0004\n",
            "Step 201/390 - D loss: 4.0216, G loss: 0.0004\n",
            "Step 202/390 - D loss: 4.0537, G loss: 0.0004\n",
            "Step 203/390 - D loss: 4.0348, G loss: 0.0004\n",
            "Step 204/390 - D loss: 4.0274, G loss: 0.0004\n",
            "Step 205/390 - D loss: 4.0439, G loss: 0.0004\n",
            "Step 206/390 - D loss: 4.0272, G loss: 0.0004\n",
            "Step 207/390 - D loss: 4.0204, G loss: 0.0004\n",
            "Step 208/390 - D loss: 4.0170, G loss: 0.0004\n",
            "Step 209/390 - D loss: 4.0145, G loss: 0.0004\n",
            "Step 210/390 - D loss: 4.0248, G loss: 0.0004\n",
            "Step 211/390 - D loss: 3.9909, G loss: 0.0004\n",
            "Step 212/390 - D loss: 4.0044, G loss: 0.0004\n",
            "Step 213/390 - D loss: 4.0153, G loss: 0.0005\n",
            "Step 214/390 - D loss: 4.0095, G loss: 0.0005\n",
            "Step 215/390 - D loss: 4.0038, G loss: 0.0005\n",
            "Step 216/390 - D loss: 3.9993, G loss: 0.0005\n",
            "Step 217/390 - D loss: 3.9908, G loss: 0.0005\n",
            "Step 218/390 - D loss: 4.0020, G loss: 0.0005\n",
            "Step 219/390 - D loss: 3.9835, G loss: 0.0005\n",
            "Step 220/390 - D loss: 3.9950, G loss: 0.0005\n",
            "Step 221/390 - D loss: 3.9605, G loss: 0.0005\n",
            "Step 222/390 - D loss: 3.9836, G loss: 0.0005\n",
            "Step 223/390 - D loss: 3.9729, G loss: 0.0005\n",
            "Step 224/390 - D loss: 3.9966, G loss: 0.0005\n",
            "Step 225/390 - D loss: 3.9536, G loss: 0.0005\n",
            "Step 226/390 - D loss: 3.9785, G loss: 0.0005\n",
            "Step 227/390 - D loss: 3.9907, G loss: 0.0005\n",
            "Step 228/390 - D loss: 3.9885, G loss: 0.0005\n",
            "Step 229/390 - D loss: 3.9505, G loss: 0.0005\n",
            "Step 230/390 - D loss: 3.9757, G loss: 0.0005\n",
            "Step 231/390 - D loss: 3.9693, G loss: 0.0005\n",
            "Step 232/390 - D loss: 3.9703, G loss: 0.0005\n",
            "Step 233/390 - D loss: 3.9677, G loss: 0.0005\n",
            "Step 234/390 - D loss: 3.9825, G loss: 0.0005\n",
            "Step 235/390 - D loss: 3.9551, G loss: 0.0005\n",
            "Step 236/390 - D loss: 3.9669, G loss: 0.0005\n",
            "Step 237/390 - D loss: 3.9508, G loss: 0.0005\n",
            "Step 238/390 - D loss: 3.9843, G loss: 0.0005\n",
            "Step 239/390 - D loss: 3.9452, G loss: 0.0005\n",
            "Step 240/390 - D loss: 3.9547, G loss: 0.0005\n",
            "Step 241/390 - D loss: 3.9431, G loss: 0.0005\n",
            "Step 242/390 - D loss: 3.9870, G loss: 0.0005\n",
            "Step 243/390 - D loss: 3.9408, G loss: 0.0005\n",
            "Step 244/390 - D loss: 3.9628, G loss: 0.0005\n",
            "Step 245/390 - D loss: 3.9615, G loss: 0.0005\n",
            "Step 246/390 - D loss: 3.9160, G loss: 0.0005\n",
            "Step 247/390 - D loss: 3.9737, G loss: 0.0005\n",
            "Step 248/390 - D loss: 3.9517, G loss: 0.0005\n",
            "Step 249/390 - D loss: 3.9196, G loss: 0.0005\n",
            "Step 250/390 - D loss: 3.9416, G loss: 0.0005\n",
            "Step 251/390 - D loss: 3.9287, G loss: 0.0005\n",
            "Step 252/390 - D loss: 3.9268, G loss: 0.0005\n",
            "Step 253/390 - D loss: 3.9207, G loss: 0.0005\n",
            "Step 254/390 - D loss: 3.9501, G loss: 0.0005\n",
            "Step 255/390 - D loss: 3.9211, G loss: 0.0005\n",
            "Step 256/390 - D loss: 3.9445, G loss: 0.0005\n",
            "Step 257/390 - D loss: 3.9180, G loss: 0.0006\n",
            "Step 258/390 - D loss: 3.9251, G loss: 0.0005\n",
            "Step 259/390 - D loss: 3.9188, G loss: 0.0006\n",
            "Step 260/390 - D loss: 3.9063, G loss: 0.0006\n",
            "Step 261/390 - D loss: 3.9142, G loss: 0.0006\n",
            "Step 262/390 - D loss: 3.9215, G loss: 0.0006\n",
            "Step 263/390 - D loss: 3.9206, G loss: 0.0006\n",
            "Step 264/390 - D loss: 3.8936, G loss: 0.0006\n",
            "Step 265/390 - D loss: 3.9051, G loss: 0.0006\n",
            "Step 266/390 - D loss: 3.9100, G loss: 0.0006\n",
            "Step 267/390 - D loss: 3.9085, G loss: 0.0006\n",
            "Step 268/390 - D loss: 3.9220, G loss: 0.0006\n",
            "Step 269/390 - D loss: 3.8996, G loss: 0.0006\n",
            "Step 270/390 - D loss: 3.8989, G loss: 0.0006\n",
            "Step 271/390 - D loss: 3.8965, G loss: 0.0006\n",
            "Step 272/390 - D loss: 3.8933, G loss: 0.0006\n",
            "Step 273/390 - D loss: 3.8933, G loss: 0.0006\n",
            "Step 274/390 - D loss: 3.8951, G loss: 0.0006\n",
            "Step 275/390 - D loss: 3.8906, G loss: 0.0006\n",
            "Step 276/390 - D loss: 3.9051, G loss: 0.0006\n",
            "Step 277/390 - D loss: 3.9223, G loss: 0.0006\n",
            "Step 278/390 - D loss: 3.8860, G loss: 0.0006\n",
            "Step 279/390 - D loss: 3.8694, G loss: 0.0006\n",
            "Step 280/390 - D loss: 3.8924, G loss: 0.0006\n",
            "Step 281/390 - D loss: 3.8971, G loss: 0.0006\n",
            "Step 282/390 - D loss: 3.8711, G loss: 0.0006\n",
            "Step 283/390 - D loss: 3.8800, G loss: 0.0006\n",
            "Step 284/390 - D loss: 3.8867, G loss: 0.0006\n",
            "Step 285/390 - D loss: 3.8914, G loss: 0.0006\n",
            "Step 286/390 - D loss: 3.9060, G loss: 0.0006\n",
            "Step 287/390 - D loss: 3.8767, G loss: 0.0006\n",
            "Step 288/390 - D loss: 3.8864, G loss: 0.0006\n",
            "Step 289/390 - D loss: 3.8704, G loss: 0.0006\n",
            "Step 290/390 - D loss: 3.8702, G loss: 0.0006\n",
            "Step 291/390 - D loss: 3.8567, G loss: 0.0006\n",
            "Step 292/390 - D loss: 3.8602, G loss: 0.0006\n",
            "Step 293/390 - D loss: 3.8540, G loss: 0.0006\n",
            "Step 294/390 - D loss: 3.8633, G loss: 0.0006\n",
            "Step 295/390 - D loss: 3.8649, G loss: 0.0006\n",
            "Step 296/390 - D loss: 3.8540, G loss: 0.0006\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 297/390 - D loss: 3.8590, G loss: 0.0006\n",
            "Step 298/390 - D loss: 3.8504, G loss: 0.0006\n",
            "Step 299/390 - D loss: 3.8699, G loss: 0.0006\n",
            "Step 300/390 - D loss: 3.8402, G loss: 0.0006\n",
            "Step 301/390 - D loss: 3.8495, G loss: 0.0006\n",
            "Step 302/390 - D loss: 3.8631, G loss: 0.0006\n",
            "Step 303/390 - D loss: 3.8566, G loss: 0.0006\n",
            "Step 304/390 - D loss: 3.8549, G loss: 0.0006\n",
            "Step 305/390 - D loss: 3.8712, G loss: 0.0006\n",
            "Step 306/390 - D loss: 3.8601, G loss: 0.0006\n",
            "Step 307/390 - D loss: 3.8614, G loss: 0.0006\n",
            "Step 308/390 - D loss: 3.8425, G loss: 0.0006\n",
            "Step 309/390 - D loss: 3.8483, G loss: 0.0006\n",
            "Step 310/390 - D loss: 3.8459, G loss: 0.0006\n",
            "Step 311/390 - D loss: 3.8382, G loss: 0.0006\n",
            "Step 312/390 - D loss: 3.8587, G loss: 0.0006\n",
            "Step 313/390 - D loss: 3.8593, G loss: 0.0006\n",
            "Step 314/390 - D loss: 3.8594, G loss: 0.0006\n",
            "Step 315/390 - D loss: 3.8707, G loss: 0.0006\n",
            "Step 316/390 - D loss: 3.8631, G loss: 0.0006\n",
            "Step 317/390 - D loss: 3.8526, G loss: 0.0006\n",
            "Step 318/390 - D loss: 3.8422, G loss: 0.0006\n",
            "Step 319/390 - D loss: 3.8319, G loss: 0.0006\n",
            "Step 320/390 - D loss: 3.8348, G loss: 0.0006\n",
            "Step 321/390 - D loss: 3.8444, G loss: 0.0006\n",
            "Step 322/390 - D loss: 3.8330, G loss: 0.0006\n",
            "Step 323/390 - D loss: 3.8526, G loss: 0.0006\n",
            "Step 324/390 - D loss: 3.8302, G loss: 0.0006\n",
            "Step 325/390 - D loss: 3.8154, G loss: 0.0006\n",
            "Step 326/390 - D loss: 3.8324, G loss: 0.0006\n",
            "Step 327/390 - D loss: 3.8436, G loss: 0.0006\n",
            "Step 328/390 - D loss: 3.8092, G loss: 0.0006\n",
            "Step 329/390 - D loss: 3.8381, G loss: 0.0006\n",
            "Step 330/390 - D loss: 3.8428, G loss: 0.0006\n",
            "Step 331/390 - D loss: 3.8272, G loss: 0.0006\n",
            "Step 332/390 - D loss: 3.8244, G loss: 0.0006\n",
            "Step 333/390 - D loss: 3.8123, G loss: 0.0006\n",
            "Step 334/390 - D loss: 3.8043, G loss: 0.0006\n",
            "Step 335/390 - D loss: 3.8040, G loss: 0.0006\n",
            "Step 336/390 - D loss: 3.8198, G loss: 0.0006\n",
            "Step 337/390 - D loss: 3.8096, G loss: 0.0006\n",
            "Step 338/390 - D loss: 3.7920, G loss: 0.0006\n",
            "Step 339/390 - D loss: 3.8145, G loss: 0.0006\n",
            "Step 340/390 - D loss: 3.8232, G loss: 0.0006\n",
            "Step 341/390 - D loss: 3.8107, G loss: 0.0006\n",
            "Step 342/390 - D loss: 3.8182, G loss: 0.0006\n",
            "Step 343/390 - D loss: 3.8276, G loss: 0.0007\n",
            "Step 344/390 - D loss: 3.8108, G loss: 0.0007\n",
            "Step 345/390 - D loss: 3.8248, G loss: 0.0007\n",
            "Step 346/390 - D loss: 3.8182, G loss: 0.0007\n",
            "Step 347/390 - D loss: 3.8056, G loss: 0.0007\n",
            "Step 348/390 - D loss: 3.8184, G loss: 0.0007\n",
            "Step 349/390 - D loss: 3.8119, G loss: 0.0007\n",
            "Step 350/390 - D loss: 3.8067, G loss: 0.0007\n",
            "Step 351/390 - D loss: 3.7883, G loss: 0.0007\n",
            "Step 352/390 - D loss: 3.7978, G loss: 0.0007\n",
            "Step 353/390 - D loss: 3.8089, G loss: 0.0007\n",
            "Step 354/390 - D loss: 3.8126, G loss: 0.0007\n",
            "Step 355/390 - D loss: 3.7768, G loss: 0.0007\n",
            "Step 356/390 - D loss: 3.7869, G loss: 0.0007\n",
            "Step 357/390 - D loss: 3.7987, G loss: 0.0007\n",
            "Step 358/390 - D loss: 3.8002, G loss: 0.0007\n",
            "Step 359/390 - D loss: 3.7884, G loss: 0.0007\n",
            "Step 360/390 - D loss: 3.7933, G loss: 0.0007\n",
            "Step 361/390 - D loss: 3.8075, G loss: 0.0007\n",
            "Step 362/390 - D loss: 3.8113, G loss: 0.0007\n",
            "Step 363/390 - D loss: 3.7896, G loss: 0.0007\n",
            "Step 364/390 - D loss: 3.7935, G loss: 0.0007\n",
            "Step 365/390 - D loss: 3.7945, G loss: 0.0007\n",
            "Step 366/390 - D loss: 3.7816, G loss: 0.0007\n",
            "Step 367/390 - D loss: 3.7815, G loss: 0.0007\n",
            "Step 368/390 - D loss: 3.7885, G loss: 0.0007\n",
            "Step 369/390 - D loss: 3.7881, G loss: 0.0007\n",
            "Step 370/390 - D loss: 3.7941, G loss: 0.0007\n",
            "Step 371/390 - D loss: 3.7752, G loss: 0.0007\n",
            "Step 372/390 - D loss: 3.7946, G loss: 0.0007\n",
            "Step 373/390 - D loss: 3.8035, G loss: 0.0007\n",
            "Step 374/390 - D loss: 3.8003, G loss: 0.0007\n",
            "Step 375/390 - D loss: 3.7903, G loss: 0.0007\n",
            "Step 376/390 - D loss: 3.7910, G loss: 0.0007\n",
            "Step 377/390 - D loss: 3.7803, G loss: 0.0007\n",
            "Step 378/390 - D loss: 3.7745, G loss: 0.0007\n",
            "Step 379/390 - D loss: 3.7873, G loss: 0.0007\n",
            "Step 380/390 - D loss: 3.7825, G loss: 0.0007\n",
            "Step 381/390 - D loss: 3.7853, G loss: 0.0007\n",
            "Step 382/390 - D loss: 3.7622, G loss: 0.0007\n",
            "Step 383/390 - D loss: 3.7993, G loss: 0.0007\n",
            "Step 384/390 - D loss: 3.7819, G loss: 0.0007\n",
            "Step 385/390 - D loss: 3.7720, G loss: 0.0007\n",
            "Step 386/390 - D loss: 3.7840, G loss: 0.0007\n",
            "Step 387/390 - D loss: 3.7823, G loss: 0.0007\n",
            "Step 388/390 - D loss: 3.8087, G loss: 0.0007\n",
            "Step 389/390 - D loss: 3.7950, G loss: 0.0007\n",
            "Step 390/390 - D loss: 3.7806, G loss: 0.0007\n",
            "Epoch 10/200\n",
            "Step 1/390 - D loss: 3.7756, G loss: 0.0007\n",
            "Step 2/390 - D loss: 3.7807, G loss: 0.0007\n",
            "Step 3/390 - D loss: 3.7832, G loss: 0.0007\n",
            "Step 4/390 - D loss: 3.7905, G loss: 0.0007\n",
            "Step 5/390 - D loss: 3.7753, G loss: 0.0007\n",
            "Step 6/390 - D loss: 3.7630, G loss: 0.0007\n",
            "Step 7/390 - D loss: 3.7718, G loss: 0.0007\n",
            "Step 8/390 - D loss: 3.7794, G loss: 0.0007\n",
            "Step 9/390 - D loss: 3.7609, G loss: 0.0007\n",
            "Step 10/390 - D loss: 3.7708, G loss: 0.0007\n",
            "Step 11/390 - D loss: 3.7735, G loss: 0.0007\n",
            "Step 12/390 - D loss: 3.7701, G loss: 0.0007\n",
            "Step 13/390 - D loss: 3.7854, G loss: 0.0007\n",
            "Step 14/390 - D loss: 3.7629, G loss: 0.0007\n",
            "Step 15/390 - D loss: 3.7604, G loss: 0.0007\n",
            "Step 16/390 - D loss: 3.7736, G loss: 0.0007\n",
            "Step 17/390 - D loss: 3.7608, G loss: 0.0007\n",
            "Step 18/390 - D loss: 3.7511, G loss: 0.0007\n",
            "Step 19/390 - D loss: 3.7757, G loss: 0.0007\n",
            "Step 20/390 - D loss: 3.7674, G loss: 0.0007\n",
            "Step 21/390 - D loss: 3.7709, G loss: 0.0007\n",
            "Step 22/390 - D loss: 3.7485, G loss: 0.0007\n",
            "Step 23/390 - D loss: 3.7734, G loss: 0.0007\n",
            "Step 24/390 - D loss: 3.7771, G loss: 0.0007\n",
            "Step 25/390 - D loss: 3.7617, G loss: 0.0007\n",
            "Step 26/390 - D loss: 3.7652, G loss: 0.0007\n",
            "Step 27/390 - D loss: 3.7679, G loss: 0.0007\n",
            "Step 28/390 - D loss: 3.7464, G loss: 0.0007\n",
            "Step 29/390 - D loss: 3.7538, G loss: 0.0007\n",
            "Step 30/390 - D loss: 3.7454, G loss: 0.0007\n",
            "Step 31/390 - D loss: 3.7789, G loss: 0.0007\n",
            "Step 32/390 - D loss: 3.7547, G loss: 0.0007\n",
            "Step 33/390 - D loss: 3.7685, G loss: 0.0007\n",
            "Step 34/390 - D loss: 3.7866, G loss: 0.0007\n",
            "Step 35/390 - D loss: 3.7808, G loss: 0.0007\n",
            "Step 36/390 - D loss: 3.7765, G loss: 0.0007\n",
            "Step 37/390 - D loss: 3.7604, G loss: 0.0007\n",
            "Step 38/390 - D loss: 3.7636, G loss: 0.0007\n",
            "Step 39/390 - D loss: 3.7602, G loss: 0.0007\n",
            "Step 40/390 - D loss: 3.7905, G loss: 0.0007\n",
            "Step 41/390 - D loss: 3.7601, G loss: 0.0007\n",
            "Step 42/390 - D loss: 3.7547, G loss: 0.0007\n",
            "Step 43/390 - D loss: 3.7597, G loss: 0.0007\n",
            "Step 44/390 - D loss: 3.7713, G loss: 0.0007\n",
            "Step 45/390 - D loss: 3.7370, G loss: 0.0007\n",
            "Step 46/390 - D loss: 3.7506, G loss: 0.0007\n",
            "Step 47/390 - D loss: 3.7557, G loss: 0.0007\n",
            "Step 48/390 - D loss: 3.7758, G loss: 0.0007\n",
            "Step 49/390 - D loss: 3.7512, G loss: 0.0007\n",
            "Step 50/390 - D loss: 3.7771, G loss: 0.0007\n",
            "Step 51/390 - D loss: 3.7844, G loss: 0.0007\n",
            "Step 52/390 - D loss: 3.7478, G loss: 0.0007\n",
            "Step 53/390 - D loss: 3.7681, G loss: 0.0007\n",
            "Step 54/390 - D loss: 3.7554, G loss: 0.0007\n",
            "Step 55/390 - D loss: 3.7375, G loss: 0.0007\n",
            "Step 56/390 - D loss: 3.7493, G loss: 0.0007\n",
            "Step 57/390 - D loss: 3.7613, G loss: 0.0007\n",
            "Step 58/390 - D loss: 3.7561, G loss: 0.0007\n",
            "Step 59/390 - D loss: 3.7450, G loss: 0.0007\n",
            "Step 60/390 - D loss: 3.7589, G loss: 0.0007\n",
            "Step 61/390 - D loss: 3.7543, G loss: 0.0007\n",
            "Step 62/390 - D loss: 3.7452, G loss: 0.0007\n",
            "Step 63/390 - D loss: 3.7372, G loss: 0.0007\n",
            "Step 64/390 - D loss: 3.7442, G loss: 0.0007\n",
            "Step 65/390 - D loss: 3.7443, G loss: 0.0007\n",
            "Step 66/390 - D loss: 3.7597, G loss: 0.0007\n",
            "Step 67/390 - D loss: 3.7741, G loss: 0.0007\n",
            "Step 68/390 - D loss: 3.7569, G loss: 0.0007\n",
            "Step 69/390 - D loss: 3.7473, G loss: 0.0007\n",
            "Step 70/390 - D loss: 3.7464, G loss: 0.0007\n",
            "Step 71/390 - D loss: 3.7565, G loss: 0.0007\n",
            "Step 72/390 - D loss: 3.7529, G loss: 0.0007\n",
            "Step 73/390 - D loss: 3.7477, G loss: 0.0007\n",
            "Step 74/390 - D loss: 3.7393, G loss: 0.0007\n",
            "Step 75/390 - D loss: 3.7596, G loss: 0.0007\n",
            "Step 76/390 - D loss: 3.7418, G loss: 0.0007\n",
            "Step 77/390 - D loss: 3.7386, G loss: 0.0007\n",
            "Step 78/390 - D loss: 3.7396, G loss: 0.0007\n",
            "Step 79/390 - D loss: 3.7490, G loss: 0.0007\n",
            "Step 80/390 - D loss: 3.7410, G loss: 0.0007\n",
            "Step 81/390 - D loss: 3.7597, G loss: 0.0007\n",
            "Step 82/390 - D loss: 3.7391, G loss: 0.0007\n",
            "Step 83/390 - D loss: 3.7581, G loss: 0.0007\n",
            "Step 84/390 - D loss: 3.7364, G loss: 0.0007\n",
            "Step 85/390 - D loss: 3.7484, G loss: 0.0007\n",
            "Step 86/390 - D loss: 3.7551, G loss: 0.0007\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 87/390 - D loss: 3.7357, G loss: 0.0007\n",
            "Step 88/390 - D loss: 3.7299, G loss: 0.0007\n",
            "Step 89/390 - D loss: 3.7380, G loss: 0.0007\n",
            "Step 90/390 - D loss: 3.7547, G loss: 0.0007\n",
            "Step 91/390 - D loss: 3.7408, G loss: 0.0007\n",
            "Step 92/390 - D loss: 3.7446, G loss: 0.0007\n",
            "Step 93/390 - D loss: 3.7167, G loss: 0.0007\n",
            "Step 94/390 - D loss: 3.7325, G loss: 0.0007\n",
            "Step 95/390 - D loss: 3.7618, G loss: 0.0007\n",
            "Step 96/390 - D loss: 3.7342, G loss: 0.0007\n",
            "Step 97/390 - D loss: 3.7293, G loss: 0.0007\n",
            "Step 98/390 - D loss: 3.7394, G loss: 0.0007\n",
            "Step 99/390 - D loss: 3.7433, G loss: 0.0007\n",
            "Step 100/390 - D loss: 3.7226, G loss: 0.0007\n",
            "Step 101/390 - D loss: 3.7544, G loss: 0.0007\n",
            "Step 102/390 - D loss: 3.7505, G loss: 0.0007\n",
            "Step 103/390 - D loss: 3.7397, G loss: 0.0007\n",
            "Step 104/390 - D loss: 3.7326, G loss: 0.0007\n",
            "Step 105/390 - D loss: 3.7284, G loss: 0.0007\n",
            "Step 106/390 - D loss: 3.7372, G loss: 0.0007\n",
            "Step 107/390 - D loss: 3.7552, G loss: 0.0007\n",
            "Step 108/390 - D loss: 3.7362, G loss: 0.0007\n",
            "Step 109/390 - D loss: 3.7354, G loss: 0.0007\n",
            "Step 110/390 - D loss: 3.7460, G loss: 0.0007\n",
            "Step 111/390 - D loss: 3.7416, G loss: 0.0007\n",
            "Step 112/390 - D loss: 3.7547, G loss: 0.0007\n",
            "Step 113/390 - D loss: 3.7341, G loss: 0.0007\n",
            "Step 114/390 - D loss: 3.7358, G loss: 0.0007\n",
            "Step 115/390 - D loss: 3.7227, G loss: 0.0007\n",
            "Step 116/390 - D loss: 3.7480, G loss: 0.0007\n",
            "Step 117/390 - D loss: 3.7399, G loss: 0.0007\n",
            "Step 118/390 - D loss: 3.7415, G loss: 0.0007\n",
            "Step 119/390 - D loss: 3.7271, G loss: 0.0007\n",
            "Step 120/390 - D loss: 3.7094, G loss: 0.0007\n",
            "Step 121/390 - D loss: 3.7327, G loss: 0.0007\n",
            "Step 122/390 - D loss: 3.7196, G loss: 0.0007\n",
            "Step 123/390 - D loss: 3.7213, G loss: 0.0007\n",
            "Step 124/390 - D loss: 3.7231, G loss: 0.0007\n",
            "Step 125/390 - D loss: 3.7171, G loss: 0.0007\n",
            "Step 126/390 - D loss: 3.7350, G loss: 0.0007\n",
            "Step 127/390 - D loss: 3.7453, G loss: 0.0007\n",
            "Step 128/390 - D loss: 3.7539, G loss: 0.0007\n",
            "Step 129/390 - D loss: 3.7318, G loss: 0.0007\n",
            "Step 130/390 - D loss: 3.7165, G loss: 0.0007\n",
            "Step 131/390 - D loss: 3.7201, G loss: 0.0007\n",
            "Step 132/390 - D loss: 3.7336, G loss: 0.0007\n",
            "Step 133/390 - D loss: 3.7341, G loss: 0.0007\n",
            "Step 134/390 - D loss: 3.7303, G loss: 0.0007\n",
            "Step 135/390 - D loss: 3.7277, G loss: 0.0007\n",
            "Step 136/390 - D loss: 3.7190, G loss: 0.0008\n",
            "Step 137/390 - D loss: 3.6981, G loss: 0.0007\n",
            "Step 138/390 - D loss: 3.7199, G loss: 0.0007\n",
            "Step 139/390 - D loss: 3.7090, G loss: 0.0007\n",
            "Step 140/390 - D loss: 3.7089, G loss: 0.0008\n",
            "Step 141/390 - D loss: 3.7088, G loss: 0.0007\n",
            "Step 142/390 - D loss: 3.7204, G loss: 0.0008\n",
            "Step 143/390 - D loss: 3.7203, G loss: 0.0008\n",
            "Step 144/390 - D loss: 3.7138, G loss: 0.0008\n",
            "Step 145/390 - D loss: 3.7115, G loss: 0.0007\n",
            "Step 146/390 - D loss: 3.7168, G loss: 0.0008\n",
            "Step 147/390 - D loss: 3.7159, G loss: 0.0008\n",
            "Step 148/390 - D loss: 3.7108, G loss: 0.0008\n",
            "Step 149/390 - D loss: 3.7183, G loss: 0.0008\n",
            "Step 150/390 - D loss: 3.7134, G loss: 0.0008\n",
            "Step 151/390 - D loss: 3.6979, G loss: 0.0008\n",
            "Step 152/390 - D loss: 3.7003, G loss: 0.0008\n",
            "Step 153/390 - D loss: 3.7254, G loss: 0.0008\n",
            "Step 154/390 - D loss: 3.7043, G loss: 0.0008\n",
            "Step 155/390 - D loss: 3.6960, G loss: 0.0008\n",
            "Step 156/390 - D loss: 3.7279, G loss: 0.0008\n",
            "Step 157/390 - D loss: 3.7469, G loss: 0.0008\n",
            "Step 158/390 - D loss: 3.6997, G loss: 0.0008\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Train the generator to fool the discriminator\u001b[39;00m\n\u001b[1;32m     36\u001b[0m noise \u001b[38;5;241m=\u001b[39m generate_noise(batch_size, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m generator_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Print the losses for this step\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps_per_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - D loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiscriminator_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, G loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerator_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1727\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1723\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x,\n\u001b[1;32m   1724\u001b[0m                                                 y, sample_weight,\n\u001b[1;32m   1725\u001b[0m                                                 class_weight)\n\u001b[1;32m   1726\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 1727\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_metrics:\n\u001b[1;32m   1730\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/anaconda3/envs/cs512/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set the batch size and number of epochs\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "\n",
        "# Create a function to generate noise vectors for the generator\n",
        "def generate_noise(batch_size, noise_dim):\n",
        "    return tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "# Define the number of steps to take for each epoch\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "# Train the GAN model\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    if (epoch > 0 and epoch % 10 ==0):\n",
        "        generator.save('local.h5')\n",
        "        print(\"saved\")\n",
        "    # Shuffle the data\n",
        "    np.random.shuffle(x_train)\n",
        "\n",
        "    # Loop over batches of data\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Sample a batch of real images\n",
        "        real_images = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        noise = generate_noise(batch_size, 100)\n",
        "        fake_images = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
        "        discriminator_loss = 0.5 * (discriminator_loss_real + discriminator_loss_fake)\n",
        "\n",
        "        # Train the generator to fool the discriminator\n",
        "        noise = generate_noise(batch_size, 100)\n",
        "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        # Print the losses for this step\n",
        "        print(f\"Step {step+1}/{steps_per_epoch} - D loss: {discriminator_loss:.4f}, G loss: {generator_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB5eOcgchyAq",
        "outputId": "e05f8b15-d518-4b81-daff-7ee44f0901bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Load a sample input image\n",
        "img_path = 'bliss.png'\n",
        "input_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "input_image = cv2.resize(input_image, (32, 32))\n",
        "input_image = input_image.astype('float32') / 255.0\n",
        "input_image = np.expand_dims(input_image, axis=-1)\n",
        "input_image = tf.stack([input_image[:, :, :]]*3, axis=-1)\n",
        "\n",
        "# Generate an output image using the trained GAN model\n",
        "noise = generate_noise(1, 100)\n",
        "generated_image = generator.predict(noise)\n",
        "\n",
        "# Display the input and output images\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(input_image[:, :, 0], cmap='gray')\n",
        "plt.title('Input Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(generated_image[0, :, :, :], cmap='gray')\n",
        "plt.title('Generated Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zb6--5Yl2jB"
      },
      "outputs": [],
      "source": [
        "# Save the generator model\n",
        "generator.save('model2-local.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxenWo67P6rK"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # Shuffle the data\n",
        "    np.random.shuffle(x_train)\n",
        "\n",
        "    # Loop over batches of data\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Sample a batch of real images\n",
        "        real_images = x_train[step * batch_size:(step + 1) * batch_size]\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        noise = generate_noise(batch_size, 100)\n",
        "        fake_images = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
        "        discriminator_loss = 0.5 * (discriminator_loss_real + discriminator_loss_fake)\n",
        "\n",
        "        # Train the generator to fool the discriminator\n",
        "        noise = generate_noise(batch_size, 100)\n",
        "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        # Print the losses for this step\n",
        "        print(f\"Step {step+1}/{steps_per_epoch} - D loss: {discriminator_loss:.4f}, G loss: {generator_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEQxlvvmP6rK"
      },
      "outputs": [],
      "source": [
        "# Save the generator model\n",
        "generator.save('generator_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AChccnZPP6rL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}